---
title: "Rédaction_V2"
format: html
editor: visual
execute-dir: project
---

# -------------------------------

# INTRODUCTION

# --------------------------------------------------

# Chargement des packages

```{r}

library(tidyverse)

library(ggalluvial)   # diagrammes alluviaux (transitions, flux entre catégories)
library(MuMIn)        # sélection de modèles, AICc, multimodel inference
library(lme4)

library(stats)
library(plotly)

library(ggrepel)      # étiquettes non superposées sur graphiques ggplot
library(ggpmisc)      # annotations statistiques (équations, R²) sur ggplot

library(MASS)         # outils statistiques avancés (LDA, glm, distributions)
library(ade4)         # analyses multivariées écologiques (PCA, CA, RLQ)

library(tidyr)
library(dplyr)
library(stringr)

library(vegan)        # écologie numérique : RDA, CCA, NMDS, PERMANOVA
library(car)          # diagnostics de modèles (VIF, tests de type II/III)

library(RMark)        # modèles capture-marquage-recapture (interface MARK)
library(DiagrammeR)   # graphes et diagrammes (flowcharts, DAG)
library(rstatix)      # Tables propres

```

# --------------------------------------------------

# Ouverture des tableaux de données

## --------------

Les tableaux sont ouverts chacun de leur côté afin de pouvoir réaliser les analyses ci-dessous indépendamment, dans le cas où toutes les données n’ont pas été entièrement relevées.

### Tableau : recouvrement

```{r}
recouvrement <- read.csv("data/raw/Recouvrement VF.csv",sep = ";")
unique(recouvrement$Site)
```

### Tableau : détections individuelles

```{r}
verification <- read.csv("data/raw/detections_individuelles_verifsTC+LD_18dec.csv", sep = ";")

# Certains noms des sites ont des espaces invisibles, correction : 
unique(verification$site)
verification$site <- trimws(verification$site)
unique(verification$site)
```

### Tableau : taille et phénologie vérifiées

```{r}
data_original <- read.csv("data/raw/Taille et phéno verif LD.csv", sep = ";")
unique(data_original$site)

# Certains noms contiennent des accents non pris en charge
data_original <- data_original %>% 
  mutate(site
         = case_when(
    site == "Combe Michaut" ~ "Combe Michaut",
    site == "Tête Cendrée Bas" ~ "Tete Cendree Bas",
    site == "Tête Cendrée Haut" ~ "Tete Cendree Haut",
    site == "Vigne au Renard" ~ "Vigne au Renard",
    site == "Val Clavin" ~ "Val Clavin"
  ))
unique(data_original$site)
```

### Tableau : autonotation des observateurs

```{r}
experience <- read.csv("data/raw/Experience_des_observateurs_VF.csv", sep = ";")

# Pour les analyses suivantes nous avons rajouté la colonne sexe : 
experience$sexe <- c("m","f","m","m","m","f","m","m","m","f","f","f","f","m","f","m","m","m","m","m","f","f","f","m","f","m","f","m","f","f","f","m","f","f","m")

```

# --------------------------------------------------

# Compilation tableau complet

Pour les analyses suivantes, nous avons compilé l’ensemble des tableaux en un seul.

```{r}

# Ajouter une colonne d'identifiant individuel en ajoutant la session
  ## Pour le tableau "vérification" des observateurs
verification2<- verification %>% 
  mutate(id_ind_fin = paste(ID_ind, session, sep = ".")) %>% 
  dplyr::select(id_ind_fin, everything())
  ## Pour le tableau "data_original" des évaluateurs

# Mettre le stade phénologique en ligne et non en colonne 
data_original2 <- data_original %>%
  dplyr::select(-tailleS1, -tailleS2, -tailleS3, -nbfleurs, -nbfruits, -predation) %>% 
  pivot_longer(
    cols = c(phenoS1, phenoS2, phenoS3),
    names_to = "session",
    values_to = "phenologie_verif"
  )%>% 
   mutate(session = case_when(
    session == "phenoS1" ~ 1,
    session == "phenoS2" ~ 2,
    session == "phenoS3" ~ 3
  )
   ) %>% 
  mutate(phenologie_verif
         = case_when(
    phenologie_verif == "j" ~ "juv",
    phenologie_verif == "nf" ~ "non_fleuri",
    phenologie_verif == "f" ~ "fleur",
    phenologie_verif == "ff" ~ "fleurs_fanees",
    phenologie_verif == "F" ~"fruit"
  ))

# Mettre la taille en ligne et non en colonne
data_original3 <- data_original %>% 
  dplyr::select(tailleS1, tailleS2, tailleS3) %>% 
  pivot_longer(
    cols = c(tailleS1, tailleS2, tailleS3),
    names_to = "session",
    values_to = "taille"
  ) %>% 
   mutate(session = case_when(
    session == "tailleS1" ~ 1,
    session == "tailleS2" ~ 2,
    session == "tailleS3" ~ 3
  )
   )

# Enlever la session car déjà présente sur l'autre data frame
data_original3 <- data_original3 %>% 
  dplyr::select(-session)

# Ajout des deux tableaux et suppression des lignes sans informations, liées à l’observation d’un individu à partir des sessions 2 ou 3
data_original4 <- cbind(data_original2, data_original3)

# Vérifier si il manque des informations par rapport à la phénologie
data_original4 %>% 
  filter(is.na(phenologie_verif))
      #Il manque des informations

# Ajouter la variable individuelle complète
data_original_obs <- data_original4 %>% 
  mutate(id_ind_fin = paste(ID_ind, session, sep = ".")) %>% 
  dplyr::select(id_ind_fin, everything())

# Prendre en compte le stade phénologique observé par observateurs
verification3 <- verification2 %>% 
  pivot_longer(
    cols = c(juv, non_fleuri, fleur, fleurs_fanees, fruit),
    names_to = "phenologie",
    values_to = "presence"
  )  
  
# Garder seulement la phénologie observée par observateurs
verification_obs <- verification3 %>% 
  filter(presence == 1)
  
# Vérifier le nombre individus
str(unique(verification_obs$id_ind_fin))
str(unique(data_original_obs$id_ind_fin))
str(data_original_obs$id_ind_fin)
str(verification_obs$id_ind_fin)
    # À priori, 66 individus jamais observés par les observateurs

# Extraire la liste de tous les individus
nb_individu <- data.frame(id_ind_fin = data_original_obs$id_ind_fin)

# Extraire la liste des individus dans le test de détection
nb_ind_obs <- data.frame(id_ind_fin = unique(verification_obs$id_ind_fin))

# Extraire les individus manquants
nb_individu_manquant <- nb_individu %>% 
  anti_join(nb_ind_obs, by = "id_ind_fin")

# Reprendre les données originales sur les valeurs manquantes
nb_individu_manquant_original <- data_original_obs %>% 
  semi_join(nb_individu_manquant, by = "id_ind_fin") 
  
# Joindre à ces données manquantes les valeurs du tableau observateurs
nb_individu_manquant_final <- nb_individu_manquant_original %>% 
  left_join(verification_obs, by = "id_ind_fin") %>% 
  dplyr::select(-ends_with(".y")) %>% 
  rename_with(~ sub("\\.x$", "", .x), ends_with(".x"))

# Joindre au fichier original les informations des évaluateurs
data_verification_original <- verification_obs %>% 
  left_join(data_original_obs, by = "id_ind_fin") %>% 
  dplyr::select(-ends_with(".y")) %>% 
  rename_with(~ sub("\\.x$", "", .x), ends_with(".x"))

# Mettre les colomnes dans le bon ordre
nb_individu_manquant_final <- nb_individu_manquant_final %>% 
  dplyr::select(id_ind_fin, session, site, date, numero_quadrat, ID_quadrat, marquage, ID_ind, observateur, adequation, phenologie, presence, quadrat, phenologie_verif, taille)

# Joindre ces données manquantes à tableau observateurs
tab_detection <- rbind(data_verification_original, nb_individu_manquant_final)

# Créer nouvelle valeur adéquation
tab_detection <- tab_detection %>% 
  mutate(adequation_reel = if_else(
    phenologie == phenologie_verif, 1, 0),
  comparaison_adequation = if_else(
    adequation_reel==adequation, 1, 0 ) )

# Taux d'erreur dans note d'adéquation
sum(tab_detection$comparaison_adequation == 0, na.rm = T) / nrow(tab_detection)

# Vérifier le nombre d'observateurs par session et par quadrat
nb_verif_quadrat <- verification %>% 
  group_by(session, site, numero_quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  )
nrow(nb_verif_quadrat)
nb_verif_quadrat <- nb_verif_quadrat %>% 
  mutate(site = case_when(
    site == "Combe Michaut" ~ "CM",
    site == "Tete Cendree Bas" ~ "TCb",
    site == "Tete Cendree Haut" ~ "TCh",
    site == "Vigne au Renard" ~ "VaR",
    site == "Val Clavin" ~ "VC"
  ),
  ID = "Q")

nb_verif_quadrat <- nb_verif_quadrat %>% 
  mutate(id_quadrat = paste(ID, numero_quadrat, sep = ""),
         id_quadrat_fin = paste(site, id_quadrat, session, sep =".")) %>% 
  dplyr::select(id_quadrat_fin, everything())

nb_obs_quadrat <- data_original_obs %>% 
  group_by(session, site, quadrat) %>% 
  count()
nrow(nb_obs_quadrat)

nb_quadrat_final <- tab_detection %>% 
  group_by(session, site, quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  ) %>% 
  filter(!is.na(quadrat))
nrow(nb_quadrat_final)

nb_quadrat_manquant <- nb_individu_manquant_final %>% 
  group_by(session, ID_quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  )
nrow(nb_quadrat_manquant)
    #individus manquants dans 39 quadras

nb_quadrat_manquant <- nb_quadrat_manquant %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  dplyr::select(id_quadrat_fin, everything())

test <- nb_quadrat_manquant %>% 
  anti_join(nb_verif_quadrat, by = "id_quadrat_fin")

# Nous avons bien tous les quadrat observés, juste pas tous les individus

str(tab_detection)

# Pour le moment, j'ai un tableau avec tous les individus observés, mais je n'ai pas l'information sur les individus non observés par les observateurs.
# Il me faut, à chaque fois, le nombre de quadrats observés par observateur pour pouvoir calculer le nombre d'observateurs par quadrat.

verification_obs_quadrat <- verification %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  group_by(id_quadrat_fin, observateur) %>% 
  count()

# Ajouter à tableau détection : id_quadrat_fin
tab_detection <- tab_detection %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = "."))

# Vérifier qu'il n'y pas de NA crées
tab_detection[is.na(tab_detection$id_quadrat_fin), ]

# Calculer le nombre d'individus par quadrat
nb_indiv_quadrat <- data_original_obs %>% 
    mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  group_by(id_quadrat_fin) %>% 
  summarise(
    nb_individus = n_distinct(ID_ind),
    .groups = "drop"
  )

# Comparaison du nombre d'individus par quadrat au nombre observé par mes observateurs
difference_ind <- verification_obs_quadrat %>% 
  full_join(nb_indiv_quadrat, by = "id_quadrat_fin")

# Taux de detection par observateur
difference_ind <- difference_ind %>% 
  mutate(detection = n/nb_individus)

# Extraire les identifiants de tous les individus possibles
individus_par_quadrat <- tab_detection %>%
  distinct(id_quadrat_fin, ID_ind)

# Combinaisons de tous les individus possibles avec les observateurs
grille_complete <- difference_ind %>%
  dplyr::select(id_quadrat_fin, observateur) %>%
  distinct() %>%
  left_join(individus_par_quadrat, by = "id_quadrat_fin", relationship = "many-to-many")

# Ajouter les informations de detection dans la grille complete
tab_complet <- grille_complete %>%
  left_join(
    tab_detection %>%
      mutate(detection = 1) %>%
      dplyr::select(id_quadrat_fin, observateur, ID_ind, detection),
    by = c("id_quadrat_fin", "observateur", "ID_ind")
  ) %>%
  mutate(
    detection = ifelse(is.na(detection), 0, detection)
  )

# Vérifier que cela a fonctionné en comparant le nombre de détections calculées avec le nombre de détections par quadrat

tab_complet %>%
  group_by(id_quadrat_fin, observateur) %>%
  summarise(
    n_detectes = sum(detection),
    .groups = "drop"
  ) %>%
  left_join(difference_ind, by = c("id_quadrat_fin", "observateur")) %>% 
  filter(n_detectes != n)

# Ajouter l'information des observateurs au tableau de détection
tab_complet <- tab_complet %>%
  left_join(
    tab_detection,
    by = c("id_quadrat_fin","ID_ind", "observateur")
  )

# Ajouter les informations aux données originales
data_original_obs <- data_original_obs %>% 
    mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = "."))

tab_complet <- tab_complet %>%
  left_join(
    data_original_obs,
    by = c("id_quadrat_fin","ID_ind"),
    suffix = c("_test", "")
  ) %>%
  dplyr::select(
    -ends_with("_test")  # ou l’inverse selon ce que tu veux garder
  ) %>% 
  dplyr::select(id_ind_fin,id_quadrat_fin, ID_quadrat, ID_ind,site, quadrat, marquage, session,observateur, detection, phenologie_verif, phenologie, adequation, adequation_reel, taille)

```

### Joindre des données supplémentaires

Pour la construction des modèles, intégrer l’ensemble des données disponibles est pertinent afin de sélectionner les variables qui constitueront nos modèles. Ainsi, il est possible d’ajouter progressivement des données supplémentaires en utilisant les colonnes communes aux différents tableaux comme repère pour les jointures. Par exemple, ici, nous souhaitons inclure le tableau « recouvrement » contenant les différentes strates.

```{r}
# Extraire la partie quadrat de tab_complet (tout avant le dernier point)
tab_complet <- tab_complet %>%
  mutate(
    ID_Quadrat_clean = str_replace(id_quadrat_fin, "\\.[0-9]+$", "")
  )

# Nettoyer recouvrement pour correspondre au format de tab_complet
recouvrement_clean <- recouvrement %>%
  mutate(
    ID_Quadrat_clean = str_replace_all(ID_Quadrat, "_", ".")
  ) %>%
  dplyr::select(ID_Quadrat_clean, starts_with("S_"))

# Faire le left_join pour ajouter les colonnes S_ au tableau complet
tab_complet <- tab_complet %>%
  left_join(recouvrement_clean, by = "ID_Quadrat_clean") %>% 
  dplyr::select(-ID_Quadrat_clean)

#Vérification histoires de capture
verif_sessions <- tab_complet %>%
  group_by(ID_ind) %>%
  summarise(
    nb_sessions = n_distinct(session),
    sessions = paste(sort(unique(session)), collapse = ","),
    .groups = "drop"
  )

check_sessions <- verif_sessions %>%
  mutate(
    ok_sessions = sessions == "1,2,3"
  )

check_sessions %>%
  filter(!ok_sessions)

```

# --------------------------------------------------

# ANALYSES PRELIMINAIRES

## --------------

Avant de commencer des analyses complexes, difficiles à interpréter ou qui fournissent une compilation des informations, il est important d’étudier chaque variable indépendamment afin d’en expliquer les effets.

# I\_ Analyse générale

## --------------

## I_i Relation taille et phénologie

```{r}

# Mise en forme des données en format long :
# empilement des données de taille et de phénologie
# pour les trois sessions d’observation
data_long <- bind_rows(
  data_original %>% transmute(pheno = phenoS1, taille = tailleS1),
  data_original %>% transmute(pheno = phenoS2, taille = tailleS2),
  data_original %>% transmute(pheno = phenoS3, taille = tailleS3)
)

# Conversion de la variable taille en numérique
# (remplacement des virgules par des points)
# et suppression des valeurs manquantes
data_long <- data_long %>%
  mutate(
    taille = as.numeric(gsub(",", ".", taille))
  ) %>%
  filter(!is.na(taille), !is.na(pheno))

# Ordonnancement des stades phénologiques
# afin de respecter la progression biologique
data_long$pheno <- factor(
  data_long$pheno,
  levels = c("j", "nf", "f", "F", "ff")
)

# Visualisation de la distribution des tailles
# en fonction des stades phénologiques
# (toutes sessions confondues)
ggplot(data = data_long, aes(x = pheno, y = taille)) +
  geom_boxplot() +
  labs(
    x = "Stade phénologique",
    y = "Taille",
    title = "Taille selon le stade phénologique (sessions confondues)"
  ) +
  theme_minimal()

# Test global de significativité
kruskal.test(taille ~ pheno, data = data_long) 
# Hypothèse : il y a au moins une différence significative de taille entre les stades phénologiques. Hypothèse acceptée si p-value < 0.05 

# Comparaisons deux à deux (si le test global est significatif)
pairwise.wilcox.test(
  data_long$taille,
  data_long$pheno,
  p.adjust.method = "BH",
  exact = FALSE
)


# Afficher le tableau propre
data_long %>%
  pairwise_wilcox_test(taille ~ pheno, p.adjust.method = "BH") %>%
  select(group1, group2, p, p.adj)

```

Les tailles diffèrent significativement entre l’ensemble des stades phénologiques (tests de Wilcoxon deux à deux avec correction de Benjamini–Hochberg ; Tableau X). Les stades précoces (j et nf) présentent des différences très marquées avec tous les stades plus avancés (p_adj ≪ 0,001), indiquant une augmentation nette de la taille au cours du développement. Les différences entre les stades tardifs (f, F et ff) restent significatives, bien que plus faibles, suggérant une progression continue de la taille jusqu’aux phases finales du cycle phénologique. Ces résultats confirment une relation étroite entre la taille des individus et leur stade phénologique.

## I_ii Relation recouvrement végétal et site

L’analyse factorielle discriminante (AFD) est une méthode statistique qui permet de déterminer si des groupes prédéfinis peuvent être différenciés à partir de variables explicatives. Elle cherche à identifier les combinaisons de variables qui séparent le mieux ces groupes.

Dans ce travail, l’AFD est utilisée pour tester si les sites étudiés peuvent être distingués en fonction de la structure de la végétation, décrite par les recouvrements des différentes strates (muscinale, herbacée, arbustive et arborescente). L’objectif est donc de vérifier si chaque site présente une signature de recouvrement particulière et d’identifier quelles strates contribuent le plus à cette différenciation.

```{r}
# -------------------------------
# Analyse Factorielle Discriminante (AFD)
# -------------------------------

# -------------------------------
# 1. LDA sur les données originales
# -------------------------------
afd_recouvrement <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = recouvrement
)

# -------------------------------
# 2. Centrage et normalisation des variables
# -------------------------------
newdata <- as.data.frame(scale(recouvrement[, 4:8]))

# On ajoute la variable de groupe (Site) pour l'analyse
newdata$Site <- recouvrement$Site

# -------------------------------
# 3. LDA sur les données centrées-réduites
# -------------------------------
afd2 <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = newdata
)

# -------------------------------
# 4. MANOVA pour tester les différences entre groupes
# -------------------------------
manova_res <- manova(as.matrix(recouvrement[, 4:8]) ~ recouvrement$Site)

# -------------------------------
# 5. Prédiction avec LDA
# -------------------------------
pred <- predict(afd2)
table(Site = recouvrement$Site, Predicted = pred$class)

# -------------------------------
# 6. Validation croisée (jackknife)
# -------------------------------
afd_cv <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = newdata,
  CV = TRUE
)
table(Site = newdata$Site, Predicted = afd_cv$class)

# -------------------------------
# 7. AFD basée sur l'ACP centrée-réduite
# -------------------------------
pca_res <- dudi.pca(recouvrement[, 4:8], scannf = FALSE, nf = 3)
afd3 <- discrimin(pca_res, factor(recouvrement$Site), scannf = FALSE, nf = 3) ## dans le nombre d'axe, indiquer la valeur adéquate dans pca_res$nf

# Exploration des valeurs propres et des coefficients standardisés
afd3$eig
sqrt(afd3$eig / (1 + afd3$eig))

# Projection des variables sur les fonctions discriminantes
# Créer une nouvelle fenêtre graphique (ou plot)
s.arrow(afd3$fa)  

# Projection des individus selon leur groupe
s.class(afd3$li, factor(recouvrement$Site))

#Regarder contribution relative des strates des variables aux axes
afd3$fa # strates
afd3$gc # sites
#A priori strate muscinale et arbustive basse sont les plus importantes
```

Les résultats de l’analyse factorielle discriminante (AFD) permettent de visualiser et d’expliquer les différences de composition végétale entre les sites étudiés.

Les deux graphiques issus de l’AFD illustrent ces différences. Le premier graphique montre la contribution des différentes strates de végétation aux axes discriminants : la longueur et la direction des flèches indiquent quelles strates participent le plus à la séparation des sites. Le second graphique représente la projection des individus regroupés par site : une bonne séparation entre les groupes traduit des différences nettes de recouvrement des strates entre les sites.

Le tableau des coefficients standardisés sur les trois premières fonctions discriminantes (DS1, DS2, DS3) permet de quantifier l’importance relative de chaque strate dans la discrimination des sites. L’interprétation montre que les strates muscinale et arbustive basse ont les coefficients les plus élevés sur les axes principaux (DS1 et DS2), ce qui indique qu’elles jouent un rôle clé dans la différenciation des sites. Les autres strates contribuent moins à la séparation, suggérant que leurs variations sont moins distinctives entre les sites.

Le tableau des coordonnées des sites sur les trois premières fonctions discriminantes montre la position de chaque site dans l’espace discriminant défini par les strates. Sur le premier axe (DS1), Combe Michaut est la plus positive et Vigne au Renard la plus négative, indiquant que ces deux sites sont les plus contrastés en termes de recouvrement des strates discriminantes, notamment muscinale et arbustive basse. Les autres sites se distinguent principalement sur le deuxième axe (DS2), avec Val Clavin très positive et Tête Cendrée haut négative, ce qui reflète des différences spécifiques sur les strates associées à cet axe.

Dans l’ensemble, ces résultats montrent que la structuration de la végétation permet de discriminer partiellement certains sites. Certains sites sont nettement distincts, tandis que d’autres se rapprochent, illustrant des similarités écologiques. L’AFD met ainsi en évidence que les strates muscinale et arbustive basse sont les variables les plus informatives pour expliquer les différences de composition végétale entre les sites.

## --------------

# II\_ Analyse de la variation dans le temps

Dans un premier temps, nous avons étudié la variation des données au cours du temps afin d’obtenir une vision dynamique de leur évolution.

## --------------

## II_i Effet de la session

### Effet de la session sur la taille

```{r}

# Transformer les données en format long
taille_long <- data_original %>%
  dplyr::select(tailleS1, tailleS2, tailleS3) %>%
  pivot_longer(
    cols = everything(),
    names_to = "session",
    values_to = "taille"
  ) %>%
  mutate(
    # remplacer les "," par "." et convertir en numérique
    taille = as.numeric(gsub(",", ".", taille)),
    # renommer les sessions
    session = dplyr::recode(session, "tailleS1"="S1", "tailleS2"="S2", "tailleS3"="S3")
  )

# Calcul de la moyenne, écart-type et IC 95%
taille_stats <- taille_long %>%
  group_by(session) %>%
  summarise(
    mean_taille = mean(taille, na.rm = TRUE),
    sd_taille = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille)),
    .groups = "drop"
  ) %>%
  mutate(
    se = sd_taille / sqrt(n),
    ci_lower = mean_taille - 1.96 * se,
    ci_upper = mean_taille + 1.96 * se
  )

# Histogramme avec IC 95%
ggplot(taille_stats, aes(x = session, y = mean_taille, fill = session)) +
  geom_bar(stat = "identity", width = 0.6) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, color = "black") +
  scale_fill_manual(values = c("S1"="#FF9999", "S2"="#FF4D4D", "S3"="#CC0000")) +
  labs(
    title = "Taille moyenne par session",
    x = "Session",
    y = "Taille moyenne",
    fill = "Session"
  ) +
  theme_minimal()


# Test global de significativité
kruskal.test(taille ~ session, data = taille_long)
# Hypothèse : il y a au moins une différence significative de taille entre les sessions. Hypothèse acceptée si p-value < 0.05 

# Comparaisons deux à deux (si le test global est significatif)
taille_long %>%
  pairwise_wilcox_test(taille ~ session, p.adjust.method = "BH") %>%
  select(group1, group2, p, p.adj)


```

Le graphique montre la taille moyenne des individus par session avec les barres d’erreur représentant l’intervalle de confiance à 95 %. On observe une augmentation progressive de la taille : la moyenne passe de S1 (\~13,7) à S2 (\~16,9) puis à S3 (\~17,3). L'augmentation est statistiquement significative.

### Effet de la session sur la phénologie

```{r}

# Transformer les données en format long : session = S1, S2, S3
pheno_long <- data_original %>%
  dplyr::select(phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = everything(),
    names_to = "session",
    values_to = "pheno"
  ) %>%
  # Remplacer NA par un label pour garder comme modalité
  dplyr::mutate(pheno = ifelse(is.na(pheno), "NA", as.character(pheno))) %>%
  # Renommer les sessions plus simplement
  mutate(session = dplyr::recode(session,
                          "phenoS1" = "S1",
                          "phenoS2" = "S2",
                          "phenoS3" = "S3"))

# Calcul des effectifs par session et type phénologique
pheno_stats <- pheno_long %>%
  group_by(session, pheno) %>%
  summarise(
    n = n(),
    .groups = "drop"
  ) %>%
  mutate(
    # IC 95% approximatif (Poisson)
    se = sqrt(n),
    ci_lower = pmax(n - 1.96 * se, 0),
    ci_upper = n + 1.96 * se
  )

# Définir l'ordre des phénos
pheno_stats$pheno <- factor(pheno_stats$pheno, levels = c("j", "nf", "f", "ff", "F", "NA"))

# Graphique avec barres côte à côte et IC 95%
ggplot(pheno_stats, aes(x = session, y = n, fill = pheno)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
                position = position_dodge(width = 0.8), width = 0.2, color = "black") +
  scale_fill_manual(values = c(
    "j"  = "#FF9999",
    "nf" = "#FF4D4D",
    "f"  = "#CC0000",
    "ff" = "#990000",
    "F"  = "#660000",
    "NA" = "#000000"  # noir pur pour NA
  )) +
  labs(
    title = "Effet de la session (S1, S2, S3) sur la phénologie",
    x = "Session",
    y = "Nombre d'individus",
    fill = "Type phénologique"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Le graphique montre une progression claire du développement phénologique au fil des sessions : début majoritairement jeunes, floraison qui commence à S2 principalement, diminution des données manquantes et des jeunes. La diminution des NA pourrait être dûe à une meilleure détectabilité des individus matures (nous vérifirons cette hpyothèse dans les analyses suivantes). La session 3 montre l'apparition de fleurs fannées, et de fruits.

## --------------

# III\_ Analyse de la variation dans l'espace

## --------------

## III_i Effet du site

### Effet du site sur la taille

Taille \~ site

```{r}

# Transformer les données en format long pour toutes les tailles
taille_long <- data_original %>%
  dplyr::select(site, tailleS1, tailleS2, tailleS3) %>%
  pivot_longer(
    cols = c(tailleS1, tailleS2, tailleS3),
    names_to = "session",
    values_to = "taille"
  ) %>%
  mutate(
    # remplacer les "," par "." et convertir en numérique
    taille = as.numeric(gsub(",", ".", taille))
  )

# Calcul de la taille moyenne par site
taille_stats <- taille_long %>%
  group_by(site) %>%
  summarise(
    mean_taille = mean(taille, na.rm = TRUE),
    sd_taille = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille)),
    .groups = "drop"
  ) %>%
  mutate(
    se = sd_taille / sqrt(n),
    ci_lower = mean_taille - 1.96 * se,
    ci_upper = mean_taille + 1.96 * se
  )

# Histogramme avec IC 95%
ggplot(taille_stats, aes(x = site, y = mean_taille)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, color = "black") +
  labs(
    title = "Taille moyenne par site",
    x = "Site",
    y = "Taille moyenne",
    fill = "Site"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

```

### Effet du site sur la taille selon la session

Taille \~ site + session

```{r}

# Assurer que les colonnes de taille sont numériques
data_original <- data_original %>%
  mutate(
    tailleS1 = as.numeric(gsub(",", ".", tailleS1)),
    tailleS2 = as.numeric(gsub(",", ".", tailleS2)),
    tailleS3 = as.numeric(gsub(",", ".", tailleS3))
  )

# Calcul des statistiques pour chaque taille
stats_long <- data_original %>%
  pivot_longer(cols = c(tailleS1, tailleS2, tailleS3),
               names_to = "taille_type",
               values_to = "taille") %>%
  group_by(site, taille_type) %>%
  summarise(
    mean = mean(taille, na.rm = TRUE),
    sd = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille))
  ) %>%
  mutate(
    se = sd / sqrt(n),
    ci95 = se * qt(0.975, df = n - 1)
  )

# Définir des couleurs rouges avec différentes opacités
red_colors <- c("tailleS1" = "#FF6666",  # clair
                "tailleS2" = "#FF3333",  # moyen
                "tailleS3" = "#CC0000")  # foncé

# Graphique avec les trois tailles côte à côte par site
ggplot(stats_long, aes(x = site, y = mean, fill = taille_type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = mean - ci95, ymax = mean + ci95),
                position = position_dodge(width = 0.8), width = 0.2) +
  scale_fill_manual(values = red_colors) +
  labs(
    title = "Taille moyenne par site avec IC 95%",
    y = "Taille moyenne",
    x = "Site",
    fill = "Type de taille"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Effet du site sur la phénologie

phénologie \~ site

```{r}

# Transformer les phénos en format long en gardant les NA
pheno_long <- data_original %>%
  dplyr::select(site, phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = c(phenoS1, phenoS2, phenoS3),
    names_to = "pheno_type",
    values_to = "pheno"
  ) %>%
  # Remplacer NA par un label pour garder comme modalité
  mutate(pheno = ifelse(is.na(pheno), "NA", as.character(pheno)))

# Calcul des effectifs par site et type phénologique
pheno_stats <- pheno_long %>%
  group_by(site, pheno) %>%
  summarise(n = n(), .groups = "drop") %>%
  complete(site, pheno, fill = list(n = 0)) %>%  # inclure les combinaisons manquantes
  mutate(
    # IC 95% approximatif pour comptages (Poisson)
    se = sqrt(n),
    ci_lower = pmax(n - 1.96 * se, 0),
    ci_upper = n + 1.96 * se
  )

# Définir l'ordre des phénos
pheno_stats$pheno <- factor(pheno_stats$pheno, levels = c("j", "nf", "f", "ff", "F", "NA"))

# Graphique avec barres côte à côte et IC 95%
ggplot(pheno_stats, aes(x = site, y = n, fill = pheno)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
                position = position_dodge(width = 0.8), width = 0.2, color = "black") +
  scale_fill_manual(values = c(
    "j"  = "#FF9999",
    "nf" = "#FF4D4D",
    "f"  = "#CC0000",
    "ff" = "#990000",
    "F"  = "#660000",
    "NA" = "#000000"  # noir pur pour NA
  )) +
  labs(
    title = "Effet du site sur la phénologie",
    x = "Site",
    y = "Nombre d'individus",
    fill = "Type phénologique"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## --------------

## III_ii Effet de la strate

### Effet de la strate sur la taille

Taille \~ strate

```{r}

# Joindre les données par ID_Quadrat
data_joined <- data_original %>%
  left_join(recouvrement, by = c("ID_quadrat" = "ID_Quadrat"))

# Calcul de la taille moyenne par individu
data_joined <- data_joined %>%
  mutate(
    tailleS1 = as.numeric(gsub(",", ".", tailleS1)),
    tailleS2 = as.numeric(gsub(",", ".", tailleS2)),
    tailleS3 = as.numeric(gsub(",", ".", tailleS3)),
    taille_moyenne = rowMeans(dplyr::select(., tailleS1, tailleS2, tailleS3), na.rm = TRUE)
  )

# Transformer les strates en format long pour facettes
recouvrement_long <- data_joined %>%
  pivot_longer(
    cols = c(S_muscinale, S_herbacee, S_arbustive_basse, S_arbustive_haute, S_arborescente),
    names_to = "strate",
    values_to = "recouvrement"
  )

# Formule pour afficher R² et p-value
eqn <- ggpmisc::stat_poly_eq(
  aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")),
  formula = y ~ x,
  parse = TRUE,
  label.x.npc = "right",
  label.y.npc = 0.1,
  size = 3
)

# Graphique par strate avec couleurs modifiées
ggplot(recouvrement_long, aes(x = recouvrement, y = taille_moyenne)) +
  geom_point(alpha = 0.7, color = "black") +  # points noirs
  geom_smooth(method = "lm", se = TRUE, color = "#CC0000", fill = "#FF9999") +  # ligne rouge foncé, IC rouge clair
  eqn +
  facet_wrap(~ strate, scales = "free_x") +
  labs(
    title = "Taille moyenne en fonction du recouvrement végétal par strate",
    x = "Recouvrement (%)",
    y = "Taille moyenne"
  ) +
  theme_minimal()
```

### Effet de la strate sur la phénologie

phénologie \~ strate

```{r}

# Phénologie en format long
pheno_long <- data_original %>%
  dplyr::select(ID_quadrat, phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = starts_with("pheno"),
    names_to = "session",
    values_to = "pheno"
  ) %>%
  mutate(pheno = ifelse(is.na(pheno), "NA", pheno))

# Tableau de contingence (fréquences)
pheno_tab <- pheno_long %>%
  group_by(ID_quadrat, pheno) %>%
  summarise(n = n(), .groups = "drop") %>%
  pivot_wider(
    names_from = pheno,
    values_from = n,
    values_fill = 0
  )

# Vérification
str(pheno_tab)

data_rda <- pheno_tab %>%
  left_join(recouvrement, by = c("ID_quadrat" = "ID_Quadrat")) %>% dplyr::select(-"NA")

# Variables explicatives (recouvrement)
X <- data_rda %>%
  dplyr::select(
    S_muscinale,
    S_herbacee,
    S_arbustive_basse,
    S_arbustive_haute,
    S_arborescente
  )

Y <- data_rda %>%
  dplyr::select(j, nf, f, ff, F)

# Hellinger (très recommandé)
Y_hel <- decostand(Y, method = "hellinger")

X <- data_rda %>%
  dplyr::select(
    S_muscinale,
    S_herbacee,
    S_arbustive_basse,
    S_arbustive_haute,
    S_arborescente
  )

rda_pheno <- rda(Y_hel ~ ., data = X)

plot(rda_pheno, scaling = 2)

a_1<- anova(rda_pheno)          # effet global du recouvrement
a_2<-anova(rda_pheno, by="term") # effet de chaque strate
a_3<- anova(rda_pheno, by="axis") # axes significatifs


```

La RDA montre que le recouvrement végétal n’explique pas significativement la variation globale de la phénologie (p = 0.146). Toutefois, le recouvrement herbacé et arbustif bas présentent des effets proches du seuil de significativité (p \< 0.1). Les strates hautes (arbustive haute et arborescente) n’influencent pas la phénologie. Ces résultats suggèrent que la phénologie est principalement associée à la structure végétale proche du sol.

## --------------

# IV\_ Niveau des observateurs

## Adéquation et fiabilité des observateurs

```{r}

# ------------------------------------------------------------
# 1. Taux d’erreur d’adéquation par observateur
# ------------------------------------------------------------

verification3 <- verification %>% 
  group_by(observateur) %>% 
  count(adequation) %>% 
  pivot_wider(
    names_from = adequation,
    values_from = n,
    names_glue = "{ifelse(adequation == 1, 'id_valide', 'id_fausse')}"
  ) %>% 
  replace_na(list(
    id_valide = 0,
    id_fausse = 0
  )) %>% 
  mutate(
    id_total = id_valide + id_fausse,
    tx_erreur = id_fausse / id_total
  )

verification3 <- verification3 %>%
  left_join(
    experience %>% dplyr::select(Observateur, sexe),
    by = c("observateur" = "Observateur")
  )

# Vérification des adéquations manquantes
verification %>% 
  filter(is.na(adequation))

# ------------------------------------------------------------
# 2. Score moyen d’auto-évaluation (A à E)
# ------------------------------------------------------------

experience <- experience %>%
  mutate(
    score_moyen = rowMeans(across(A:E), na.rm = TRUE),
    fiabilite = score_moyen / 10,
    risque_erreur = 1 - fiabilite
  )

# Variabilité intra-observateur
experience <- experience %>%
  rowwise() %>%
  mutate(ecart_type = sd(c_across(A:E), na.rm = TRUE)) %>%
  ungroup()

# Classement par risque d’erreur
experience <- experience %>%
  arrange(desc(risque_erreur)) %>%
  mutate(ID.observateur = factor(ID.observateur, levels = ID.observateur))

# ------------------------------------------------------------
# 3. Fusion auto-évaluation / adéquation réelle
# ------------------------------------------------------------

experience2 <- experience %>% 
  inner_join(
    verification3,
    by = join_by("Observateur" == "observateur")
  )


# ------------------------------------------------------------
# 4. Taux de détection réel par observateur
# ------------------------------------------------------------

tx_erreur <- tab_complet %>% 
  group_by(observateur) %>% 
  summarise(
    nb_ind = n(),
    nb_detect = sum(detection, na.rm = TRUE),
    tx_detect = nb_detect / nb_ind
  )

tx_erreur_fin <- experience2 %>% 
  inner_join(
    tx_erreur,
    by = join_by("Observateur" == "observateur")
  )

# ------------------------------------------------------------
# 5. Graphiques
# ------------------------------------------------------------

```

### Erreur d’attribution phénologique vs non-détection

```{r}

ggplot(tx_erreur_fin, aes(x = tx_erreur, y = 1 - tx_detect)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre taux d'erreur d'attribution et non-détection",
    x = "Taux d'erreur d'attribution de la phénologie",
    y = "Taux de non-détection",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Autonotation vs erreur d'attribution phénologique

```{r}
ggplot(tx_erreur_fin, aes(x = risque_erreur, y = tx_erreur)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre risque d'erreur (auto-évaluation) et erreur d'attribution",
    x = "Risque d'erreur basé sur l'auto-évaluation",
    y = "Taux d'erreur d'attribution de la phénologie",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Autonotation vs non-détection

```{r}
ggplot(tx_erreur_fin, aes(x = risque_erreur, y = 1 - tx_detect)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre risque d'erreur (auto-évaluation) et non-détection",
    x = "Risque d'erreur basé sur l'auto-évaluation",
    y = "Taux de non-détection",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Analyses complémentaires

```{r}
# ------------------------------------------------------------
# Visualisation des 3 axes en 3D 
# ------------------------------------------------------------

# Graphique 3D interactif avec taille fixe
plot_ly(
  tx_erreur_fin,
  x = ~tx_erreur,
  y = ~risque_erreur,
  z = ~ (1 - tx_detect),
  type = "scatter3d",
  mode = "markers+text",
  text = ~Observateur,
  textposition = "top center",
  marker = list(
    size = 5,  # taille fixe pour tous les points
    color = ~ifelse(sexe.x == "f", "#E41A1C", "#377EB8"),
    opacity = 0.8
  ),
  hovertemplate = paste(
    "<b>%{text}</b><br>",
    "Sexe: %{customdata[0]}<br>",
    "Taux erreur: %{x}<br>",
    "Risque auto: %{y}<br>",
    "Non-détection: %{z}<br>",
    "<extra></extra>"
  ),
  customdata = tx_erreur_fin[, c("sexe.x")]
) %>%
  layout(
    scene = list(
      xaxis = list(title = "Taux d'erreur d'attribution"),
      yaxis = list(title = "Risque d'erreur (auto-évaluation)"),
      zaxis = list(title = "Taux de non-détection")
    ),
    title = "Graphique 3D interactif des erreurs et non-détection"
  )

# ------------------------------------------------------------
# Corrélation
# ------------------------------------------------------------

cor.test(
  tx_erreur_fin$tx_detect,
  tx_erreur_fin$tx_erreur,
  method = "spearman"
)

# ------------------------------------------------------------
# Modèles linéaires
# ------------------------------------------------------------

model1_autonotation <- lm(
  risque_erreur ~ tx_erreur + tx_detect,
  data = tx_erreur_fin
)

model2_autonotation <- lm(
  risque_erreur ~ tx_detect,
  data = tx_erreur_fin
)

model3_autonotation <- lm(
  risque_erreur ~ tx_erreur,
  data = tx_erreur_fin
)

summary(model1_autonotation)
anova(model1_autonotation)

summary(model2_autonotation)
anova(model2_autonotation)

summary(model3_autonotation)
anova(model3_autonotation)

# ------------------------------------------------------------
# Comparaison des modèles
# ------------------------------------------------------------

AIC(model1_autonotation, model2_autonotation, model3_autonotation)

```

# --------------------------------------------------

# PROBABILITE DE DETECTION

## --------------

## V_i GLM

```{r}
# On a plusieurs strates et on veut seulement une covariable "recouvrement". On utilise donc une ACP pour avec l'inertie sur PC1.

# Extraire juste les colonnes numériques pour la PCA
recouvrement_num <- tab_complet %>%
  ungroup() %>%  # enlever le grouping
  dplyr::select(S_muscinale:S_arborescente) %>%
  mutate(across(everything(), as.numeric)) %>%
  as.data.frame()

# Vérifier
str(recouvrement_num)

pca <- prcomp(recouvrement_num, scale. = TRUE)
acp1 <- dudi.pca(recouvrement_num, scale=T, center=T, scannf=F, nf=4)
# Ajouter la première composante à ton tableau original
tab_complet$recouvrement_PC1 <- pca$x[,1]
tab_complet$recouvrement_PC1v2 <- acp1$li[,1]
#Calcul des % de chaque axe :
pc<-round(acp1$eig/sum(acp1$eig)*100,2)
pc

# % cumulés
cumsum(pc) 

#visualisation sur un graph
barplot(acp1$eig)

###Graphique de l'ACP####
s.corcircle(acp1$co, xax=1, yax=2, box = F, clabel = 0.5) 

# GLM

glm_model <- glmer(
  detection ~ recouvrement_PC1 + site + session + taille + phenologie_verif +
    (1 | ID_ind),
  data = tab_complet,
  family = binomial
)

table(tab_complet$detection)

tab_complet <- tab_complet %>%
  mutate(
    site = factor(site),
    session = factor(session),
    phenologie_verif = factor(phenologie_verif)
  )

tab_complet <- tab_complet %>%
  mutate(
    phenologie_grp = case_when(
      phenologie_verif %in% c("fleur", "fleurs_fanees", "fruit") ~ "reproductif",
      phenologie_verif %in% c("juv", "non_fleuri") ~ "vegetatif",
      TRUE ~ "0"
    ),
    phenologie_grp = factor(phenologie_grp)
  )

glm_model <- glmer(
  detection ~ recouvrement_PC1 + phenologie_grp +
    (1 | ID_ind),
  data = tab_complet,
  family = binomial,
  control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))
)
table(tab_complet$site, tab_complet$session)
table(tab_complet$phenologie_verif, tab_complet$session)

table(tab_complet$ID_ind)

summary(glm_model)       # coefficients, significativité
anova(glm_model, test="Chisq")

```

### Sélection de modèles

```{r}

# # Autoriser MuMIn à travailler avec glmer
# options(na.action = "na.fail")
# 
# #modèle complet
# glm_model <- glmer(
#   detection ~ recouvrement_PC1 + site + session + taille + phenologie_verif +
#     (1 | ID_ind) + (1 | id_quadrat_fin),
#   data = tab_complet,
#   family = binomial
# )
# 
# # Sélection de modèle (toutes combinaisons de variables fixes)
# model_set <- dredge(glm_model, trace = TRUE)
# 
# # Afficher les modèles triés par AICc
# model_set
# 
# # Optionnel : extraire les meilleurs modèles avec delta AICc < 2
# best_models <- get.models(model_set, subset = delta < 2)
# 
# # Afficher le résumé du meilleur modèle
# summary(best_models[[1]]) 

```

# --------------------------------------------------

# CMR

```{r}
unique(tab_complet$phenologie_verif)
#Transformer lignes phenologie ayant des NA en 0
tab_complet <- tab_complet %>%
  mutate(
    phenologie_verif = replace_na(phenologie_verif, "0")
  )

#Faire la même chose avec les tailles
tab_complet <- tab_complet %>%
  mutate(
    taille = as.numeric(gsub(",", ".", taille)),
    taille = replace_na(taille, 0)
  )

#Regarder le nombre d'observateurs par quadra
tab_obs <- tab_complet %>% 
  group_by(id_quadrat_fin, observateur) %>% 
  summarise(n = 1, .groups = "drop") %>% 
  ungroup()

#Regarder le nombre de quadra observés par observateur
tab_obs2 <- tab_obs %>% 
  group_by(observateur) %>% 
  summarise(nb_quadra = n()) %>% 
  arrange(desc(nb_quadra))
  
#Regarder le nombre d'observations par quadra
tab_obs_tot <- tab_obs %>% 
  group_by(id_quadrat_fin) %>% 
  summarise(nb_obs = n()) %>% 
  ungroup()

#Regarder pourcentages d'observations
nb_obs <- tab_obs_tot %>% 
  count(nb_obs) %>% 
  mutate(pourcentage = round((n * 100) / sum(n), 2))

nb_obs
#A priori seulement 7% des quadra avec moins de 5 observateurs (6 quadra sur 81 quadra) donc on garde 5 observateurs comme valeur minimale

#regarder si j'ai des sessions qui vont disparaître avec cette méthode :
enlever <- tab_obs_tot %>% 
  filter(nb_obs <5)
enlever
#quadra à enlever :
# TCb.Q9.2
# TCb.Q7.2
# CM.Q7.2
Qenlever <- c("TCb.Q9", "TCb.Q7", "CM.Q7")

#extraire informations quadra avec 5 et 6 obs
tab_obs_tot_5obs <- tab_obs_tot %>% 
  filter(nb_obs == 5)

tab_obs_tot_6obs <- tab_obs_tot %>% 
  filter(nb_obs == 6)

#Transvaser ces infos dans tableau complet
tab_complet_5obs <- tab_complet %>% 
  semi_join(tab_obs_tot_5obs, by = "id_quadrat_fin")

tab_complet_6obs <- tab_complet %>% 
  semi_join(tab_obs_tot_6obs, by = "id_quadrat_fin")

#Pour données avec 6 obs par quadrat il va falloir enlever un obs en enlevant en fonction de nb obs décroissant des observateurs
#Extraire nb obs par observateur
tab_complet_5obs <- tab_complet_5obs %>%
  left_join(tab_obs2, by = "observateur")

tab_tmp <- tab_complet_6obs %>%
  left_join(tab_obs2, by = "observateur")

#Garder 5 observations par individu/session/quadra/site
tab_complet_5obs_6 <- tab_tmp %>%
  group_by(id_ind_fin) %>%
  slice_max(nb_quadra, n = 5, with_ties = FALSE) %>%
  ungroup()

#Vérification si nombre de lignes semble bon
nrow(tab_complet_6obs) - (nrow(tab_complet_6obs)/6)
nrow(tab_complet_5obs_6)

#Fusion des deux tableaux 5 obs et 5obs issu de 6obs
tab_complet_final <- rbind(tab_complet_5obs, tab_complet_5obs_6)
ind_av_filtrage <- nrow(tab_complet_final)

#Enlever les trois quadra ayant été partiellement supprimés
tab_complet_final <- tab_complet_final %>% 
  filter(!ID_quadrat %in% c("TCb.Q9","TCb.Q7", "CM.Q7"))
ind_ap_filtrage <- nrow(tab_complet_final)
#pourcentage indiv perdus :
(1-(ind_ap_filtrage/ind_av_filtrage))*100

#Vérification histoires de capture
verif_sessions <- tab_complet_final %>%
  group_by(ID_ind) %>%
  summarise(
    nb_sessions = n_distinct(session),
    sessions = paste(sort(unique(session)), collapse = ","),
    .groups = "drop"
  )

check_sessions <- verif_sessions %>%
  mutate(
    ok_sessions = sessions == "1,2,3"
  )

check_sessions %>%
  filter(!ok_sessions)



```

#RMARK 

```{r}

# ---------------------------------------------------------
# 2. Résumer par individu × session (une ligne par ID_ind × session)
# ---------------------------------------------------------
tab_sess <- tab_complet_final %>%
  mutate(session = as.integer(session)) %>%
  group_by(ID_ind, session) %>%
  summarise(
    detection = ifelse(all(is.na(detection)), NA_integer_, max(as.integer(detection), na.rm = TRUE)),
    phenologie = {
      ph = phenologie[!is.na(phenologie)]
      if(length(ph) == 0) NA_character_ else ph[1]
    },
    taille = mean(taille, na.rm = TRUE),
    recouvrement = mean(recouvrement_PC1, na.rm = TRUE),
    site = first(site)
  ) %>% ungroup()

# contrôle
table(tab_sess$session, useNA = "ifany")
head(tab_sess)

# ---------------------------------------------------------
# 3. Construire les historiques ch par individu et covariables individuelles
# ---------------------------------------------------------
hist_by_id <- tab_sess %>%
  arrange(ID_ind, session) %>%
  group_by(ID_ind) %>%
  summarise(
    ch = paste0(detection, collapse = ""),
    site = first(site),
    taille = mean(taille, na.rm = TRUE),
    recouv = mean(recouvrement, na.rm = TRUE)
  ) %>% ungroup()

# retirer historiques NA et "000" (jamais vus)
n_sessions <- length(unique(tab_sess$session))
zero_ch <- paste(rep(0, n_sessions), collapse = "")
histories_clean <- hist_by_id %>%
  filter(!is.na(ch)) %>%
  filter(ch != zero_ch)

# vérifier que tous les ch ont la bonne longueur
table(nchar(histories_clean$ch))

# ---------------------------------------------------------
# 4. Formatage des covariables individuelles et centrage
# ---------------------------------------------------------
histories_clean <- histories_clean %>%
  mutate(
    site = factor(site),
    taille_c = as.numeric(scale(taille, center = TRUE, scale = FALSE)),
    recouv_c = as.numeric(scale(recouv, center = TRUE, scale = FALSE))
  )

# ---------------------------------------------------------
# 5. Construire la table time varying pour phenologie (ID_ind × session)
# ---------------------------------------------------------
tv_pheno <- tab_sess %>%
  select(ID_ind, session, phenologie) %>%
  mutate(phenologie = as.character(phenologie)) %>%
  arrange(ID_ind, session)

# compléter la grille si nécessaire (garantir une ligne par ID_ind × session)
ids <- unique(tv_pheno$ID_ind)
sessions <- sort(unique(tv_pheno$session))
grid <- expand.grid(ID_ind = ids, session = sessions, stringsAsFactors = FALSE)
tv_pheno_full <- grid %>%
  left_join(tv_pheno, by = c("ID_ind", "session")) %>%
  arrange(ID_ind, session)

# ---------------------------------------------------------
# 6. Préparer les données pour RMark
# ---------------------------------------------------------
histories_for_mark <- histories_clean %>%
  rename(ID = ID_ind) %>%
  select(ID, ch, site, taille_c, recouv_c)

processed <- process.data(histories_for_mark, model = "CJS", groups = c("site"))
ddl <- make.design.data(processed)

# ---------------------------------------------------------
# 7. Injecter phenologie dans ddl pour p et/ou Phi (time varying)
# ---------------------------------------------------------
# créer clés pour matcher
key_tv <- paste(tv_pheno_full$ID_ind, tv_pheno_full$session, sep = "_")
key_ddl_p <- paste(ddl$p$ID, ddl$p$time, sep = "_")
ddl$p$phenologie <- tv_pheno_full$phenologie[match(key_ddl_p, key_tv)]

# si tu veux phenologie pour Phi (survie entre t et t+1)
key_ddl_Phi <- paste(ddl$Phi$ID, ddl$Phi$time, sep = "_")
ddl$Phi$phenologie <- tv_pheno_full$phenologie[match(key_ddl_Phi, key_tv)]

# contrôle des NA éventuels
table(ddl$p$phenologie, useNA = "ifany")
table(ddl$Phi$phenologie, useNA = "ifany")

# ---------------------------------------------------------
# 8. Jeu de modèles candidats
# ---------------------------------------------------------
models <- list()

models$null <- mark(processed, ddl,
                    model.parameters = list(
                      Phi = list(formula = ~1),
                      p   = list(formula = ~1)
                    ))

models$time <- mark(processed, ddl,
                    model.parameters = list(
                      Phi = list(formula = ~time),
                      p   = list(formula = ~1)
                    ))

models$site <- mark(processed, ddl,
                    model.parameters = list(
                      Phi = list(formula = ~site),
                      p   = list(formula = ~1)
                    ))

models$taille <- mark(processed, ddl,
                      model.parameters = list(
                        Phi = list(formula = ~taille_c),
                        p   = list(formula = ~1)
                      ))

models$pheno_p <- mark(processed, ddl,
                       model.parameters = list(
                         Phi = list(formula = ~1),
                         p   = list(formula = ~phenologie)
                       ))

models$comb <- mark(processed, ddl,
                    model.parameters = list(
                      Phi = list(formula = ~site + taille_c),
                      p   = list(formula = ~phenologie)
                    ))

models$int <- mark(processed, ddl,
                   model.parameters = list(
                     Phi = list(formula = ~site * taille_c),
                     p   = list(formula = ~phenologie)
                   ))

# ---------------------------------------------------------
# 9. Comparaison des modèles et sélection
# ---------------------------------------------------------
model_list <- unlist(models, recursive = FALSE)
mt <- model.table(model_list, use.lnl = FALSE)
print(mt)

# ---------------------------------------------------------
# 10. Résultats du meilleur modèle et prédictions exemples
# ---------------------------------------------------------
best_name <- rownames(mt)[1]
best_model <- model_list[[best_name]]
cat("Meilleur modèle selon AICc :", best_name, "\n")
summary(best_model)

# prédiction Phi en fonction de taille pour le premier site
newdata <- data.frame(
  taille_c = seq(min(histories_for_mark$taille_c, na.rm = TRUE),
                 max(histories_for_mark$taille_c, na.rm = TRUE), length = 50),
  site = factor(levels(histories_for_mark$site)[1], levels = levels(histories_for_mark$site))
)
pred_phi <- predict(best_model, type = "Phi", newdata = newdata)
plot_df <- data.frame(taille_c = newdata$taille_c,
                      estimate = pred_phi$estimate,
                      lcl = pred_phi$lcl,
                      ucl = pred_phi$ucl)

ggplot(plot_df, aes(x = taille_c, y = estimate)) +
  geom_line() +
  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.2) +
  labs(x = "Taille centrée", y = "Survie apparente Phi") +
  theme_minimal()

```

## --------------

## VII_iAnalyse des transitions phénologiques avec et sans MARK ###VII_i.i Toutes transitions

```{r}
# -------------------------------
# 1. Charger les données
# -------------------------------
data<- data_original

# -------------------------------
# 2. Préparer les données phénologiques
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS1, phenoS2, phenoS3) %>%
  mutate(
    phenoS1 = phenology_codes[phenoS1],
    phenoS2 = phenology_codes[phenoS2],
    phenoS3 = phenology_codes[phenoS3]
  )

# Supprimer les individus avec NA dans phenoS1, phenoS2 ou phenoS3
phenology_data_numeric <- phenology_data_numeric %>%
  filter(!is.na(phenoS1) & !is.na(phenoS2) & !is.na(phenoS3))

# -------------------------------
# 3. Calcul empirique des transitions 1 → 2 → 3
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS1, phenoS2, phenoS3),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Calculer les transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Créer le champ "ch" pour MARK
# -------------------------------
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS1, phenoS2, phenoS3))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 3))

# -------------------------------
# 6. Préparer les données pour RMark
# -------------------------------
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1", "2", "3", "4", "5")
)

ms_ddl <- make.design.data(ms_data)

# -------------------------------
# 7. Modèle Multistrata avec RMark
# -------------------------------
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

### VII_i.ii Transitions session 1 → 2

```{r}
###MARK Session 1-2 ----

# -------------------------------
# 1. Charger les données
# -------------------------------
data <- data_original

# -------------------------------
# 2. Préparer les données phénologiques (sessions 1 et 2)
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS1, phenoS2) %>%
  mutate(
    phenoS1 = as.character(phenology_codes[phenoS1]),
    phenoS2 = as.character(phenology_codes[phenoS2])
  ) %>%
  # Supprimer les individus avec NA dans phenoS1 ou phenoS2
  filter(!is.na(phenoS1) & !is.na(phenoS2))

# -------------------------------
# 3. Calcul empirique des transitions 1 → 2
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS1, phenoS2),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation des transitions avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Partie RMark
# -------------------------------
# Créer le champ "ch" pour MARK
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS1, phenoS2))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 2))

# Préparer les données pour RMark
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1","2","3","4","5")
)

ms_ddl <- make.design.data(ms_data)

# Modèle Multistrata avec RMark
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

### VII_i.iii Transitions session 2 → 3

```{r}
###MARK Session 2-3 ----

# -------------------------------
# 1. Charger les données
# -------------------------------
data <- data_original

# -------------------------------
# 2. Préparer les données phénologiques (sessions 2 et 3)
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS2, phenoS3) %>%
  mutate(
    phenoS2 = as.character(phenology_codes[phenoS2]),
    phenoS3 = as.character(phenology_codes[phenoS3])
  ) %>%
  # Supprimer les individus avec NA dans phenoS2 ou phenoS3
  filter(!is.na(phenoS2) & !is.na(phenoS3))

# -------------------------------
# 3. Calcul empirique des transitions 2 → 3
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS2, phenoS3),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation des transitions avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Partie RMark
# -------------------------------
# Créer le champ "ch" pour MARK
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS2, phenoS3))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 2))

# Préparer les données pour RMark
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1","2","3","4","5")
)

ms_ddl <- make.design.data(ms_data)

# Modèle Multistrata avec RMark
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

## --------------

