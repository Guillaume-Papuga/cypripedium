---
title: "Rédaction_V2"
format: html
editor: visual
execute-dir: project
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE, 
  echo = FALSE
)
#ce code permet de n'afficher aucun message parasite ni les warnings. 

```

# -------------------------------

# INTRODUCTION

# --------------------------------------------------

# Chargement des packages

```{r, message = FALSE, warning = FALSE}
library(MuMIn)        # sélection de modèles, AICc, multimodel inference

library(tidyverse)

library(ggalluvial)   # diagrammes alluviaux (transitions, flux entre catégories)
library(lme4) #modèle mixtes

library(emmeans) #prédictions de modèles linéaires

library(stats)
library(plotly)

library(ggrepel)      # étiquettes non superposées sur graphiques ggplot
library(ggpmisc)      # annotations statistiques (équations, R²) sur ggplot

library(MASS)         # outils statistiques avancés (LDA, glm, distributions)
library(ade4)         # analyses multivariées écologiques (PCA, CA, RLQ)

library(tidyr)
library(dplyr)
library(stringr)

library(vegan)        # écologie numérique : RDA, CCA, NMDS, PERMANOVA
library(car)          # diagnostics de modèles (VIF, tests de type II/III)

library(RMark)        # modèles capture-marquage-recapture (interface MARK)
library(DiagrammeR)   # graphes et diagrammes (flowcharts, DAG)
library(rstatix)      # Tables propres
library(nnet)         # Régression multionomiale
library(kableExtra)   # Tableau propre

```

# --------------------------------------------------

# Ouverture des tableaux de données

## --------------

Les tableaux sont ouverts chacun de leur côté afin de pouvoir réaliser les analyses ci-dessous indépendamment, dans le cas où toutes les données n’ont pas été entièrement relevées.

### Tableau : recouvrement

Ce tableau donne pour chaque quadrat du protocole un recouvrement de 1 à 10 de différentes strates végétales, initialement exprimé en % 10 par 10 : - strate muscinale - strate herbacée \< à 1m de hauteur - strate arbustive basse entre 1 et 3m de hauteur - strate arbustive haute entre 3 et 7m de hauteur - strate arborescente \> à 7m de hauteur

```{r, message=FALSE, echo=FALSE}
recouvrement <- read.csv("data/raw/Recouvrement VF.csv",sep = ";")
#Premières lignes du tableau pour lecteur
head(recouvrement)
```

### Tableau : détections individuelles

Ce tableau donne la mesure d'un individu par un observateur. Celui-ci informe sur le stade phénologique de l'individu qu'il observe. Une ligne du tableau correspond à un individu, son appartenance à un site, un quadrat et une session. La variable marquage correspond au numéro de l'individu.

```{r, message=FALSE, echo=FALSE}
verification <- read.csv("data/raw/detections_individuelles_verifsTC+LD_18dec.csv", sep = ";")

# Certains noms des sites ont des espaces invisibles, correction :
verification$site <- trimws(verification$site)

#Premières lignes du tableau pour lecteur
head(verification)
```

### Tableau : taille et phénologie vérifiées

Ce tableau donne la mesure des individus par les opérateurs de la manip. Pour chaque individu la phénologie et la taille ont été renseigné par session, le nombre de fleurs et de fruits et la présence de prédation ont aussi été renseignés.

```{r, message=FALSE, echo=FALSE}
data_original <- read.csv("data/raw/Taille et phéno verif LD.csv", sep = ";")

# Certains noms contiennent des accents non pris en charge
data_original <- data_original %>% 
  mutate(site
         = case_when(
    site == "Combe Michaut" ~ "Combe Michaut",
    site == "Tête Cendrée Bas" ~ "Tete Cendree Bas",
    site == "Tête Cendrée Haut" ~ "Tete Cendree Haut",
    site == "Vigne au Renard" ~ "Vigne au Renard",
    site == "Val Clavin" ~ "Val Clavin"
  ))

#Premières lignes du tableau pour lecteur
head(data_original)
```

### Tableau : autonotation des observateurs

Ce tableau correspond à l'autonotation (de 1 à 10) que s'est attribué chaque observateur en répondant à cinq questions de A à E sur différentes thématiques autours du suivi botanique : - Question A : Niveau de connaissances naturalistes, hors botanique - Question B : Niveau de connaissances en botanique - Question C : Niveau d'expérience pratique du suivi de l’espèce - Question D : Niveau de connaissances théoriques de l’espèce - Question E : Niveau de connaissance pratique des sites d’étude - Question F : Liste des sites d’étude connus Les colonnes de VC à TCh correspondent à la connaissance des observateurs sur les différents sites. L'informations du nombre de quadrat prospectés par session et au total ainsi que le sexe de l'observateur est renseignée.

```{r, message=FALSE, echo=FALSE}
experience <- read.csv("data/raw/Experience_des_observateurs_VF.csv", sep = ";")

# Pour les analyses suivantes nous avons rajouté la colonne sexe à partir des informations trouvées sur internet:
experience$sexe <- c("m","f","m","m","m","f","m","m","m","f","f","f","f","m","f","m","m","m","m","m","f","f","f","m","f","m","f","m","f","f","f","m","f","f","m")

#Premières lignes du tableau pour lecteur
head(experience)
```

# --------------------------------------------------

# Compilation tableau complet

Pour les analyses suivantes, nous avons compilé l’ensemble des tableaux en un seul tableau récapitulatif.

```{r, echo = FALSE, message = FALSE, warning = FALSE, include =FALSE}

# Ajouter une colonne d'identifiant individuel en ajoutant la session
  ## Pour le tableau "vérification" des observateurs
verification2<- verification %>% 
  mutate(id_ind_fin = paste(ID_ind, session, sep = ".")) %>% 
  dplyr::select(id_ind_fin, everything())
  ## Pour le tableau "data_original" des évaluateurs

# Mettre le stade phénologique en ligne et non en colonne 
data_original2 <- data_original %>%
  dplyr::select(-tailleS1, -tailleS2, -tailleS3, -nbfleurs, -nbfruits, -predation) %>% 
  pivot_longer(
    cols = c(phenoS1, phenoS2, phenoS3),
    names_to = "session",
    values_to = "phenologie_verif"
  )%>% 
   mutate(session = case_when(
    session == "phenoS1" ~ 1,
    session == "phenoS2" ~ 2,
    session == "phenoS3" ~ 3
  )
   ) %>% 
  mutate(phenologie_verif
         = case_when(
    phenologie_verif == "j" ~ "juv",
    phenologie_verif == "nf" ~ "non_fleuri",
    phenologie_verif == "f" ~ "fleur",
    phenologie_verif == "ff" ~ "fleurs_fanees",
    phenologie_verif == "F" ~"fruit"
  ))

# Mettre la taille en ligne et non en colonne
data_original3 <- data_original %>% 
  dplyr::select(tailleS1, tailleS2, tailleS3) %>% 
  pivot_longer(
    cols = c(tailleS1, tailleS2, tailleS3),
    names_to = "session",
    values_to = "taille"
  ) %>% 
   mutate(session = case_when(
    session == "tailleS1" ~ 1,
    session == "tailleS2" ~ 2,
    session == "tailleS3" ~ 3
  )
   )

# Enlever la session car déjà présente sur l'autre data frame
data_original3 <- data_original3 %>% 
  dplyr::select(-session)

# Ajout des deux tableaux et suppression des lignes sans informations, liées à l’observation d’un individu à partir des sessions 2 ou 3
data_original4 <- cbind(data_original2, data_original3)

# Vérifier si il manque des informations par rapport à la phénologie
data_original4 %>% 
  filter(is.na(phenologie_verif))
      #Il manque des informations

# Ajouter la variable individuelle complète
data_original_obs <- data_original4 %>% 
  mutate(id_ind_fin = paste(ID_ind, session, sep = ".")) %>% 
  dplyr::select(id_ind_fin, everything())

# Prendre en compte le stade phénologique observé par observateurs
verification3 <- verification2 %>% 
  pivot_longer(
    cols = c(juv, non_fleuri, fleur, fleurs_fanees, fruit),
    names_to = "phenologie",
    values_to = "presence"
  )  
  
# Garder seulement la phénologie observée par observateurs
verification_obs <- verification3 %>% 
  filter(presence == 1)
  
# Vérifier le nombre individus
str(unique(verification_obs$id_ind_fin))
str(unique(data_original_obs$id_ind_fin))
str(data_original_obs$id_ind_fin)
str(verification_obs$id_ind_fin)
    # À priori, 66 individus jamais observés par les observateurs

# Extraire la liste de tous les individus
nb_individu <- data.frame(id_ind_fin = data_original_obs$id_ind_fin)

# Extraire la liste des individus dans le test de détection
nb_ind_obs <- data.frame(id_ind_fin = unique(verification_obs$id_ind_fin))

# Extraire les individus manquants
nb_individu_manquant <- nb_individu %>% 
  anti_join(nb_ind_obs, by = "id_ind_fin")

# Reprendre les données originales sur les valeurs manquantes
nb_individu_manquant_original <- data_original_obs %>% 
  semi_join(nb_individu_manquant, by = "id_ind_fin") 
  
# Joindre à ces données manquantes les valeurs du tableau observateurs
nb_individu_manquant_final <- nb_individu_manquant_original %>% 
  left_join(verification_obs, by = "id_ind_fin") %>% 
  dplyr::select(-ends_with(".y")) %>% 
  rename_with(~ sub("\\.x$", "", .x), ends_with(".x"))

# Joindre au fichier original les informations des évaluateurs
data_verification_original <- verification_obs %>% 
  left_join(data_original_obs, by = "id_ind_fin") %>% 
  dplyr::select(-ends_with(".y")) %>% 
  rename_with(~ sub("\\.x$", "", .x), ends_with(".x"))

# Mettre les colomnes dans le bon ordre
nb_individu_manquant_final <- nb_individu_manquant_final %>% 
  dplyr::select(id_ind_fin, session, site, date, numero_quadrat, ID_quadrat, marquage, ID_ind, observateur, adequation, phenologie, presence, quadrat, phenologie_verif, taille)

# Joindre ces données manquantes à tableau observateurs
tab_detection <- rbind(data_verification_original, nb_individu_manquant_final)

# Créer nouvelle valeur adéquation
tab_detection <- tab_detection %>% 
  mutate(adequation_reel = if_else(
    phenologie == phenologie_verif, 1, 0),
  comparaison_adequation = if_else(
    adequation_reel==adequation, 1, 0 ) )

# Taux d'erreur dans note d'adéquation
sum(tab_detection$comparaison_adequation == 0, na.rm = T) / nrow(tab_detection)

# Vérifier le nombre d'observateurs par session et par quadrat
nb_verif_quadrat <- verification %>% 
  group_by(session, site, numero_quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  )
nrow(nb_verif_quadrat)
nb_verif_quadrat <- nb_verif_quadrat %>% 
  mutate(site = case_when(
    site == "Combe Michaut" ~ "CM",
    site == "Tete Cendree Bas" ~ "TCb",
    site == "Tete Cendree Haut" ~ "TCh",
    site == "Vigne au Renard" ~ "VaR",
    site == "Val Clavin" ~ "VC"
  ),
  ID = "Q")

nb_verif_quadrat <- nb_verif_quadrat %>% 
  mutate(id_quadrat = paste(ID, numero_quadrat, sep = ""),
         id_quadrat_fin = paste(site, id_quadrat, session, sep =".")) %>% 
  dplyr::select(id_quadrat_fin, everything())

nb_obs_quadrat <- data_original_obs %>% 
  group_by(session, site, quadrat) %>% 
  count()
nrow(nb_obs_quadrat)

nb_quadrat_final <- tab_detection %>% 
  group_by(session, site, quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  ) %>% 
  filter(!is.na(quadrat))
nrow(nb_quadrat_final)

nb_quadrat_manquant <- nb_individu_manquant_final %>% 
  group_by(session, ID_quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  )
nrow(nb_quadrat_manquant)
    #individus manquants dans 39 quadras

nb_quadrat_manquant <- nb_quadrat_manquant %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  dplyr::select(id_quadrat_fin, everything())

test <- nb_quadrat_manquant %>% 
  anti_join(nb_verif_quadrat, by = "id_quadrat_fin")

# Nous avons bien tous les quadrat observés, juste pas tous les individus

str(tab_detection)

# Pour le moment, on obtient un tableau avec tous les individus observés, mais sans l'information sur les individus non observés par les observateurs.
# Il faut, à chaque fois, le nombre de quadrats observés par observateur pour pouvoir calculer le nombre d'observateurs par quadrat.

verification_obs_quadrat <- verification %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  group_by(id_quadrat_fin, observateur) %>% 
  count()

# Ajouter à tableau détection : id_quadrat_fin
tab_detection <- tab_detection %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = "."))

# Vérifier qu'il n'y pas de NA crées
tab_detection[is.na(tab_detection$id_quadrat_fin), ]

# Calculer le nombre d'individus par quadrat
nb_indiv_quadrat <- data_original_obs %>% 
    mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  group_by(id_quadrat_fin) %>% 
  summarise(
    nb_individus = n_distinct(ID_ind),
    .groups = "drop"
  )

# Comparaison du nombre d'individus par quadrat au nombre observé par mes observateurs
difference_ind <- verification_obs_quadrat %>% 
  full_join(nb_indiv_quadrat, by = "id_quadrat_fin")

# Taux de detection par observateur
difference_ind <- difference_ind %>% 
  mutate(detection = n/nb_individus)

# Extraire les identifiants de tous les individus possibles
individus_par_quadrat <- tab_detection %>%
  distinct(id_quadrat_fin, ID_ind)

# Combinaisons de tous les individus possibles avec les observateurs
grille_complete <- difference_ind %>%
  dplyr::select(id_quadrat_fin, observateur) %>%
  distinct() %>%
  left_join(individus_par_quadrat, by = "id_quadrat_fin", relationship = "many-to-many")

# Ajouter les informations de detection dans la grille complete
tab_complet <- grille_complete %>%
  left_join(
    tab_detection %>%
      mutate(detection = 1) %>%
      dplyr::select(id_quadrat_fin, observateur, ID_ind, detection),
    by = c("id_quadrat_fin", "observateur", "ID_ind")
  ) %>%
  mutate(
    detection = ifelse(is.na(detection), 0, detection)
  )

# Vérifier que cela a fonctionné en comparant le nombre de détections calculées avec le nombre de détections par quadrat

tab_complet %>%
  group_by(id_quadrat_fin, observateur) %>%
  summarise(
    n_detectes = sum(detection),
    .groups = "drop"
  ) %>%
  left_join(difference_ind, by = c("id_quadrat_fin", "observateur")) %>% 
  filter(n_detectes != n)

# Ajouter l'information des observateurs au tableau de détection
tab_complet <- tab_complet %>%
  left_join(
    tab_detection,
    by = c("id_quadrat_fin","ID_ind", "observateur")
  )

# Ajouter les informations aux données originales
data_original_obs <- data_original_obs %>% 
    mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = "."))

tab_complet <- tab_complet %>%
  left_join(
    data_original_obs,
    by = c("id_quadrat_fin","ID_ind"),
    suffix = c("_test", "")
  ) %>%
  dplyr::select(
    -ends_with("_test")  # ou l’inverse selon ce que tu veux garder
  ) %>% 
  dplyr::select(id_ind_fin,id_quadrat_fin, ID_quadrat, ID_ind,site, quadrat, marquage, session,observateur, detection, phenologie_verif, phenologie, adequation, adequation_reel, taille)


```

### Joindre des données supplémentaires

Pour la construction des modèles, intégrer l’ensemble des données disponibles est pertinent afin de sélectionner les variables qui constitueront nos modèles. Ainsi, il est possible d’ajouter progressivement des données supplémentaires en utilisant les colonnes communes aux différents tableaux comme repère pour les jointures. Par exemple, ici, nous souhaitons inclure le tableau « recouvrement » contenant les différentes strates.

```{r, echo = FALSE, message = FALSE, warning = FALSE, include =FALSE}
# Extraire la partie quadrat de tab_complet (tout avant le dernier point)
tab_complet <- tab_complet %>%
  mutate(
    ID_Quadrat_clean = str_replace(id_quadrat_fin, "\\.[0-9]+$", "")
  )

# Nettoyer recouvrement pour correspondre au format de tab_complet
recouvrement_clean <- recouvrement %>%
  mutate(
    ID_Quadrat_clean = str_replace_all(ID_Quadrat, "_", ".")
  ) %>%
  dplyr::select(ID_Quadrat_clean, starts_with("S_"))

# Faire le left_join pour ajouter les colonnes S_ au tableau complet
tab_complet <- tab_complet %>%
  left_join(recouvrement_clean, by = "ID_Quadrat_clean") %>% 
  dplyr::select(-ID_Quadrat_clean)

#Vérification histoires de capture
verif_sessions <- tab_complet %>%
  group_by(ID_ind) %>%
  summarise(
    nb_sessions = n_distinct(session),
    sessions = paste(sort(unique(session)), collapse = ","),
    .groups = "drop"
  )

check_sessions <- verif_sessions %>%
  mutate(
    ok_sessions = sessions == "1,2,3"
  )

check_sessions %>%
  filter(!ok_sessions)

```

# --------------------------------------------------

# ANALYSES PRELIMINAIRES

## --------------

Avant de commencer des analyses complexes, difficiles à interpréter ou qui fournissent une compilation des informations, il est important d’étudier chaque variable indépendamment afin d’en expliquer les effets.

# I\_ Analyse générale avec modélisation

## --------------

## Modèle taille
## --------------

### Preparation de données

```{r, echo = FALSE, message = FALSE, warning = FALSE, include = FALSE}

data_original_obs
unique(data_original_obs$phenologie_verif)

#On repart de tableau vérificatrices avec la taille et la phénologie par session passée sur une colonne et colonne session ajoutée
#On enlève phénologie NA 
data_taille <- data_original_obs %>% 
  filter(!is.na(phenologie_verif))

#On vérifie que l'on a l'info sur toutes les tailles
data_taille %>% 
  filter(is.na(taille))

#passer la taille en numérique
data_taille <- data_taille %>%
  mutate(
    taille = as.numeric(gsub(",", ".", taille))
  )
#distribution variable réponse taille
ggplot(data=data_taille, aes(x= taille))+
  geom_histogram()
#Plus ou moins une loi de poisson
#Comme la variable taille est continue on va utiliser une loi de poisson

#Enlever les taille = à 0 qui vont faire planter le modèle
any(data_taille$taille <= 0)

data_taille <- data_taille %>% 
  filter(!taille<=0)
#6 individus de perdus

#Mettre les variables explicatives en facteur
data_taille$phenologie_verif <- factor(data_taille$phenologie_verif)
data_taille$site <- factor(data_taille$site)
data_taille$session <- factor(data_taille$session)
data_taille$ID_ind <- factor(data_taille$ID_ind)
data_taille$ID_quadrat <- factor(data_taille$ID_quadrat)

head(data_taille)
```

### Construction modèle

```{r}
#Modèle (on utlise glmmTMB pour faire les prédictions car algorithme trop lent avec glmer de lme4)

mod_glmm_gamma <- glmer(
  taille ~ phenologie_verif + site * session + (1 | ID_ind) + (1|ID_quadrat),
  family = Gamma(link = "log"),
  data = data_taille
)

summary(mod_glmm_gamma)
Anova(mod_glmm_gamma, type = 3)

#prédictions du modèle
emm <- emmeans(
  mod_glmm_gamma,
  ~ session * phenologie_verif | site,
  type = "response"
)

#tableau pour lecture
emm_clean <- emm %>%
  as.data.frame() %>%
  select(site, phenologie_verif, session, response) %>%
  mutate(response = round(response, 2)) %>%
  pivot_wider(
    names_from = session,
    values_from = response,
    names_prefix = "session_"
  )

emm_clean %>%
  kbl(
    booktabs = TRUE,
    caption = "Prédictions du modèle par site, phénologie et session"
  ) %>%
  kable_classic(full_width = FALSE)

```

Méthode d'interprétation : Ce tableau présente les tailles prédites par le modèle pour chaque combinaison de site, phénologie et session. Les valeurs correspondent aux prédictions moyennes, ce qui permet de comparer facilement l’évolution de la taille entre les sessions et entre les stades phénologiques. Des valeurs plus élevées indiquent des individus plus grands, et les différences entre colonnes (sessions) montrent comment la taille progresse au cours du temps.

### Préparation Graphique

```{r, echo = FALSE, message = FALSE, warning = FALSE, include = FALSE}
#préparation graphique
emm_df <- as.data.frame(emm)

emm_df$phenologie_verif <- factor(
  emm_df$phenologie_verif,
  levels = c("juv", "non_fleuri", "fleur", "fleurs_fanees","fruit")
)

```

## Effet Taille, Site, Phénologie, Session

```{r}

#graphique avec tous les effets
ggplot(emm_df, aes(
  x = session,
  y = response,
  fill = phenologie_verif
)) +
  geom_col(
    position = position_dodge(width = 0.9),
    color = "black"
  ) +
  geom_errorbar(
    aes(ymin = asymp.LCL, ymax = asymp.UCL),
    position = position_dodge(width = 0.9),
    width = 0.2
  ) +
  facet_wrap(~ site) +
  labs(
    x = "Session",
    y = "Taille prédite",
    fill = "Phénologie"
  ) +
  scale_fill_manual(values = c(
    "juv"  = "#FF9999",
    "non_fleuri" = "#FF4D4D",
    "fleur"  = "#CC0000",
      "fleurs_fanees"  = "#990000",
"fruit"   = "#660000"
  )) +
  theme_minimal()
```

Ce graphique montre que la taille prédite augmente clairement entre les sessions 1, 2 et 3, quel que soit le site ou le stade phénologique. Les individus en phases avancées de phénologie (fleurs fanées, fruits) sont systématiquement plus grands, et cette tendance est cohérente dans tous les sites.

## Effet Session

Effet propre de la session, toutes phénologies et tous sites confondus (prédiction marginale).

```{r, echo=FALSE, message=FALSE, warning=FALSE}

emm_session <- emmeans(
  mod_glmm_gamma,
  ~ session,
  type = "response"
)

emm_session_df <- as.data.frame(emm_session)

ggplot(emm_session_df, aes(
  x = session,
  y = response
)) +
  geom_col(
    fill = "grey70",
    color = "black",
    width = 0.7
  ) +
  geom_errorbar(
    aes(ymin = asymp.LCL, ymax = asymp.UCL),
    width = 0.2
  ) +
  labs(
    x = "Session",
    y = "Taille prédite (moyenne marginale)",
    title = "Effet marginal de la session sur la taille"
  ) +
  theme_minimal()

#tableau pour lecture
tab <- pairs(emm_session) %>% 
  as.data.frame() %>% 
  mutate(
    ratio   = round(ratio, 3),
    SE      = round(SE, 4),
    z.ratio = round(z.ratio, 2),
    p.value = signif(p.value, 3)
  )

tab %>%
  kbl(booktabs = TRUE, caption = "Contrastes entre sessions (EMMs)") %>%
  kable_classic(full_width = FALSE)


```

Méthode d'interprétation : Ce tableau présente les contrastes entre sessions à partir des moyennes marginales estimées. Le ratio indique l’effet multiplicatif entre deux sessions : un ratio inférieur à 1 signifie que la première session a une valeur plus faible que la seconde. Le z‑ratio et la p‑value testent si cette différence est statistiquement significative. Les comparaisons avec p \< 0.05 sont considérées comme significatives.

Résultats : Les comparaisons montrent que la session 1 a des valeurs significativement plus faibles que les sessions 2 et 3 (ratios \< 1 et p \< 0.001). La session 2 est également légèrement mais significativement plus faible que la session 3 (p = 0.0015). Les tailles prédites augmentent significativement donc d’une session à l’autre.

## Effet Phénologie

Effet propre de la phénologie, toutes sessions et tous sites confondus (prédiction marginale).

```{r, echo=FALSE, message=FALSE, warning=FALSE}

emm_phenologie <- emmeans(
  mod_glmm_gamma,
  ~ phenologie_verif,
  type = "response"
)

emm_phenologie_df <- as.data.frame(emm_phenologie)
emm_phenologie_df$phenologie_verif <- factor(
  emm_phenologie_df$phenologie_verif,
  levels = c("juv", "non_fleuri", "fleur", "fruit", "fleurs_fanees")
)

ggplot(emm_phenologie_df, aes(
  x = phenologie_verif,
  y = response
)) +
  geom_col(
    fill = "skyblue",
    color = "black",
    width = 0.7
  ) +
  geom_errorbar(
    aes(ymin = asymp.LCL, ymax = asymp.UCL),
    width = 0.2
  ) +
  labs(
    x = "Phénologie",
    y = "Taille prédite (moyenne marginale)",
    title = "Effet marginal de la phénologie sur la taille"
  ) +
  theme_minimal()

#tableau pour lecture
tab <- pairs(emm_phenologie) %>% 
  as.data.frame() %>% 
  mutate(
    ratio   = round(ratio, 3),
    SE      = round(SE, 4),
    z.ratio = round(z.ratio, 2),
    p.value = signif(p.value, 3)
  )

tab %>%
  kbl(booktabs = TRUE, caption = "Contrastes entre phénologie (EMMs)") %>%
  kable_classic(full_width = FALSE)

```
Méthode d'interprétation : Ce tableau compare les tailles prédites entre les différents stades phénologiques. Le ratio indique combien la première catégorie est plus grande (ratio > 1) ou plus petite (ratio < 1) que la seconde. Les valeurs de p montrent si ces différences sont statistiquement significatives. Les contrastes avec p < 0.05 révèlent des différences nettes entre phénologies, tandis que les ratios proches de 1 et non significatifs indiquent des tailles similaires entre stades.

Résultats : Les contrastes montrent une progression nette de la taille au cours de la phénologie. Les stades juvénile et non fleuri sont significativement plus petits que tous les stades floraux et post‑floraux. En revanche, les stades fleur, fleurs fanées et fruit présentent des tailles similaires, sans différences significatives entre eux. Globalement, le modèle met en évidence une augmentation marquée de la taille entre les phases précoces et les phases florales, suivie d’une stabilisation une fois la floraison engagée.

## Effet Site

Effet propre du site , toutes sessions et toutes phénologies confondus (prédiction marginale).

```{r, echo=FALSE, message=FALSE, warning=FALSE}

emm_site <- emmeans(
  mod_glmm_gamma,
  ~ site,
  type = "response"
)

emm_site_df <- as.data.frame(emm_site)

ggplot(emm_site_df, aes(
  x = site,
  y = response
)) +
  geom_col(
    fill = "grey70",
    color = "black",
    width = 0.7
  ) +
  geom_errorbar(
    aes(ymin = asymp.LCL, ymax = asymp.UCL),
    width = 0.2
  ) +
  labs(
    x = "Session",
    y = "Taille prédite (moyenne marginale)",
    title = "Effet marginal de la session sur la taille"
  ) +
  theme_minimal()

#tableau pour lecture
tab <- pairs(emm_site) %>% 
  as.data.frame() %>% 
  mutate(
    ratio   = round(ratio, 3),
    SE      = round(SE, 4),
    z.ratio = round(z.ratio, 2),
    p.value = signif(p.value, 3)
  )

tab %>%
  kbl(booktabs = TRUE, caption = "Contrastes entre sites (EMMs)") %>%
  kable_classic(full_width = FALSE)

```

Méthode d'interprétation : Ce tableau présente les contrastes entre sites à partir des moyennes marginales estimées. Le ratio indique si la taille prédite est plus élevée dans le premier site du contraste (ratio > 1) ou plus faible (ratio < 1). Le z‑ratio et la p‑value testent la significativité statistique de cette différence. Les contrastes dont la p‑value est faible (p < 0.05) révèlent des différences nettes entre sites, tandis que les ratios proches de 1 et non significatifs indiquent des tailles similaires. Ce type de tableau permet donc d’identifier rapidement quels sites se distinguent réellement les uns des autres.

Résultats : Les contrastes montrent que la plupart des sites présentent des tailles prédictes similaires, avec peu de différences statistiquement significatives. Seuls quelques écarts ressortent, notamment des tailles plus élevées à Tête Cendrée Haut et Vigne au Renard par rapport à certains autres sites. Dans l’ensemble, la variabilité entre sites reste limitée, et seules quelques comparaisons isolées indiquent des différences marquées.

## --------------
# I\_ Analyse générale sans modélisation
## --------------

## I_i Relation taille et phénologie

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Mise en forme des données en format long :
# empilement des données de taille et de phénologie
# pour les trois sessions d’observation
data_long <- bind_rows(
  data_original %>% transmute(pheno = phenoS1, taille = tailleS1),
  data_original %>% transmute(pheno = phenoS2, taille = tailleS2),
  data_original %>% transmute(pheno = phenoS3, taille = tailleS3)
)

# Conversion de la variable taille en numérique
# (remplacement des virgules par des points)
# et suppression des valeurs manquantes
data_long <- data_long %>%
  mutate(
    taille = as.numeric(gsub(",", ".", taille))
  ) %>%
  filter(!is.na(taille), !is.na(pheno))

# Ordonnancement des stades phénologiques
# afin de respecter la progression biologique
data_long$pheno <- factor(
  data_long$pheno,
  levels = c("j", "nf", "f", "F", "ff")
)

# Visualisation de la distribution des tailles
# en fonction des stades phénologiques
# (toutes sessions confondues)
ggplot(data = data_long, aes(x = pheno, y = taille)) +
  geom_boxplot() +
  labs(
    x = "Stade phénologique",
    y = "Taille",
    title = "Taille selon le stade phénologique (sessions confondues)"
  ) +
  theme_minimal()

# Test global de significativité
ktest<- kruskal.test(taille ~ pheno, data = data_long) 
# Hypothèse : il y a au moins une différence significative de taille entre les stades phénologiques. Hypothèse acceptée si p-value < 0.05 

#tableau lecture simple
tab_pheno <- data_long %>%
  pairwise_wilcox_test(taille ~ pheno, p.adjust.method = "BH") %>%
  select(group1, group2, p, p.adj) %>%
  mutate(
    p      = signif(p, 3),
    p.adj  = signif(p.adj, 3)
  )

tab_pheno %>%
  kbl(
    booktabs = TRUE,
    caption = "Comparaisons deux à deux entre phénologies (test de Wilcoxon, correction BH)"
  ) %>%
  kable_classic(full_width = FALSE)


```

Méthode d'interprétation : Ce type de tableau présente les comparaisons deux à deux entre groupes, ici entre phénologies, à l’aide d’un test de Wilcoxon. Pour chaque paire, on indique les deux groupes comparés ainsi que la p‑value brute et la p‑value ajustée, cette dernière tenant compte du nombre total de comparaisons. Cela permet d’identifier rapidement quelles paires de groupes diffèrent réellement de manière significative.

Résultats : Les tailles diffèrent significativement entre l’ensemble des stades phénologiques (tests de Wilcoxon deux à deux avec correction de Benjamini–Hochberg ; Tableau X). Les stades précoces (j et nf) présentent des différences très marquées avec tous les stades plus avancés (p_adj ≪ 0,001), indiquant une augmentation nette de la taille au cours du développement. Les différences entre les stades tardifs (f, F et ff) restent significatives, bien que plus faibles, suggérant une progression continue de la taille jusqu’aux phases finales du cycle phénologique. Ces résultats confirment une relation étroite entre la taille des individus et leur stade phénologique.

## I_ii Relation recouvrement végétal et site

### RDA
L’analyse factorielle discriminante (AFD) est une méthode statistique qui permet de déterminer si des groupes prédéfinis peuvent être différenciés à partir de variables explicatives. Elle cherche à identifier les combinaisons de variables qui séparent le mieux ces groupes.

Dans ce travail, l’AFD est utilisée pour tester si les sites étudiés peuvent être distingués en fonction de la structure de la végétation, décrite par les recouvrements des différentes strates (muscinale, herbacée, arbustive et arborescente). L’objectif est donc de vérifier si chaque site présente une signature de recouvrement particulière et d’identifier quelles strates contribuent le plus à cette différenciation.

Cette méthode suppose une variable réponse continue et des relations linéaires

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# -------------------------------
# 1. LDA sur les données originales
# -------------------------------
afd_recouvrement <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = recouvrement
)

# -------------------------------
# 2. Centrage et normalisation des variables
# -------------------------------
newdata <- as.data.frame(scale(recouvrement[, 4:8]))

# On ajoute la variable de groupe (Site) pour l'analyse
newdata$Site <- recouvrement$Site

# -------------------------------
# 3. LDA sur les données centrées-réduites
# -------------------------------
afd2 <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = newdata
)

# -------------------------------
# 4. MANOVA pour tester les différences entre groupes
# -------------------------------
manova_res <- manova(as.matrix(recouvrement[, 4:8]) ~ recouvrement$Site)

# -------------------------------
# 5. Prédiction avec LDA
# -------------------------------
pred <- predict(afd2)
a<- table(Site = recouvrement$Site, Predicted = pred$class)

# -------------------------------
# 6. Validation croisée (jackknife)
# -------------------------------
afd_cv <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = newdata,
  CV = TRUE
)
b<- table(Site = newdata$Site, Predicted = afd_cv$class)

# -------------------------------
# 7. AFD basée sur l'ACP centrée-réduite
# -------------------------------
pca_res <- dudi.pca(recouvrement[, 4:8], scannf = FALSE, nf = 3)
afd3 <- discrimin(pca_res, factor(recouvrement$Site), scannf = FALSE, nf = 3) ## dans le nombre d'axe, indiquer la valeur adéquate dans pca_res$nf

# Exploration des valeurs propres et des coefficients standardisés
valeur_propres <- afd3$eig

# Projection des variables sur les fonctions discriminantes
# Créer une nouvelle fenêtre graphique (ou plot)
s.arrow(afd3$fa)  

# Projection des individus selon leur groupe
s.class(afd3$li, factor(recouvrement$Site))

#Regarder contribution relative des strates et des variables aux axes
# strates
tab_afd <- afd3$fa %>%
  as.data.frame() %>%
  mutate(
    DS1 = round(DS1, 3),
    DS2 = round(DS2, 3),
    DS3 = round(DS3, 3)
  ) %>%
  tibble::rownames_to_column("strate")

tab_afd %>%
  kbl(
    booktabs = TRUE,
    caption = "Coefficients standardisés des strates sur les fonctions discriminantes (AFD)"
  ) %>%
  kable_classic(full_width = FALSE)

# sites
tab_afd <- afd3$gc %>%
  as.data.frame() %>%
  mutate(
    DS1 = round(DS1, 3),
    DS2 = round(DS2, 3),
    DS3 = round(DS3, 3)
  ) %>%
  tibble::rownames_to_column("strate")

tab_afd %>%
  kbl(
    booktabs = TRUE,
    caption = "Coefficients standardisés des sites sur les fonctions discriminantes (AFD)"
  ) %>%
  kable_classic(full_width = FALSE)

```

Méthode d'interprétation : Les résultats de l’analyse factorielle discriminante (AFD) permettent de visualiser et d’expliquer les différences de composition végétale entre les sites étudiés. Le premier graphique montre la contribution des différentes strates de végétation aux axes discriminants : la longueur et la direction des flèches indiquent quelles strates participent le plus à la séparation des sites. Le second graphique représente la projection des individus regroupés par site : une bonne séparation entre les groupes traduit des différences nettes de recouvrement des strates entre les sites.Le tableau des coefficients standardisés sur les trois premières fonctions discriminantes (DS1, DS2, DS3) permet de quantifier l’importance relative de chaque strate dans la discrimination des sites. 

Résultats : Les strates muscinale et arbustive basse ont les coefficients les plus élevés sur les axes principaux (DS1 et DS2). Les autres strates contribuent moins à la séparation. Sur le premier axe (DS1), Combe Michaut est la plus positive et Vigne au Renard la plus négative, indiquant que ces deux sites sont les plus contrastés en termes de recouvrement des strates discriminantes, notamment muscinale et arbustive basse. Les autres sites se distinguent principalement sur le deuxième axe (DS2), avec Val Clavin très positive et Tête Cendrée haut négative.
Les strates muscinale et arbustive basse sont les variables les plus informatives pour expliquer les différences de composition végétale entre les sites.

### Régression Multinomiale

Modèle statistique utilisé quand la variable réponse est catégorielle avec plus de deux catégories, sans ordre naturel entre elles. Phénologie est un état discret, non ordonné, avec plusieurs modalités. On fait pas de RDA car elle suggère que la variable réponse est continue, elle cherche des relations linéaires. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}

mod_pheno <- multinom(
  phenologie_verif ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = tab_complet
)

#Tableau lecture simple
# Extraction
coef_mat <- summary(mod_pheno)$coefficients
se_mat   <- summary(mod_pheno)$standard.errors
z_mat    <- coef_mat / se_mat
p_mat    <- 2 * (1 - pnorm(abs(z_mat)))

# Fonction pour étoiles 
etoiles <- function(p){
  ifelse(p < 0.001, "***",
         ifelse(p < 0.01, "**",
                ifelse(p < 0.05, "*",
                       ifelse(p < 0.1, ".", ""))))
}

tableau <- data.frame(
  Etat = rep(rownames(coef_mat), each = ncol(coef_mat)),
  Parametre = rep(colnames(coef_mat), times = nrow(coef_mat)),
  Coefficient = as.vector(coef_mat),
  SE = as.vector(se_mat),
  z = as.vector(z_mat),
  p_value = as.vector(p_mat)
) %>%
  mutate(
    Coefficient = round(Coefficient, 4),
    SE = round(SE, 4),
    z = round(z, 3),
    p_value = signif(p_value, 3),
    Signif = etoiles(p_value)
  )

kable(tableau, format = "html", booktabs = TRUE,
      caption = "Régression multinomiale : effets des strates de recouvrement sur la phénologie") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))
```

Méthode d'interprétation : Dans ce tableau de régression multinomiale, chaque ligne indique l’effet d’une strate de végétation sur la probabilité d’appartenir à un état phénologique donné, comparé à la catégorie de référence. La colonne *Coefficient* montre si la strate augmente (valeur positive) ou diminue (valeur négative) cette probabilité, tandis que l’erreur standard (*SE*), la statistique *z* et la *p‑value* renseignent sur la précision de l’estimation et sa significativité. La colonne *Signif* résume visuellement cette significativité. Ensemble, ces informations permettent d’identifier quelles strates influencent réellement la transition d’un état phénologique à un autre et dans quel sens.

Résultats : Les résultats montrent un gradient phénologique structuré par l’ouverture du milieu : Milieux ouverts (herbacées) → stades avancés (fleurs fanées, fruits), peu de juvéniles. Milieux semi‑fermés (arbustif bas) → forte probabilité de fleurs fanées et de fruits. Milieux très fermés (arbustif haut, arborescent) → stades précoces (non fleuri, juvénile), peu de stades avancés. Mousse → effet faible ou non significatif, sauf absence quasi totale de fleurs fanées dans ces micro‑habitats.

La structure verticale du recouvrement influence donc fortement la progression phénologique, avec un cycle plus avancé dans les milieux ouverts ou semi‑ouverts, et plus précoce dans les milieux fermés.

## --------------

# II\_ Analyse de la variation dans le temps

Dans un premier temps, nous avons étudié la variation des données au cours du temps afin d’obtenir une vision dynamique de leur évolution.

## --------------

## II_i Effet de la session

### Effet de la session sur la taille

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Transformer les données en format long
taille_long <- data_original %>%
  dplyr::select(tailleS1, tailleS2, tailleS3) %>%
  pivot_longer(
    cols = everything(),
    names_to = "session",
    values_to = "taille"
  ) %>%
  mutate(
    # remplacer les "," par "." et convertir en numérique
    taille = as.numeric(gsub(",", ".", taille)),
    # renommer les sessions
    session = dplyr::recode(session, "tailleS1"="S1", "tailleS2"="S2", "tailleS3"="S3")
  )

# Calcul de la moyenne, écart-type et IC 95%
taille_stats <- taille_long %>%
  group_by(session) %>%
  summarise(
    mean_taille = mean(taille, na.rm = TRUE),
    sd_taille = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille)),
    .groups = "drop"
  ) %>%
  mutate(
    se = sd_taille / sqrt(n),
    ci_lower = mean_taille - 1.96 * se,
    ci_upper = mean_taille + 1.96 * se
  )

# Histogramme avec IC 95%
ggplot(taille_stats, aes(x = session, y = mean_taille, fill = session)) +
  geom_bar(stat = "identity", width = 0.6) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, color = "black") +
  scale_fill_manual(values = c("S1"="#FF9999", "S2"="#FF4D4D", "S3"="#CC0000")) +
  labs(
    title = "Taille moyenne par session",
    x = "Session",
    y = "Taille moyenne",
    fill = "Session"
  ) +
  theme_minimal()

#tableau lecture simple
# Comparaisons deux à deux après Kruskal-Wallis
tab_session <- taille_long %>%
  pairwise_wilcox_test(taille ~ session, p.adjust.method = "BH") %>%
  select(group1, group2, p, p.adj) %>%
  mutate(
    p     = signif(p, 3),
    p.adj = signif(p.adj, 3)
  )

tab_session %>%
  kbl(
    booktabs = TRUE,
    caption = "Comparaisons deux à deux entre sessions (test de Wilcoxon, correction BH)"
  ) %>%
  kable_classic(full_width = FALSE)


```

Méthode d'interprétation : Le graphique montre la taille moyenne des individus par session avec les barres d’erreur représentant l’intervalle de confiance à 95 %. Le tableau compare les sessions deux à deux pour voir si leur taille diffère significativement. Les colonnes p et p.adj indiquent la significativité du test : des valeurs très faibles montrent une différence nette entre les deux sessions, tandis qu’une valeur élevée signifie qu’elles ne diffèrent pas. Chaque ligne résume donc si la paire de sessions considérée présente ou non une différence statistiquement détectable.

Résultats : Nous observons une augmentation progressive de la taille : la moyenne passe de S1 (\~13,7) à S2 (\~16,9) puis à S3 (\~17,3). L'augmentation est statistiquement significative.

### Effet de la session sur la phénologie

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Transformer les données en format long : session = S1, S2, S3
pheno_long <- data_original %>%
  dplyr::select(phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = everything(),
    names_to = "session",
    values_to = "pheno"
  ) %>%
  # Remplacer NA par un label pour garder comme modalité
  dplyr::mutate(pheno = ifelse(is.na(pheno), "NA", as.character(pheno))) %>%
  # Renommer les sessions plus simplement
  mutate(session = dplyr::recode(session,
                          "phenoS1" = "S1",
                          "phenoS2" = "S2",
                          "phenoS3" = "S3"))

# Calcul des effectifs par session et type phénologique
pheno_stats <- pheno_long %>%
  group_by(session, pheno) %>%
  summarise(
    n = n(),
    .groups = "drop"
  ) %>%
  mutate(
    # IC 95% approximatif (Poisson)
    se = sqrt(n),
    ci_lower = pmax(n - 1.96 * se, 0),
    ci_upper = n + 1.96 * se
  )

# Définir l'ordre des phénos
pheno_stats$pheno <- factor(pheno_stats$pheno, levels = c("j", "nf", "f", "ff", "F", "NA"))

# Graphique avec barres côte à côte et IC 95%
ggplot(pheno_stats, aes(x = session, y = n, fill = pheno)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
                position = position_dodge(width = 0.8), width = 0.2, color = "black") +
  scale_fill_manual(values = c(
    "j"  = "#FF9999",
    "nf" = "#FF4D4D",
    "f"  = "#CC0000",
    "ff" = "#990000",
    "F"  = "#660000",
    "NA" = "#000000"  # noir pur pour NA
  )) +
  labs(
    title = "Effet de la session (S1, S2, S3) sur la phénologie",
    x = "Session",
    y = "Nombre d'individus",
    fill = "Type phénologique"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

tab_pheno <- pheno_stats %>%
  mutate(
    n        = round(n, 0),
    se       = round(se, 2),
    ci_lower = round(ci_lower, 2),
    ci_upper = round(ci_upper, 2)
  ) %>%
  arrange(session, pheno)

tab_pheno %>%
  kbl(
    booktabs = TRUE,
    caption = "Effectifs par session et type phénologique avec IC 95% (approximation Poisson)"
  ) %>%
  kable_classic(full_width = FALSE)

```

Méthode d'interprétation : Le graphique montre la taille moyenne des individus par phénologie avec les barres d’erreur représentant l’intervalle de confiance à 95 %. Ce tableau présente, pour chaque session (S1, S2, S3) et chaque type phénologique, le nombre d’individus observés (n). La colonne se indique l’erreur standard associée à cet effectif, et les colonnes ci_lower et ci_upper donnent les bornes de l’intervalle de confiance à 95 %, c’est‑à‑dire la zone dans laquelle l’effectif réel est probablement situé. Chaque ligne correspond donc à une combinaison session × phéno et résume combien d’individus ont été comptés et la précision de cette estimation.

Résultats : Nous observons que S1 est dominée par les stades j et nf, avec relativement peu de fleurs et un nombre notable de données manquantes. En S2, le stade nf devient majoritaire et les stades reproducteurs (f et ff) apparaissent davantage. En S3, les stades avancés (ff et F) sont plus représentés, tandis que les stades précoces diminuent. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## Même graphique mais inversé
# ordonner les modalités
pheno_stats$pheno <- factor(pheno_stats$pheno, levels = c("j", "nf", "f", "ff", "F", "NA"))
pheno_stats$session <- factor(pheno_stats$session, levels = c("S1", "S2", "S3"))

# graphique : phénologie en x, couleur = session
ggplot(pheno_stats, aes(x = pheno, y = n, fill = session)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
                position = position_dodge(width = 0.8), width = 0.2, color = "black") +
  scale_fill_manual(values = c("S1" = "#FF9999", "S2" = "#FF4D4D", "S3" = "#CC0000")) +
  labs(title = "Distribution de la phénologie par session", x = "Type phénologique", y = "Nombre d'individus", fill = "Session") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5), legend.position = "right")
```

## --------------

# III\_ Analyse de la variation dans l'espace

Dans un second temps, nous avons étudié la variation des données dans l'espace afin d’obtenir une vision spatiale de leur évolution.

## --------------

## III_i Effet du site

### Effet du site sur la taille

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Transformer les données en format long pour toutes les tailles
taille_long <- data_original %>%
  dplyr::select(site, tailleS1, tailleS2, tailleS3) %>%
  pivot_longer(
    cols = c(tailleS1, tailleS2, tailleS3),
    names_to = "session",
    values_to = "taille"
  ) %>%
  mutate(
    # remplacer les "," par "." et convertir en numérique
    taille = as.numeric(gsub(",", ".", taille))
  )

# Calcul de la taille moyenne par site
taille_stats <- taille_long %>%
  group_by(site) %>%
  summarise(
    mean_taille = mean(taille, na.rm = TRUE),
    sd_taille = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille)),
    .groups = "drop"
  ) %>%
  mutate(
    se = sd_taille / sqrt(n),
    ci_lower = mean_taille - 1.96 * se,
    ci_upper = mean_taille + 1.96 * se
  )

# Histogramme avec IC 95%
ggplot(taille_stats, aes(x = site, y = mean_taille)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, color = "black") +
  labs(
    title = "Taille moyenne par site",
    x = "Site",
    y = "Taille moyenne",
    fill = "Site"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

#tableau lecture simple
tab_pheno <- pheno_stats %>%
  mutate(
    n        = round(n, 0),
    se       = round(se, 2),
    ci_lower = round(ci_lower, 2),
    ci_upper = round(ci_upper, 2)
  ) %>%
  arrange(session, pheno)

tab_pheno %>%
  kbl(
    booktabs = TRUE,
    caption = "Effectifs par session et type phénologique avec IC 95% (approximation Poisson)"
  ) %>%
  kable_classic(full_width = FALSE)

```
Méthode d'interprétation : Le graphique montre la taille moyenne des individus par sites avec les barres d’erreur représentant l’intervalle de confiance à 95 %. Le tableau présente, pour chaque session et chaque type phénologique, le nombre d’individus observés ainsi que l’incertitude associée à ces effectifs. Les colonnes indiquent l’erreur standard et les bornes de l’intervalle de confiance à 95 %, ce qui permet d’apprécier la précision des estimations. La lecture se fait ligne par ligne : chaque combinaison session × phéno résume combien d’individus ont été comptés et dans quelle mesure cet effectif est fiable statistiquement.

Résultats : Voici une version plus concise :

Le tableau montre comment les stades phénologiques évoluent d’une session à l’autre. S1 est dominée par les stades précoces, S2 voit apparaître davantage de stades reproducteurs, et S3 présente surtout des stades avancés. Les intervalles de confiance indiquent la précision des effectifs : ils sont serrés pour les stades fréquents et plus larges pour les stades rares. En résumé, le tableau illustre une progression nette de la phénologie au fil des sessions.

### Effet du site sur la taille selon la session

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Assurer que les colonnes de taille sont numériques
data_original <- data_original %>%
  mutate(
    tailleS1 = as.numeric(gsub(",", ".", tailleS1)),
    tailleS2 = as.numeric(gsub(",", ".", tailleS2)),
    tailleS3 = as.numeric(gsub(",", ".", tailleS3))
  )

# Calcul des statistiques pour chaque taille
stats_long <- data_original %>%
  pivot_longer(cols = c(tailleS1, tailleS2, tailleS3),
               names_to = "taille_type",
               values_to = "taille") %>%
  group_by(site, taille_type) %>%
  summarise(
    mean = mean(taille, na.rm = TRUE),
    sd = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille))
  ) %>%
  mutate(
    se = sd / sqrt(n),
    ci95 = se * qt(0.975, df = n - 1)
  )

# Définir des couleurs rouges avec différentes opacités
red_colors <- c("tailleS1" = "#FF6666",  # clair
                "tailleS2" = "#FF3333",  # moyen
                "tailleS3" = "#CC0000")  # foncé

# Graphique avec les trois tailles côte à côte par site
ggplot(stats_long, aes(x = site, y = mean, fill = taille_type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = mean - ci95, ymax = mean + ci95),
                position = position_dodge(width = 0.8), width = 0.2) +
  scale_fill_manual(values = red_colors) +
  labs(
    title = "Taille moyenne par site avec IC 95%",
    y = "Taille moyenne",
    x = "Site",
    fill = "Type de taille"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#tableau lecture simple
tab_taille <- stats_long %>%
  mutate(
    mean  = round(mean, 2),
    sd    = round(sd, 2),
    se    = round(se, 2),
    ci95  = round(ci95, 2)
  ) %>%
  arrange(site, taille_type)

tab_taille %>%
  kbl(
    booktabs = TRUE,
    caption = "Taille moyenne par site et type de mesure avec IC 95%"
  ) %>%
  kable_classic(full_width = FALSE)

```
Méthode d'interprétation : Le graphique montre la taille moyenne des individus par sites et par session avec les barres d’erreur représentant l’intervalle de confiance à 95 %. Le tableau présente, pour chaque site et chaque session, la taille moyenne observée ainsi que les indicateurs de variabilité associés. Les colonnes indiquent l’écart‑type, le nombre d’individus mesurés, l’erreur standard et l’intervalle de confiance à 95 %, ce qui permet d’évaluer la précision des moyennes. Chaque ligne correspond donc à une combinaison site × session et résume la valeur moyenne et la fiabilité statistique de cette estimation.

Résultats : Les sites présentent des dynamiques de taille différentes. À Tête Cendrée Bas, les tailles sont globalement élevées et augmentent légèrement entre S1 et S3, mais les faibles effectifs rendent les intervalles de confiance plus larges. À Tête Cendrée Haut, les tailles sont plus faibles mais progressent régulièrement, avec des estimations précises grâce à des effectifs importants. Val Clavin est le site où les tailles sont les plus grandes, avec une forte hausse entre S1 et S2 suivie d’une stabilisation, et des intervalles de confiance raisonnables malgré des effectifs modestes. Enfin, à Vigne au Renard, les tailles sont intermédiaires, augmentent légèrement entre S1 et S2 puis se stabilisent, avec des intervalles de confiance un peu plus larges mais une tendance générale nette.

### Effet du site sur la phénologie

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Transformer les phénos en format long en gardant les NA
pheno_long <- data_original %>%
  dplyr::select(site, phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = c(phenoS1, phenoS2, phenoS3),
    names_to = "pheno_type",
    values_to = "pheno"
  ) %>%
  # Remplacer NA par un label pour garder comme modalité
  mutate(pheno = ifelse(is.na(pheno), "NA", as.character(pheno)))

# Calcul des effectifs par site et type phénologique
pheno_stats <- pheno_long %>%
  group_by(site, pheno) %>%
  summarise(n = n(), .groups = "drop") %>%
  complete(site, pheno, fill = list(n = 0)) %>%  # inclure les combinaisons manquantes
  mutate(
    # IC 95% approximatif pour comptages (Poisson)
    se = sqrt(n),
    ci_lower = pmax(n - 1.96 * se, 0),
    ci_upper = n + 1.96 * se
  )

# Définir l'ordre des phénos
pheno_stats$pheno <- factor(pheno_stats$pheno, levels = c("j", "nf", "f", "ff", "F", "NA"))

# Graphique avec barres côte à côte et IC 95%
ggplot(pheno_stats, aes(x = site, y = n, fill = pheno)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
                position = position_dodge(width = 0.8), width = 0.2, color = "black") +
  scale_fill_manual(values = c(
    "j"  = "#FF9999",
    "nf" = "#FF4D4D",
    "f"  = "#CC0000",
    "ff" = "#990000",
    "F"  = "#660000",
    "NA" = "#000000"  # noir pur pour NA
  )) +
  labs(
    title = "Effet du site sur la phénologie",
    x = "Site",
    y = "Nombre d'individus",
    fill = "Type phénologique"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#tableau lecture simple
tab_pheno <- pheno_stats %>%
  mutate(
    n        = round(n, 0),
    se       = round(se, 2),
    ci_lower = round(ci_lower, 2),
    ci_upper = round(ci_upper, 2)
  ) %>%
  arrange(site, pheno)

tab_pheno %>%
  kbl(
    booktabs = TRUE,
    caption = "Effectifs par site et type phénologique avec IC 95% (approximation Poisson)"
  ) %>%
  kable_classic(full_width = FALSE)

```
Méthode d'interprétation : Le graphique montre la nombre d'individu par sites et par phénologie avec les barres d’erreur représentant l’intervalle de confiance à 95 %. Ce tableau présente, pour chaque site et chaque type phénologique, le nombre d’individus observés ainsi que l’incertitude associée à ces effectifs. Les colonnes indiquent l’erreur standard et les bornes de l’intervalle de confiance à 95 %, ce qui permet d’évaluer la précision des comptages. Chaque ligne correspond à une combinaison site × phéno et résume combien d’individus ont été observés dans chaque catégorie phénologique, ainsi que la fiabilité statistique de cette estimation.

Résultats : Les sites présentent des profils phénologiques contrastés. À Combe Michaut, tous les stades sont représentés, avec une forte présence des stades précoces et intermédiaires. À Tête Cendrée Bas, seuls les stades précoces sont observés, les stades reproducteurs étant absents, ce qui reflète une phénologie très peu avancée. À Tête Cendrée Haut, les stades précoces dominent également, avec très peu d’individus dans les stades avancés. Val Clavin présente une gamme complète de stades, incluant des stades reproducteurs plus avancés. Enfin, à Vigne au Renard, tous les stades sont présents mais en effectifs plus faibles, tout en montrant une progression phénologique plus marquée que dans les sites les plus précoces.

## --------------

## III_ii Effet de la strate

### Effet de la strate sur la taille

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Joindre les données par ID_Quadrat
data_joined <- data_original %>%
  left_join(recouvrement, by = c("ID_quadrat" = "ID_Quadrat"))

# Calcul de la taille moyenne par individu
data_joined <- data_joined %>%
  mutate(
    tailleS1 = as.numeric(gsub(",", ".", tailleS1)),
    tailleS2 = as.numeric(gsub(",", ".", tailleS2)),
    tailleS3 = as.numeric(gsub(",", ".", tailleS3)),
    taille_moyenne = rowMeans(dplyr::select(., tailleS1, tailleS2, tailleS3), na.rm = TRUE)
  )

# Transformer les strates en format long pour facettes
recouvrement_long <- data_joined %>%
  pivot_longer(
    cols = c(S_muscinale, S_herbacee, S_arbustive_basse, S_arbustive_haute, S_arborescente),
    names_to = "strate",
    values_to = "recouvrement"
  )

# Formule pour afficher R² et p-value
eqn <- ggpmisc::stat_poly_eq(
  aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")),
  formula = y ~ x,
  parse = TRUE,
  label.x.npc = "right",
  label.y.npc = 0.1,
  size = 3
)

# Graphique par strate avec couleurs modifiées
ggplot(recouvrement_long, aes(x = recouvrement, y = taille_moyenne)) +
  geom_point(alpha = 0.7, color = "black") +  # points noirs
  geom_smooth(method = "lm", se = TRUE, color = "#CC0000", fill = "#FF9999") +  # ligne rouge foncé, IC rouge clair
  eqn +
  facet_wrap(~ strate, scales = "free_x") +
  labs(
    title = "Taille moyenne en fonction du recouvrement végétal par strate",
    x = "Recouvrement (%)",
    y = "Taille moyenne"
  ) +
  theme_minimal()
```
Méthode d'interprétation : Nous cherchons simplement à vérifier s’il existe une relation entre la taille moyenne des individus et le taux de recouvrement végétal des différentes strates. La droite de régression indique la tendance générale, tandis que le R² montre à quel point cette tendance explique réellement la variation de taille, et la p‑value indique si cette relation est statistiquement fiable. 

Résultats : La strate arborescente montre une relation positive et significative : plus le recouvrement est élevé, plus les individus sont grands (R² = 0.21, p < 0.001), ce qui suggère un effet structurant fort. La strate arbustive basse présente aussi une relation positive, mais plus faible (R² = 0.08), indiquant un effet modéré. En revanche, les strates arbustive haute, herbacée et muscinale ne montrent pas de relation claire ou significative : les R² sont très faibles (< 0.05) et les p‑values élevées ou marginales, ce qui signifie que le recouvrement dans ces strates n’explique pas la variation de taille. 

### Effet de la strate sur la phénologie

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Phénologie en format long
pheno_long <- data_original %>%
  dplyr::select(ID_quadrat, phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = starts_with("pheno"),
    names_to = "session",
    values_to = "pheno"
  ) %>%
  mutate(pheno = ifelse(is.na(pheno), "NA", pheno))

# Tableau de contingence (fréquences)
pheno_tab <- pheno_long %>%
  group_by(ID_quadrat, pheno) %>%
  summarise(n = n(), .groups = "drop") %>%
  pivot_wider(
    names_from = pheno,
    values_from = n,
    values_fill = 0
  )

data_rda <- pheno_tab %>%
  left_join(recouvrement, by = c("ID_quadrat" = "ID_Quadrat")) %>% dplyr::select(-"NA")

# Variables explicatives (recouvrement)
X <- data_rda %>%
  dplyr::select(
    S_muscinale,
    S_herbacee,
    S_arbustive_basse,
    S_arbustive_haute,
    S_arborescente
  )

Y <- data_rda %>%
  dplyr::select(j, nf, f, ff, F)

# Hellinger (très recommandé)
Y_hel <- decostand(Y, method = "hellinger")

X <- data_rda %>%
  dplyr::select(
    S_muscinale,
    S_herbacee,
    S_arbustive_basse,
    S_arbustive_haute,
    S_arborescente
  )

rda_pheno <- rda(Y_hel ~ ., data = X)

plot(rda_pheno, scaling = 2)

a_1<- anova(rda_pheno)          # effet global du recouvrement
a_2<-anova(rda_pheno, by="term") # effet de chaque strate
a_3<- anova(rda_pheno, by="axis")  # axes significatifs

#Tableau lecture simple 

# Tableau 1 : effet global du recouvrement
a_1 %>%
  kbl(caption = "Effet global du recouvrement sur la phénologie (RDA)",
      booktabs = TRUE) %>%
  kable_classic(full_width = FALSE)

# Tableau 2 : effet de chaque strate
a_2 %>%
  kbl(caption = "Effet individuel de chaque strate sur la phénologie (RDA)",
      booktabs = TRUE) %>%
  kable_classic(full_width = FALSE)

# Tableau 3 : axes significatifs
a_3 %>%
  kbl(caption = "Significativité des axes RDA",
      booktabs = TRUE) %>%
  kable_classic(full_width = FALSE)

```
Méthode d'interpretation : La RDA permet d’évaluer si les variables environnementales, ici les différentes strates de recouvrement, expliquent la variation d’un ensemble de variables biologiques, en l’occurrence la phénologie. Le premier tableau teste l’effet global : il indique si l’ensemble des strates, prises ensemble, influence significativement la phénologie. Le second tableau examine l’effet individuel de chaque strate, en testant séparément si chacune contribue de manière significative à expliquer la variation phénologique. Enfin, le troisième tableau teste la significativité des axes RDA, c’est‑à‑dire si les gradients principaux extraits par l’analyse représentent des structures réelles dans les données ou seulement du bruit. Ensemble, ces trois tableaux permettent de savoir si le recouvrement influence la phénologie, quelles strates sont responsables de cet effet, et si les axes produits par la RDA sont interprétables

Résultats : L’effet global du recouvrement sur la phénologie n’est pas significatif (p = 0.19), ce qui indique que, dans l’ensemble, les strates végétales n’expliquent pas fortement la variation phénologique entre quadrats. Lorsqu’on examine les strates individuellement, seule la strate arbustive basse présente un effet significatif (p = 0.037), suggérant qu’elle influence modestement la distribution des stades phénologiques. Les autres strates (muscinale, herbacée, arbustive haute, arborescente) ne montrent aucun effet détectable. Enfin, aucun des axes RDA n’est significatif (tous p > 0.15), ce qui confirme que la structure ordonnée extraite par la RDA est faible et que les gradients phénologiques ne sont pas clairement associés aux gradients de recouvrement. En résumé, le recouvrement végétal n’explique que très faiblement la phénologie, avec un signal limité provenant de la strate arbustive basse.

## --------------

# IV\_ Niveau des observateurs

Nous avons distingué trois variables mesurées. Le risque d’erreur correspond à l’estimation que les observateurs font de leur propre fiabilité, basée sur leur auto‑évaluation dans le questionnaire. Le taux d’erreur désigne les cas où l’observateur a bien détecté l’individu, mais a attribué une phénologie incorrecte. Enfin, le taux de détection correspond simplement au fait que l’observateur a vu et signalé l’individu.

## Adéquation et fiabilité des observateurs

```{r, echo=FALSE, message=FALSE, warning=FALSE, results=FALSE}

# ------------------------------------------------------------
# 1. Taux d’erreur d’adéquation par observateur
# ------------------------------------------------------------

verification3 <- verification %>% 
  group_by(observateur) %>% 
  count(adequation) %>% 
  pivot_wider(
    names_from = adequation,
    values_from = n,
    names_glue = "{ifelse(adequation == 1, 'id_valide', 'id_fausse')}"
  ) %>% 
  replace_na(list(
    id_valide = 0,
    id_fausse = 0
  )) %>% 
  mutate(
    id_total = id_valide + id_fausse,
    tx_erreur = id_fausse / id_total
  )

verification3 <- verification3 %>%
  left_join(
    experience %>% dplyr::select(Observateur, sexe),
    by = c("observateur" = "Observateur")
  )

# Vérification des adéquations manquantes
verification %>% 
  filter(is.na(adequation))

# ------------------------------------------------------------
# 2. Score moyen d’auto-évaluation (A à E)
# ------------------------------------------------------------

experience <- experience %>%
  mutate(
    score_moyen = rowMeans(across(A:E), na.rm = TRUE),
    fiabilite = score_moyen / 10,
    risque_erreur = 1 - fiabilite
  )

# Variabilité intra-observateur
experience <- experience %>%
  rowwise() %>%
  mutate(ecart_type = sd(c_across(A:E), na.rm = TRUE)) %>%
  ungroup()

# Classement par risque d’erreur
experience <- experience %>%
  arrange(desc(risque_erreur)) %>%
  mutate(ID.observateur = factor(ID.observateur, levels = ID.observateur))

# ------------------------------------------------------------
# 3. Fusion auto-évaluation / adéquation réelle
# ------------------------------------------------------------

experience2 <- experience %>% 
  inner_join(
    verification3,
    by = join_by("Observateur" == "observateur")
  )


# ------------------------------------------------------------
# 4. Taux de détection réel par observateur
# ------------------------------------------------------------

tx_erreur <- tab_complet %>% 
  group_by(observateur) %>% 
  summarise(
    nb_ind = n(),
    nb_detect = sum(detection, na.rm = TRUE),
    tx_detect = nb_detect / nb_ind
  )

tx_erreur_fin <- experience2 %>% 
  inner_join(
    tx_erreur,
    by = join_by("Observateur" == "observateur")
  )

# ------------------------------------------------------------
# 5. Graphiques
# ------------------------------------------------------------

```

### Erreur d’attribution phénologique vs non-détection

```{r}

ggplot(tx_erreur_fin, aes(x = tx_erreur, y = 1 - tx_detect)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre taux d'erreur d'attribution et non-détection",
    x = "Taux d'erreur d'attribution de la phénologie",
    y = "Taux de non-détection",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Autonotation vs erreur d'attribution phénologique

```{r}
ggplot(tx_erreur_fin, aes(x = risque_erreur, y = tx_erreur)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre risque d'erreur (auto-évaluation) et erreur d'attribution",
    x = "Risque d'erreur basé sur l'auto-évaluation",
    y = "Taux d'erreur d'attribution de la phénologie",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Autonotation vs non-détection

```{r}
ggplot(tx_erreur_fin, aes(x = risque_erreur, y = 1 - tx_detect)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre risque d'erreur (auto-évaluation) et non-détection",
    x = "Risque d'erreur basé sur l'auto-évaluation",
    y = "Taux de non-détection",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Analyses complémentaires

```{r}
# ------------------------------------------------------------
# Visualisation des 3 axes en 3D 
# ------------------------------------------------------------

# Graphique 3D interactif avec taille fixe
plot_ly(
  tx_erreur_fin,
  x = ~tx_erreur,
  y = ~risque_erreur,
  z = ~ (1 - tx_detect),
  type = "scatter3d",
  mode = "markers+text",
  text = ~Observateur,
  textposition = "top center",
  marker = list(
    size = 5,  # taille fixe pour tous les points
    color = ~ifelse(sexe.x == "f", "#E41A1C", "#377EB8"),
    opacity = 0.8
  ),
  hovertemplate = paste(
    "<b>%{text}</b><br>",
    "Sexe: %{customdata[0]}<br>",
    "Taux erreur: %{x}<br>",
    "Risque auto: %{y}<br>",
    "Non-détection: %{z}<br>",
    "<extra></extra>"
  ),
  customdata = tx_erreur_fin[, c("sexe.x")]
) %>%
  layout(
    scene = list(
      xaxis = list(title = "Taux d'erreur d'attribution"),
      yaxis = list(title = "Risque d'erreur (auto-évaluation)"),
      zaxis = list(title = "Taux de non-détection")
    ),
    title = "Graphique 3D interactif des erreurs et non-détection"
  )

# ------------------------------------------------------------
# Corrélation
# ------------------------------------------------------------

cor.test(
  tx_erreur_fin$tx_detect,
  tx_erreur_fin$tx_erreur,
  method = "spearman"
)

# ------------------------------------------------------------
# Modèles linéaires
# ------------------------------------------------------------

model1_autonotation <- lm(
  risque_erreur ~ tx_erreur + tx_detect,
  data = tx_erreur_fin
)

model2_autonotation <- lm(
  risque_erreur ~ tx_detect,
  data = tx_erreur_fin
)

model3_autonotation <- lm(
  risque_erreur ~ tx_erreur,
  data = tx_erreur_fin
)

summary(model1_autonotation)
anova(model1_autonotation)

summary(model2_autonotation)
anova(model2_autonotation)

summary(model3_autonotation)
anova(model3_autonotation)

# ------------------------------------------------------------
# Comparaison des modèles
# ------------------------------------------------------------

AIC(model1_autonotation, model2_autonotation, model3_autonotation)

```

# --------------------------------------------------

# PROBABILITE DE DETECTION

## --------------

## V_i GLM

```{r}
# On a plusieurs strates et on veut seulement une covariable "recouvrement". On utilise donc une ACP pour avec l'inertie sur PC1.

# Extraire juste les colonnes numériques pour la PCA
recouvrement_num <- tab_complet %>%
  ungroup() %>%  # enlever le grouping
  dplyr::select(S_muscinale:S_arborescente) %>%
  mutate(across(everything(), as.numeric)) %>%
  as.data.frame()

# Vérifier
str(recouvrement_num)

acp1 <- dudi.pca(recouvrement_num, scale=T, center=T, scannf=F, nf=4)

#Calcul des % de chaque axe :
pc<-round(acp1$eig/sum(acp1$eig)*100,2)
pc

# % cumulés
cumsum(pc) 

#visualisation sur un graph
barplot(acp1$eig)

###Graphique de l'ACP####
s.corcircle(acp1$co, xax=1, yax=2, box = F, clabel = 0.5) 

# Ajouter la première et deuxième composante au tableau
tab_complet$recouvrement_PC1 <- acp1$li[,1]
tab_complet$recouvrement_PC2 <- acp1$li[,2]

# préparation variables pour GLMM
tab_complet <- tab_complet %>% 
  mutate(
    site = as.factor(site),
    session = as.factor(session),
    phenologie_verif = as.factor(phenologie_verif),
    taille = as.numeric(gsub(",", ".", taille)),
    ID_ind <- as.factor(ID_ind)
  )
str(tab_complet)

#Standardiser la taille sinon ça ne marche pas
tab_complet$taille_sc <- scale(tab_complet$taille)

tab_complet$ID_quadrat <- as.factor(tab_complet$ID_quadrat)

tx_erreur <- tab_complet %>% 
  group_by(observateur) %>% 
  summarise(
    nb_ind = n(),
    nb_detect = sum(detection, na.rm = TRUE),
    tx_detect = nb_detect / nb_ind
  )

tab_complet <- tab_complet %>% 
  left_join(
    tx_erreur,
    by = "observateur"
  )

experience_final <- experience %>% 
  mutate(observateur = Observateur) %>% 
  dplyr::select(observateur, risque_erreur)

tab_complet <- tab_complet %>% 
  left_join(experience_final, by = "observateur")

glmm_final <- glmer(
  detection ~ site * session + taille_sc + phenologie_verif + recouvrement_PC1 + recouvrement_PC2 + risque_erreur + (1|observateur) + (1|ID_ind) + (1|ID_quadrat),
  data = tab_complet,
  family = binomial,
  control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))
)

glmm_final <- glmer(
  detection ~ site * session + phenologie_verif + recouvrement_PC1 + recouvrement_PC2 + risque_erreur + (1|observateur) + (1|ID_ind) + (1|ID_quadrat) + (1|taille_sc),
  data = tab_complet,
  family = binomial,
  control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))
)

summary(glmm_final)
Anova(glmm_final, type = 3)

#prédictions marginales du modèle

#Pour l'axe 1 de l'ACP
emm_PC1 <- emmeans(
  glmm_final,
  ~ recouvrement_PC1,
  at = list(
    recouvrement_PC1 = seq(
      min(tab_complet$recouvrement_PC1, na.rm = TRUE),
      max(tab_complet$recouvrement_PC1, na.rm = TRUE),
      length.out = 100
    )
  ),
  type = "response"
)

emm_PC1_df <- as.data.frame(emm_PC1)

ggplot(emm_PC1_df, aes(x = recouvrement_PC1, y = prob)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL),
              alpha = 0.25) +
  labs(x = "Gradient de fermeture du milieu (axe 2 ACP)",
       y = "Probabilité de détection")+
  theme_minimal()

#pour l'axe 2 de l'ACP
emm_PC2 <- emmeans(
  glmm_final,
  ~ recouvrement_PC2,
  at = list(
    recouvrement_PC2 = seq(
      min(tab_complet$recouvrement_PC2, na.rm = TRUE),
      max(tab_complet$recouvrement_PC2, na.rm = TRUE),
      length.out = 100
    )
  ),
  type = "response"
)

emm_PC2_df <- as.data.frame(emm_PC2)

ggplot(emm_PC2_df, aes(x = recouvrement_PC2, y = prob)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL),
              alpha = 0.25) +
  labs(x = "Gradient de fermeture du milieu (axe 2 ACP)",
       y = "Probabilité de détection")+
  theme_minimal()

#pour le risque d'erreur lié à l'autonotation
emm_risque_erreur <- emmeans(
  glmm_final,
  ~ risque_erreur,
  at = list(
    risque_erreur = seq(
      min(tab_complet$risque_erreur, na.rm = TRUE),
      max(tab_complet$risque_erreur, na.rm = TRUE),
      length.out = 100
    )
  ),
  type = "response"
)

emm_risque_erreur_df <- as.data.frame(emm_risque_erreur)

ggplot(emm_risque_erreur_df, aes(x = risque_erreur, y = prob)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL),
              alpha = 0.25) +
  labs(x = "Risque d'erreur (basé sur autonotation des observateurs",
       y = "Probabilité de détection")+
  theme_minimal()

#pour la taille
#Préparer moyenne et écart type pour détransformer ma variable
mu_taille <- attr(tab_complet$taille_sc, "scaled:center")
sd_taille <- attr(tab_complet$taille_sc, "scaled:scale")
mu_taille
sd_taille

emm_taille <- emmeans(
  glmm_final,
  ~ taille_sc,
  at = list(
    taille_sc = seq(
      min(tab_complet$taille_sc, na.rm = TRUE),
      max(tab_complet$taille_sc, na.rm = TRUE),
      length.out = 100
    )
  ),
  type = "response"
)

emm_taille_df <- as.data.frame(emm_taille)

emm_taille_df$taille_reelle <-
  emm_taille_df$taille_sc * sd_taille + mu_taille

ggplot(emm_taille_df, aes(x = taille_reelle, y = prob)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL),
              alpha = 0.25) +
  labs(x = "Taille des individus (cm)",
       y = "Probabilité de détection")+
  theme_minimal()

#Pour l'interaction session x site
emm_site_session <- emmeans(
  glmm_final,
  ~ site * session,          # prédire toutes les combinaisons
  type = "response"          # retourne la probabilité (échelle 0-1)
)

# Convertir en data.frame pour ggplot
emm_site_session_df <- as.data.frame(emm_site_session)

ggplot(emm_site_session_df, aes(x = site, y = prob, fill = session)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL),
                position = position_dodge(width = 0.8),
                width = 0.2) +
  scale_y_continuous(limits = c(0,1)) +
  labs(
    x = "Site",
    y = "Probabilité de détection",
    fill = "Session",
    title = "Probabilité marginale de détection par site et session"
  ) +
  theme_classic(base_size = 14)

#Pour le stade phénologique
emm_phenologie <- emmeans(
  glmm_final,
  ~ phenologie_verif,          # prédire toutes les combinaisons
  type = "response"          # retourne la probabilité (échelle 0-1)
)

# Convertir en data.frame pour ggplot
emm_phenologie_df <- as.data.frame(emm_phenologie)

ggplot(emm_phenologie_df, aes(x = phenologie_verif, y = prob)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL),
                position = position_dodge(width = 0.8),
                width = 0.2) +
  scale_y_continuous(limits = c(0,1)) +
  labs(
    x = "Site",
    y = "Probabilité de détection",,
    title = "Probabilité marginale de détection par stade phénologique"
  ) +
  theme_classic(base_size = 14)


```

### Sélection de modèles

```{r}

# #Dredge ne fonctionne pas avec NA
# vars <- c("detection", "site", "session", "taille_sc",
#           "phenologie_verif", "recouvrement_PC1", "ID_ind")
# 
# tab_dredge <- tab_complet[complete.cases(tab_complet[, vars]), ]
# 
# #modèle complet
# glmm_global <- glmer(
#   detection ~ site + session + site:session + taille_sc + phenologie_verif + recouvrement_PC1 +
#     (1 | ID_ind),
#   data = tab_dredge,
#   family = binomial,
#   control = glmerControl(optimizer = "bobyqa",
#                          optCtrl = list(maxfun = 2e5))
# )
# 
# # Autoriser MuMIn à travailler avec glmer
# options(na.action = "na.fail")
# 
# # Sélection de modèle (toutes combinaisons de variables fixes)
# model_set <- dredge(glmm_global, trace = TRUE)
# 
# # Afficher les modèles triés par AICc
# model_set
# 
# model_set_df <- as.data.frame(model_set)
# 
# write.csv(
#   model_set_df,
#   file = "selection.csv",
#   row.names = FALSE
# )

```

## V_ii Détection de la phénologie

```{r}
unique(tab_complet$phenologie)
unique(tab_complet$phenologie_verif)

#création tableau
detect_comp <- tab_complet %>% 
  ungroup() %>% 
  filter(detection == 1) %>% #on ne garde que les individus détectés par les observateurs
  select(id_ind_fin,session,site,quadrat,marquage,phenologie_verif,phenologie)


unique(detect_comp$phenologie)
unique(detect_comp$phenologie_verif) #toujours des NA avec phénologie superviseuses

detect_comp %>% 
  filter(is.na(phenologie_verif))
#deux pheno non observées par superviseuses
tab_complet %>% 
  filter(id_ind_fin == "VC.Q4.45.3")
#Vu par un observateur/6

tab_complet %>% 
  filter(id_ind_fin == "VC.Q4.19.3")
#Vu par un observateur/6

#j'enlève ces deux individus des analyses
detect_comp <- detect_comp %>% 
  filter(!is.na(phenologie_verif))

#matrice de confusion
conf_mat <- table(
  phenologie_verif = tab_complet$phenologie_verif,
  phenologie = tab_complet$phenologie
)

conf_mat

#Version proportions
prop_conf_mat <- prop.table(conf_mat, margin = 1)

prop_conf_mat

#Transformer matrices en data frame
conf_df <- as.data.frame(conf_mat)
prop_df <- as.data.frame(prop_conf_mat)

# Renommage explicite (évite TOUS les bugs)
names(conf_df) <- c("phenologie_verif", "phenologie", "n")
names(prop_df) <- c("phenologie_verif", "phenologie", "prob")

#Tableau graphique
heat_df <- conf_df %>%
  left_join(prop_df,
            by = c("phenologie_verif", "phenologie")) %>%
  mutate(
    correct = phenologie_verif == phenologie,
    signed_prob = ifelse(correct, prob, -prob)
  )

#standardisation de mes probas pour que ça rende joli sur le graphique
heat_df <- heat_df %>%
  mutate(
    signed_prob_scaled = case_when(
      correct ~ prob / max(prob[correct]),               # 0 → 1 pour les bons
      !correct ~ -prob / max(prob[!correct])              # 0 → -1 pour les erreurs
    )
  )

#Heat map avec le nombre d'observations
ggplot(heat_df,
       aes(x = phenologie, y = phenologie_verif)) +
  
  geom_tile(aes(fill = signed_prob_scaled)) +
  
  geom_text(aes(label = n), size = 4, color = "black") +
  
  scale_fill_gradient2(
    low = "darkred",
    mid = "white",
    high = "darkgreen",
    midpoint = 0,
    limits = c(-1, 1),
    name = "Qualité d'observation\n(échelle relative)"
  ) +
  
  labs(
    x = "Phénologie observée",
    y = "Phénologie vérifiée",
    title = "Matrice de confusion – phénologie Sabot de Vénus",
    subtitle = "Vert = bonnes classifications | Rouge = erreurs"
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )

#Heat map avec les proportions
ggplot(heat_df,
       aes(x = phenologie, y = phenologie_verif)) +
  
  geom_tile(aes(fill = signed_prob_scaled)) +
  
  geom_text(aes(label = round(prob,2)), size = 4, color = "black") +
  
  scale_fill_gradient2(
    low = "darkred",
    mid = "white",
    high = "darkgreen",
    midpoint = 0,
    limits = c(-1, 1),
    name = "Qualité d'observation\n(échelle relative)"
  ) +
  
  labs(
    x = "Phénologie observée",
    y = "Phénologie vérifiée",
    title = "Matrice de confusion – phénologie Sabot de Vénus",
    subtitle = "Vert = bonnes classifications | Rouge = erreurs"
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )

#Si on veut faire la même chose par sites
conf_par_site <- tab_complet %>%
  group_by(site) %>%
  summarise(
    conf = list(table(phenologie_verif, phenologie)),
    .groups = "drop"
  )

prop.table(conf_par_site$conf[[1]], margin = 1)
prop.table(conf_par_site$conf[[2]], margin = 1)
prop.table(conf_par_site$conf[[3]], margin = 1)
prop.table(conf_par_site$conf[[4]], margin = 1)
prop.table(conf_par_site$conf[[5]], margin = 1)





```

# --------------------------------------------------

# CMR

## --------------

## VII_iAnalyse des transitions phénologiques avec et sans MARK ###VII_i.i Toutes transitions

```{r}
# -------------------------------
# 1. Charger les données
# -------------------------------
data<- data_original

# -------------------------------
# 2. Préparer les données phénologiques
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS1, phenoS2, phenoS3) %>%
  mutate(
    phenoS1 = phenology_codes[phenoS1],
    phenoS2 = phenology_codes[phenoS2],
    phenoS3 = phenology_codes[phenoS3]
  )

# Supprimer les individus avec NA dans phenoS1, phenoS2 ou phenoS3
phenology_data_numeric <- phenology_data_numeric %>%
  filter(!is.na(phenoS1) & !is.na(phenoS2) & !is.na(phenoS3))

# -------------------------------
# 3. Calcul empirique des transitions 1 → 2 → 3
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS1, phenoS2, phenoS3),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Calculer les transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Créer le champ "ch" pour MARK
# -------------------------------
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS1, phenoS2, phenoS3))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 3))

# -------------------------------
# 6. Préparer les données pour RMark
# -------------------------------
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1", "2", "3", "4", "5")
)

ms_ddl <- make.design.data(ms_data)

# -------------------------------
# 7. Modèle Multistrata avec RMark
# -------------------------------
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

### VII_i.ii Transitions session 1 → 2

```{r}
###MARK Session 1-2 ----

# -------------------------------
# 1. Charger les données
# -------------------------------
data <- data_original

# -------------------------------
# 2. Préparer les données phénologiques (sessions 1 et 2)
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS1, phenoS2) %>%
  mutate(
    phenoS1 = as.character(phenology_codes[phenoS1]),
    phenoS2 = as.character(phenology_codes[phenoS2])
  ) %>%
  # Supprimer les individus avec NA dans phenoS1 ou phenoS2
  filter(!is.na(phenoS1) & !is.na(phenoS2))

# -------------------------------
# 3. Calcul empirique des transitions 1 → 2
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS1, phenoS2),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation des transitions avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Partie RMark
# -------------------------------
# Créer le champ "ch" pour MARK
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS1, phenoS2))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 2))

# Préparer les données pour RMark
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1","2","3","4","5")
)

ms_ddl <- make.design.data(ms_data)

# Modèle Multistrata avec RMark
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

### VII_i.iii Transitions session 2 → 3

```{r}
###MARK Session 2-3 ----

# -------------------------------
# 1. Charger les données
# -------------------------------
data <- data_original

# -------------------------------
# 2. Préparer les données phénologiques (sessions 2 et 3)
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS2, phenoS3) %>%
  mutate(
    phenoS2 = as.character(phenology_codes[phenoS2]),
    phenoS3 = as.character(phenology_codes[phenoS3])
  ) %>%
  # Supprimer les individus avec NA dans phenoS2 ou phenoS3
  filter(!is.na(phenoS2) & !is.na(phenoS3))

# -------------------------------
# 3. Calcul empirique des transitions 2 → 3
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS2, phenoS3),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation des transitions avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Partie RMark
# -------------------------------
# Créer le champ "ch" pour MARK
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS2, phenoS3))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 2))

# Préparer les données pour RMark
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1","2","3","4","5")
)

ms_ddl <- make.design.data(ms_data)

# Modèle Multistrata avec RMark
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

## --------------

#TEST RMARK

```{r}
#Faire le tableau propre
verification %>%
  mutate(site=as.factor(site),
         date=date(date),
         ID_quadrat=as.factor(ID_quadrat),
         ID_ind=as.factor(ID_ind),
         observateur=as.factor(observateur)) %>%
  rowwise() %>%
  mutate(detecte=sum(juv, non_fleuri, fleur, fleurs_fanees, fruit)) -> data_imp


data_original %>%
  mutate(site=as.factor(site),
         ID_quadrat=as.factor(ID_quadrat),
         ID_ind=as.factor(ID_ind),
         phenoS1=as.factor(phenoS1),
         phenoS2=as.factor(phenoS2),
         phenoS3=as.factor(phenoS3)) -> taille_pheno

data_original %>%
  pivot_longer(cols=c(phenoS1, phenoS2, phenoS3), names_prefix = "phenoS", names_to = "session", values_to = "stade_pheno") %>%
  mutate(session=as.numeric(session)) %>%
  select(site, ID_quadrat, ID_ind, session, stade_pheno) -> pheno 

data_original %>%
  pivot_longer(cols=c(tailleS1, tailleS2, tailleS3), names_prefix = "tailleS", names_to = "session", values_to = "taille") %>%
  mutate(session=as.numeric(session)) %>%
  select(site, ID_quadrat, ID_ind, session, taille) -> taille


# visualisation des changements phéno
pheno %>%
  pivot_wider(names_from=session, id_cols = "ID_ind", values_from = "stade_pheno", names_prefix = "session") -> evo_pheno

evo_pheno %>%
  filter(!ID_ind%in%"CM.Q5.10") %>%
  group_by(session1, session2, session3) %>%
  summarise(n=n()) -> recap_pheno

# jointure avec données détectins individuelles et infos pheno/taille
data_imp %>%
  select(-site) %>%
  left_join(pheno) %>%
  left_join(taille) -> data

# on importe les infos observateurs / numéros de sessions 
obs_session <- readr::read_csv2("data/raw/obs_session.csv")
obs_session %>%
  dplyr::mutate(ID_quadrat = as.factor(ID_quadrat),
                observateur = as.factor(observateur),
                num_obs=as.factor(num_obs)) -> obs_session

obs_session %>%
  mutate(val=1) %>%
  pivot_wider(names_from = c(session,num_obs), values_from = val, id_cols=ID_quadrat) -> recap_sessions_obs


# on indique l'effort pour les observateurs manquants sur des quadrats, on reporte ensuite cette info aux individus
recap_sessions_obs %>%
  pivot_longer(cols=2:19,  names_to = "session_obs", values_to = "prospecte") %>%
  mutate(session=str_sub(session_obs, 1,1),
         session=as.numeric(session),
         num_obs=str_sub(session_obs, 3,6),
         num_obs=as.factor(num_obs)) %>%
  left_join(obs_session) -> effort


data %>%
  select(ID_quadrat, ID_ind) %>%
  group_by(ID_ind) %>%
  slice(1) -> ind_quadrat


ind_quadrat %>%
  left_join(effort) -> effort_inds


# histoires de détection individuelles avec les stades phénos pour multistate. 
effort_inds %>%
  left_join(data) %>%
  select(session, ID_ind, num_obs, stade_pheno, prospecte) %>%
  mutate(pheno_lettres = case_when(stade_pheno%in% "j" ~ "A",
                                   stade_pheno%in% "nf" ~ "B",
                                   stade_pheno%in% "f" ~ "C",
                                   stade_pheno%in% "ff" ~ "D",
                                   stade_pheno%in% "F"~ "E"),
         etat_prosp= case_when(prospecte==1~pheno_lettres, 
                               is.na(prospecte)~".")) %>% 
  arrange(session, num_obs) %>%
  pivot_wider(names_from = c(session,num_obs), values_from = etat_prosp, id_cols=ID_ind) %>%
  replace(is.na(.),"0") -> hist_det
  
hist_long <- hist_det %>%
  pivot_longer(
    cols = -ID_ind,
    names_to = "sess_obs",
    values_to = "etat"
  ) %>%
  mutate(
    session = as.integer(str_sub(sess_obs, 1, 1)),
    obs = str_extract(sess_obs, "obs[0-9]+")
  )

histories_for_mark <- hist_long %>%
  arrange(ID_ind, obs, session) %>%
  group_by(ID_ind, obs) %>%
  summarise(
    ch = paste0(etat, collapse = ""),
    .groups = "drop"
  )
  
histories_clean <- histories_for_mark %>%
  mutate(ID_obs = paste(ID_ind, obs, sep = "_")) %>%
  select(ID_obs, ch)

histories_valid <- histories_clean %>%
  # garder seulement les lignes qui ont au moins un A ou B
  filter(grepl("[A-Z]", ch))

histories_valid2 <- histories_valid %>%
  filter(!grepl("obs6", ID_obs))

# 2. Définir time.intervals : longueur = T - 1 = 2

# Si tu n'as pas de covariables individuelles prêtes, on utilise juste ID et ch
histories_for_mark <- histories_valid2 %>% select(ID_obs, ch)

# vérifier les chaînes
table(nchar(histories_for_mark$ch))
unique(head(histories_for_mark$ch, 20))

# définir time.intervals (T = longueur des ch ; ici T = 3 => length = 2)
T <- unique(nchar(histories_for_mark$ch))
time.intervals <- rep(1, as.integer(T) - 1)

# Process data en Multistrata : indiquer les labels d'états présents
# RMark attend : lettres pour états et "0" pour non-observé — c'est ton cas
states <- c("A","B","C","D","E")   # adapte si tu as d'autres états
```

# Multistrata

```{r}
processed_ms <- process.data(histories_for_mark, model = "Multistrata",
                             time.intervals = time.intervals,
                             strata.labels = states)

ddl_ms <- make.design.data(processed_ms)

# Exemple de modèles simples
S.const <- list(formula = ~1)                       # survie constante
p.bystratum <- list(formula = ~ stratum)            # p dépend de l'état observé
Psi.bystratum <- list(formula = ~ stratum)          # transitions dépendant de l'état de départ

# Lancer un modèle multistate simple
model_ms <- mark(processed_ms, ddl_ms,
                 model.parameters = list(S = S.const, p = p.bystratum, Psi = Psi.bystratum))

summary(model_ms)

```

Résultat correcte pour A et B et pour D et E résultats completement aberrants

#Autres modèles

```{r}

# 5. lancer modèles parcimonieux (Multistrata)
mA <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),       # survie constante
  p   = list(formula = ~stratum), # détection selon état
  Psi = list(formula = ~1)        # transitions constantes
))

mB <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~1),
  Psi = list(formula = ~stratum)
))

mC <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~stratum),
  Psi = list(formula = ~stratum)
))

# 6. comparer
models <- collect.models()
model.table(models)


```

#Prendre le recouvrement en compte

```{r}
# 1. Sécuriser noms et types
histories_for_mark <- histories_for_mark %>%
  rename_with(~ as.character(.), everything())

tab_complet <- tab_complet %>%
  rename_with(~ as.character(.), everything())

# 2. Extraire ID_ind depuis ID_obs (tout avant le premier "_")
histories_tmp <- histories_for_mark %>%
  mutate(ID_ind = sub("_.*$", "", as.character(ID_obs)),
         ID_ind = str_trim(ID_ind))

# 3. Préparer tab_complet : ID_ind + covariables à joindre
tab_tmp <- tab_complet %>%
  mutate(ID_ind = as.character(ID_ind),
         ID_ind = str_trim(ID_ind)) %>%
  select(ID_ind,
         recouvrement_PC1,
         site,
         session,
         taille,
         quadrat)

# 4. Jointure des covariables
histories_with_recov <- histories_tmp %>%
  left_join(tab_tmp, by = "ID_ind")

# 5. Conserver la structure d'origine + nouvelles colonnes
histories_for_mark_final <- histories_with_recov %>%
  select(all_of(names(histories_for_mark)),
         recouvrement_PC1,
         site,
         session,
         taille,
         quadrat)

# 6. Contrôles rapides
n_total <- nrow(histories_for_mark_final)
n_missing <- sum(is.na(histories_for_mark_final$recouvrement_PC1))
message("Total lignes : ", n_total,
        " — lignes sans recouvrement_PC1 après jointure : ", n_missing)

# 7. Préparation finale : ID_ind + centrage de la covariable continue
histories_for_mark_final <- histories_for_mark_final %>%
  mutate(ID_ind = sub("_.*$", "", as.character(ID_obs)),
         recouvrement_PC1 = as.numeric(recouvrement_PC1),
         taille = as.numeric(taille),
         recov_c = recouvrement_PC1 - mean(recouvrement_PC1, na.rm = TRUE))

# 8. Vérifier longueurs des chaînes ch
len_tab <- table(nchar(histories_for_mark_final$ch))
if (length(len_tab) != 1)
  stop("Les chaînes ch n'ont pas toutes la même longueur")

T <- as.integer(names(len_tab)[1])
time.intervals <- rep(1, T - 1)

# 9. Définir états présents (exclure '0' et '.')
states <- sort(
  setdiff(
    unique(unlist(strsplit(paste(histories_for_mark_final$ch,
                                 collapse = ""), ""))),
    c("0", ".")
  )
)
message("États détectés : ", paste(states, collapse = ", "))

# 10. Table pour process.data : ID, ch + covariables individuelles
histories_rmark <- histories_for_mark_final %>%
  transmute(ID = ID_obs,
            ch = ch,
            recov_c,
            site,
            session,
            taille,
            quadrat)

# 11. process.data Multistrata
processed_ms <- process.data(histories_rmark,
                             model = "Multistrata",
                             time.intervals = time.intervals,
                             strata.labels = states)

# 12. design data
ddl_ms <- make.design.data(processed_ms)

# Modèle 1 : base parcimonieuse (S constant, p selon état, Psi constant)
m1 <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~ stratum),
  Psi = list(formula = ~1)
))

# Modèle 2 : p constant, Psi selon état (test de structure)
m2 <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~1),
  Psi = list(formula = ~ stratum)
))

# Modèle 3 : modèle complet sans covariable (S constant, p ~ stratum, Psi ~ stratum)
m3 <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~ stratum),
  Psi = list(formula = ~ stratum)
))

# Modèle 4 : inclure recouvrement_PC1 (cov individuelle) sur S
m4 <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~ recov_c),
  p   = list(formula = ~ stratum),
  Psi = list(formula = ~ stratum)
))

# Modèle 5 : 
m5 <- mark(processed_ms, ddl_ms, model.parameters = list( 
S = list(formula = ~1), 
p = list(formula = ~ stratum + recov_c), 
Psi = list(formula = ~ stratum) ))

# Modèle 5 : 
m5 <- mark(processed_ms, ddl_ms, model.parameters = list( 
S = list(formula = ~ 1), 
p = list(formula = ~ stratum + recov_c), 
Psi = list(formula = ~ stratum) ))


# Rassembler et comparer
models_list <- list(m1 = m1, m2 = m2, m3 = m3, m4 = m4, m5 =m5)
model.table(models_list)

processed_ms <- process.data(
  histories_rmark,
  model = "Multistrata",
  time.intervals = time.intervals,
  strata.labels = states,
  groups = "site"
)

ddl_ms <- make.design.data(processed_ms)

m6 <- mark(
  processed_ms,
  ddl_ms,
  model.parameters = list(
    S   = list(formula = ~ group),                 # survie différente selon site
    p   = list(formula = ~ stratum + recov_c),     # détection selon état + recouvrement
    Psi = list(formula = ~ stratum)                # transitions selon état
  )
)

models_list <- list(m6=m6)
model.table(models_list)
```

# CRDMS

processed_crdms \<- process.data(histories_rmark, model = "CRDMS", time.intervals = time.intervals_crdms, strata.labels = states)

# 12. design data

ddl_crdms \<- make.design.data(processed_crdms)

# Modèle 1 : base parcimonieuse (S constant, p selon état, Psi constant)

m1_crdms \<- mark(processed_crdms, ddl_crdms, model.parameters = list( S = list(formula = \~1), p = list(formula = \~ stratum), Psi = list(formula = \~1) ))
