---
title: "Rédaction_V2"
format: html
editor: visual
execute-dir: project
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE, 
  echo = FALSE
)
#ce code permet de n'afficher aucun message parasite ni les warnings. 

```

# -------------------------------

# INTRODUCTION

# --------------------------------------------------

# Chargement des packages

```{r}
library(MuMIn)        # sélection de modèles, AICc, multimodel inference

library(tidyverse)

library(ggalluvial)   # diagrammes alluviaux (transitions, flux entre catégories)
library(lme4) #modèle mixtes

library(emmeans) #prédictions de modèles linéaires

library(stats)
library(plotly)

library(ggrepel)      # étiquettes non superposées sur graphiques ggplot
library(ggpmisc)      # annotations statistiques (équations, R²) sur ggplot

library(MASS)         # outils statistiques avancés (LDA, glm, distributions)
library(ade4)         # analyses multivariées écologiques (PCA, CA, RLQ)

library(tidyr)
library(dplyr)
library(stringr)

library(vegan)        # écologie numérique : RDA, CCA, NMDS, PERMANOVA
library(car)          # diagnostics de modèles (VIF, tests de type II/III)

library(RMark)        # modèles capture-marquage-recapture (interface MARK)
library(DiagrammeR)   # graphes et diagrammes (flowcharts, DAG)
library(rstatix)      # Tables propres



```

# --------------------------------------------------

# Ouverture des tableaux de données

## --------------

Les tableaux sont ouverts chacun de leur côté afin de pouvoir réaliser les analyses ci-dessous indépendamment, dans le cas où toutes les données n’ont pas été entièrement relevées.

### Tableau : recouvrement

```{r}
recouvrement <- read.csv("data/raw/Recouvrement VF.csv",sep = ";")
unique(recouvrement$Site)
```

### Tableau : détections individuelles

```{r}
verification <- read.csv("data/raw/detections_individuelles_verifsTC+LD_18dec.csv", sep = ";")

# Certains noms des sites ont des espaces invisibles, correction : 
unique(verification$site)
verification$site <- trimws(verification$site)
unique(verification$site)
```

### Tableau : taille et phénologie vérifiées

```{r}
data_original <- read.csv("data/raw/Taille et phéno verif LD.csv", sep = ";")
unique(data_original$site)

# Certains noms contiennent des accents non pris en charge
data_original <- data_original %>% 
  mutate(site
         = case_when(
    site == "Combe Michaut" ~ "Combe Michaut",
    site == "Tête Cendrée Bas" ~ "Tete Cendree Bas",
    site == "Tête Cendrée Haut" ~ "Tete Cendree Haut",
    site == "Vigne au Renard" ~ "Vigne au Renard",
    site == "Val Clavin" ~ "Val Clavin"
  ))
unique(data_original$site)
```

### Tableau : autonotation des observateurs

```{r}
experience <- read.csv("data/raw/Experience_des_observateurs_VF.csv", sep = ";")

# Pour les analyses suivantes nous avons rajouté la colonne sexe : 
experience$sexe <- c("m","f","m","m","m","f","m","m","m","f","f","f","f","m","f","m","m","m","m","m","f","f","f","m","f","m","f","m","f","f","f","m","f","f","m")

```

# --------------------------------------------------

# Compilation tableau complet

Pour les analyses suivantes, nous avons compilé l’ensemble des tableaux en un seul.

```{r, echo = FALSE, message = FALSE, warning = FALSE}

# Ajouter une colonne d'identifiant individuel en ajoutant la session
  ## Pour le tableau "vérification" des observateurs
verification2<- verification %>% 
  mutate(id_ind_fin = paste(ID_ind, session, sep = ".")) %>% 
  dplyr::select(id_ind_fin, everything())
  ## Pour le tableau "data_original" des évaluateurs

# Mettre le stade phénologique en ligne et non en colonne 
data_original2 <- data_original %>%
  dplyr::select(-tailleS1, -tailleS2, -tailleS3, -nbfleurs, -nbfruits, -predation) %>% 
  pivot_longer(
    cols = c(phenoS1, phenoS2, phenoS3),
    names_to = "session",
    values_to = "phenologie_verif"
  )%>% 
   mutate(session = case_when(
    session == "phenoS1" ~ 1,
    session == "phenoS2" ~ 2,
    session == "phenoS3" ~ 3
  )
   ) %>% 
  mutate(phenologie_verif
         = case_when(
    phenologie_verif == "j" ~ "juv",
    phenologie_verif == "nf" ~ "non_fleuri",
    phenologie_verif == "f" ~ "fleur",
    phenologie_verif == "ff" ~ "fleurs_fanees",
    phenologie_verif == "F" ~"fruit"
  ))

# Mettre la taille en ligne et non en colonne
data_original3 <- data_original %>% 
  dplyr::select(tailleS1, tailleS2, tailleS3) %>% 
  pivot_longer(
    cols = c(tailleS1, tailleS2, tailleS3),
    names_to = "session",
    values_to = "taille"
  ) %>% 
   mutate(session = case_when(
    session == "tailleS1" ~ 1,
    session == "tailleS2" ~ 2,
    session == "tailleS3" ~ 3
  )
   )

# Enlever la session car déjà présente sur l'autre data frame
data_original3 <- data_original3 %>% 
  dplyr::select(-session)

# Ajout des deux tableaux et suppression des lignes sans informations, liées à l’observation d’un individu à partir des sessions 2 ou 3
data_original4 <- cbind(data_original2, data_original3)

# Vérifier si il manque des informations par rapport à la phénologie
data_original4 %>% 
  filter(is.na(phenologie_verif))
      #Il manque des informations

# Ajouter la variable individuelle complète
data_original_obs <- data_original4 %>% 
  mutate(id_ind_fin = paste(ID_ind, session, sep = ".")) %>% 
  dplyr::select(id_ind_fin, everything())

# Prendre en compte le stade phénologique observé par observateurs
verification3 <- verification2 %>% 
  pivot_longer(
    cols = c(juv, non_fleuri, fleur, fleurs_fanees, fruit),
    names_to = "phenologie",
    values_to = "presence"
  )  
  
# Garder seulement la phénologie observée par observateurs
verification_obs <- verification3 %>% 
  filter(presence == 1)
  
# Vérifier le nombre individus
str(unique(verification_obs$id_ind_fin))
str(unique(data_original_obs$id_ind_fin))
str(data_original_obs$id_ind_fin)
str(verification_obs$id_ind_fin)
    # À priori, 66 individus jamais observés par les observateurs

# Extraire la liste de tous les individus
nb_individu <- data.frame(id_ind_fin = data_original_obs$id_ind_fin)

# Extraire la liste des individus dans le test de détection
nb_ind_obs <- data.frame(id_ind_fin = unique(verification_obs$id_ind_fin))

# Extraire les individus manquants
nb_individu_manquant <- nb_individu %>% 
  anti_join(nb_ind_obs, by = "id_ind_fin")

# Reprendre les données originales sur les valeurs manquantes
nb_individu_manquant_original <- data_original_obs %>% 
  semi_join(nb_individu_manquant, by = "id_ind_fin") 
  
# Joindre à ces données manquantes les valeurs du tableau observateurs
nb_individu_manquant_final <- nb_individu_manquant_original %>% 
  left_join(verification_obs, by = "id_ind_fin") %>% 
  dplyr::select(-ends_with(".y")) %>% 
  rename_with(~ sub("\\.x$", "", .x), ends_with(".x"))

# Joindre au fichier original les informations des évaluateurs
data_verification_original <- verification_obs %>% 
  left_join(data_original_obs, by = "id_ind_fin") %>% 
  dplyr::select(-ends_with(".y")) %>% 
  rename_with(~ sub("\\.x$", "", .x), ends_with(".x"))

# Mettre les colomnes dans le bon ordre
nb_individu_manquant_final <- nb_individu_manquant_final %>% 
  dplyr::select(id_ind_fin, session, site, date, numero_quadrat, ID_quadrat, marquage, ID_ind, observateur, adequation, phenologie, presence, quadrat, phenologie_verif, taille)

# Joindre ces données manquantes à tableau observateurs
tab_detection <- rbind(data_verification_original, nb_individu_manquant_final)

# Créer nouvelle valeur adéquation
tab_detection <- tab_detection %>% 
  mutate(adequation_reel = if_else(
    phenologie == phenologie_verif, 1, 0),
  comparaison_adequation = if_else(
    adequation_reel==adequation, 1, 0 ) )

# Taux d'erreur dans note d'adéquation
sum(tab_detection$comparaison_adequation == 0, na.rm = T) / nrow(tab_detection)

# Vérifier le nombre d'observateurs par session et par quadrat
nb_verif_quadrat <- verification %>% 
  group_by(session, site, numero_quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  )
nrow(nb_verif_quadrat)
nb_verif_quadrat <- nb_verif_quadrat %>% 
  mutate(site = case_when(
    site == "Combe Michaut" ~ "CM",
    site == "Tete Cendree Bas" ~ "TCb",
    site == "Tete Cendree Haut" ~ "TCh",
    site == "Vigne au Renard" ~ "VaR",
    site == "Val Clavin" ~ "VC"
  ),
  ID = "Q")

nb_verif_quadrat <- nb_verif_quadrat %>% 
  mutate(id_quadrat = paste(ID, numero_quadrat, sep = ""),
         id_quadrat_fin = paste(site, id_quadrat, session, sep =".")) %>% 
  dplyr::select(id_quadrat_fin, everything())

nb_obs_quadrat <- data_original_obs %>% 
  group_by(session, site, quadrat) %>% 
  count()
nrow(nb_obs_quadrat)

nb_quadrat_final <- tab_detection %>% 
  group_by(session, site, quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  ) %>% 
  filter(!is.na(quadrat))
nrow(nb_quadrat_final)

nb_quadrat_manquant <- nb_individu_manquant_final %>% 
  group_by(session, ID_quadrat) %>% 
  summarise(
    nb_observateurs = n_distinct(observateur),
    .groups = "drop"
  )
nrow(nb_quadrat_manquant)
    #individus manquants dans 39 quadras

nb_quadrat_manquant <- nb_quadrat_manquant %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  dplyr::select(id_quadrat_fin, everything())

test <- nb_quadrat_manquant %>% 
  anti_join(nb_verif_quadrat, by = "id_quadrat_fin")

# Nous avons bien tous les quadrat observés, juste pas tous les individus

str(tab_detection)

# Pour le moment, j'ai un tableau avec tous les individus observés, mais je n'ai pas l'information sur les individus non observés par les observateurs.
# Il me faut, à chaque fois, le nombre de quadrats observés par observateur pour pouvoir calculer le nombre d'observateurs par quadrat.

verification_obs_quadrat <- verification %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  group_by(id_quadrat_fin, observateur) %>% 
  count()

# Ajouter à tableau détection : id_quadrat_fin
tab_detection <- tab_detection %>% 
  mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = "."))

# Vérifier qu'il n'y pas de NA crées
tab_detection[is.na(tab_detection$id_quadrat_fin), ]

# Calculer le nombre d'individus par quadrat
nb_indiv_quadrat <- data_original_obs %>% 
    mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = ".")) %>% 
  group_by(id_quadrat_fin) %>% 
  summarise(
    nb_individus = n_distinct(ID_ind),
    .groups = "drop"
  )

# Comparaison du nombre d'individus par quadrat au nombre observé par mes observateurs
difference_ind <- verification_obs_quadrat %>% 
  full_join(nb_indiv_quadrat, by = "id_quadrat_fin")

# Taux de detection par observateur
difference_ind <- difference_ind %>% 
  mutate(detection = n/nb_individus)

# Extraire les identifiants de tous les individus possibles
individus_par_quadrat <- tab_detection %>%
  distinct(id_quadrat_fin, ID_ind)

# Combinaisons de tous les individus possibles avec les observateurs
grille_complete <- difference_ind %>%
  dplyr::select(id_quadrat_fin, observateur) %>%
  distinct() %>%
  left_join(individus_par_quadrat, by = "id_quadrat_fin", relationship = "many-to-many")

# Ajouter les informations de detection dans la grille complete
tab_complet <- grille_complete %>%
  left_join(
    tab_detection %>%
      mutate(detection = 1) %>%
      dplyr::select(id_quadrat_fin, observateur, ID_ind, detection),
    by = c("id_quadrat_fin", "observateur", "ID_ind")
  ) %>%
  mutate(
    detection = ifelse(is.na(detection), 0, detection)
  )

# Vérifier que cela a fonctionné en comparant le nombre de détections calculées avec le nombre de détections par quadrat

tab_complet %>%
  group_by(id_quadrat_fin, observateur) %>%
  summarise(
    n_detectes = sum(detection),
    .groups = "drop"
  ) %>%
  left_join(difference_ind, by = c("id_quadrat_fin", "observateur")) %>% 
  filter(n_detectes != n)

# Ajouter l'information des observateurs au tableau de détection
tab_complet <- tab_complet %>%
  left_join(
    tab_detection,
    by = c("id_quadrat_fin","ID_ind", "observateur")
  )

# Ajouter les informations aux données originales
data_original_obs <- data_original_obs %>% 
    mutate(id_quadrat_fin = paste(ID_quadrat, session, sep = "."))

tab_complet <- tab_complet %>%
  left_join(
    data_original_obs,
    by = c("id_quadrat_fin","ID_ind"),
    suffix = c("_test", "")
  ) %>%
  dplyr::select(
    -ends_with("_test")  # ou l’inverse selon ce que tu veux garder
  ) %>% 
  dplyr::select(id_ind_fin,id_quadrat_fin, ID_quadrat, ID_ind,site, quadrat, marquage, session,observateur, detection, phenologie_verif, phenologie, adequation, adequation_reel, taille)

```

### Joindre des données supplémentaires

Pour la construction des modèles, intégrer l’ensemble des données disponibles est pertinent afin de sélectionner les variables qui constitueront nos modèles. Ainsi, il est possible d’ajouter progressivement des données supplémentaires en utilisant les colonnes communes aux différents tableaux comme repère pour les jointures. Par exemple, ici, nous souhaitons inclure le tableau « recouvrement » contenant les différentes strates.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Extraire la partie quadrat de tab_complet (tout avant le dernier point)
tab_complet <- tab_complet %>%
  mutate(
    ID_Quadrat_clean = str_replace(id_quadrat_fin, "\\.[0-9]+$", "")
  )

# Nettoyer recouvrement pour correspondre au format de tab_complet
recouvrement_clean <- recouvrement %>%
  mutate(
    ID_Quadrat_clean = str_replace_all(ID_Quadrat, "_", ".")
  ) %>%
  dplyr::select(ID_Quadrat_clean, starts_with("S_"))

# Faire le left_join pour ajouter les colonnes S_ au tableau complet
tab_complet <- tab_complet %>%
  left_join(recouvrement_clean, by = "ID_Quadrat_clean") %>% 
  dplyr::select(-ID_Quadrat_clean)

#Vérification histoires de capture
verif_sessions <- tab_complet %>%
  group_by(ID_ind) %>%
  summarise(
    nb_sessions = n_distinct(session),
    sessions = paste(sort(unique(session)), collapse = ","),
    .groups = "drop"
  )

check_sessions <- verif_sessions %>%
  mutate(
    ok_sessions = sessions == "1,2,3"
  )

check_sessions %>%
  filter(!ok_sessions)

```

# --------------------------------------------------

# ANALYSES PRELIMINAIRES

## --------------

Avant de commencer des analyses complexes, difficiles à interpréter ou qui fournissent une compilation des informations, il est important d’étudier chaque variable indépendamment afin d’en expliquer les effets.

# I\_ Analyse générale

## --------------

## Ajout Galad modèle taille

```{r}
data_original_obs
unique(data_original_obs$phenologie_verif)

#On repart de tableau vérificatrices avec la taille et la phénologie par session passée sur une colomne et colomne session ajoutée
#On enlève phénologie NA 
data_taille <- data_original_obs %>% 
  filter(!is.na(phenologie_verif))

#On vérifie que l'on a l'info sur toutes les tailles
data_taille %>% 
  filter(is.na(taille))

#passer donnée taille caractères en numérique
data_taille <- data_taille %>%
  mutate(
    taille = as.numeric(gsub(",", ".", taille))
  )
#distribution variable réponse taille
ggplot(data=data_taille, aes(x= taille))+
  geom_histogram()
#Plus ou moins une loi de poisson
#Comme variable taille est continue on va utiliser une loi de poisson

#Enlever les taille = à 0 qui vont faie planter le modèle
any(data_taille$taille <= 0)

data_taille <- data_taille %>% 
  filter(!taille<=0)
#6 individus de perdus

#Mettre les variables explicatives en facteur
data_taille$phenologie_verif <- factor(data_taille$phenologie_verif)
data_taille$site <- factor(data_taille$site)
data_taille$session <- factor(data_taille$session)
data_taille$ID_ind <- factor(data_taille$ID_ind)
data_taille$ID_quadrat <- factor(data_taille$ID_quadrat)

#Modèle (on utlise glmmTMB pour faire les prédictions car algorithme trop lent avec glmer de lme4)

mod_glmm_gamma <- glmer(
  taille ~ phenologie_verif + site * session + (1 | ID_ind) + (1|ID_quadrat),
  family = Gamma(link = "log"),
  data = data_taille
)

summary(mod_glmm_gamma)
Anova(mod_glmm_gamma, type = 3)

#prédictions du modèle
emm <- emmeans(
  mod_glmm_gamma,
  ~ session * phenologie_verif | site,
  type = "response"
)

#préparation graphique
emm_df <- as.data.frame(emm)

emm_df$phenologie_verif <- factor(
  emm_df$phenologie_verif,
  levels = c("juv", "non_fleuri", "fleur", "fruit", "fleurs_fanees")
)

#graphique avec tous les effets
ggplot(emm_df, aes(
  x = session,
  y = response,
  fill = phenologie_verif
)) +
  geom_col(
    position = position_dodge(width = 0.9),
    color = "black"
  ) +
  geom_errorbar(
    aes(ymin = asymp.LCL, ymax = asymp.UCL),
    position = position_dodge(width = 0.9),
    width = 0.2
  ) +
  facet_wrap(~ site) +
  labs(
    x = "Session",
    y = "Taille prédite",
    fill = "Phénologie"
  ) +
  theme_minimal()

#Effet propre de la session toute phénologie et tout site confondu (=prédiction marginale)
emm_session <- emmeans(
  mod_glmm_gamma,
  ~ session,
  type = "response"
)

emm_session

emm_session_df <- as.data.frame(emm_session)

ggplot(emm_session_df, aes(
  x = session,
  y = response
)) +
  geom_col(
    fill = "grey70",
    color = "black",
    width = 0.7
  ) +
  geom_errorbar(
    aes(ymin = asymp.LCL, ymax = asymp.UCL),
    width = 0.2
  ) +
  labs(
    x = "Session",
    y = "Taille prédite (moyenne marginale)",
    title = "Effet marginal de la session sur la taille"
  ) +
  theme_minimal()

pairs(emm_session)

#Effet propre de la phénologie toute session et tout site confondu (=prédiction marginale)
emm_phenologie <- emmeans(
  mod_glmm_gamma,
  ~ phenologie_verif,
  type = "response"
)

emm_phenologie

emm_phenologie_df <- as.data.frame(emm_phenologie)
emm_phenologie_df$phenologie_verif <- factor(
  emm_phenologie_df$phenologie_verif,
  levels = c("juv", "non_fleuri", "fleur", "fruit", "fleurs_fanees")
)

ggplot(emm_phenologie_df, aes(
  x = phenologie_verif,
  y = response
)) +
  geom_col(
    fill = "skyblue",
    color = "black",
    width = 0.7
  ) +
  geom_errorbar(
    aes(ymin = asymp.LCL, ymax = asymp.UCL),
    width = 0.2
  ) +
  labs(
    x = "Phénologie",
    y = "Taille prédite (moyenne marginale)",
    title = "Effet marginal de la phénologie sur la taille"
  ) +
  theme_minimal()

pairs(emm_phenologie)

#Effet propre du site toute phénologie et toute session confondu (=prédiction marginale)
emm_site <- emmeans(
  mod_glmm_gamma,
  ~ site,
  type = "response"
)

emm_site

emm_site_df <- as.data.frame(emm_site)

ggplot(emm_site_df, aes(
  x = site,
  y = response
)) +
  geom_col(
    fill = "grey70",
    color = "black",
    width = 0.7
  ) +
  geom_errorbar(
    aes(ymin = asymp.LCL, ymax = asymp.UCL),
    width = 0.2
  ) +
  labs(
    x = "Session",
    y = "Taille prédite (moyenne marginale)",
    title = "Effet marginal de la session sur la taille"
  ) +
  theme_minimal()

pairs(emm_site)

```

## I_i Relation taille et phénologie

```{r}

# Mise en forme des données en format long :
# empilement des données de taille et de phénologie
# pour les trois sessions d’observation
data_long <- bind_rows(
  data_original %>% transmute(pheno = phenoS1, taille = tailleS1),
  data_original %>% transmute(pheno = phenoS2, taille = tailleS2),
  data_original %>% transmute(pheno = phenoS3, taille = tailleS3)
)

# Conversion de la variable taille en numérique
# (remplacement des virgules par des points)
# et suppression des valeurs manquantes
data_long <- data_long %>%
  mutate(
    taille = as.numeric(gsub(",", ".", taille))
  ) %>%
  filter(!is.na(taille), !is.na(pheno))

# Ordonnancement des stades phénologiques
# afin de respecter la progression biologique
data_long$pheno <- factor(
  data_long$pheno,
  levels = c("j", "nf", "f", "F", "ff")
)

# Visualisation de la distribution des tailles
# en fonction des stades phénologiques
# (toutes sessions confondues)
ggplot(data = data_long, aes(x = pheno, y = taille)) +
  geom_boxplot() +
  labs(
    x = "Stade phénologique",
    y = "Taille",
    title = "Taille selon le stade phénologique (sessions confondues)"
  ) +
  theme_minimal()

# Test global de significativité
kruskal.test(taille ~ pheno, data = data_long) 
# Hypothèse : il y a au moins une différence significative de taille entre les stades phénologiques. Hypothèse acceptée si p-value < 0.05 

# Comparaisons deux à deux (si le test global est significatif)
pairwise.wilcox.test(
  data_long$taille,
  data_long$pheno,
  p.adjust.method = "BH",
  exact = FALSE
)


# Afficher le tableau propre
data_long %>%
  pairwise_wilcox_test(taille ~ pheno, p.adjust.method = "BH") %>%
  select(group1, group2, p, p.adj)

```

Les tailles diffèrent significativement entre l’ensemble des stades phénologiques (tests de Wilcoxon deux à deux avec correction de Benjamini–Hochberg ; Tableau X). Les stades précoces (j et nf) présentent des différences très marquées avec tous les stades plus avancés (p_adj ≪ 0,001), indiquant une augmentation nette de la taille au cours du développement. Les différences entre les stades tardifs (f, F et ff) restent significatives, bien que plus faibles, suggérant une progression continue de la taille jusqu’aux phases finales du cycle phénologique. Ces résultats confirment une relation étroite entre la taille des individus et leur stade phénologique.

## I_ii Relation recouvrement végétal et site

L’analyse factorielle discriminante (AFD) est une méthode statistique qui permet de déterminer si des groupes prédéfinis peuvent être différenciés à partir de variables explicatives. Elle cherche à identifier les combinaisons de variables qui séparent le mieux ces groupes.

Dans ce travail, l’AFD est utilisée pour tester si les sites étudiés peuvent être distingués en fonction de la structure de la végétation, décrite par les recouvrements des différentes strates (muscinale, herbacée, arbustive et arborescente). L’objectif est donc de vérifier si chaque site présente une signature de recouvrement particulière et d’identifier quelles strates contribuent le plus à cette différenciation.

### RDA

Suppose une variable réponse continue et des relations linéaires

```{r}
# -------------------------------
# Analyse Factorielle Discriminante (AFD)
# -------------------------------

# -------------------------------
# 1. LDA sur les données originales
# -------------------------------
afd_recouvrement <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = recouvrement
)

# -------------------------------
# 2. Centrage et normalisation des variables
# -------------------------------
newdata <- as.data.frame(scale(recouvrement[, 4:8]))

# On ajoute la variable de groupe (Site) pour l'analyse
newdata$Site <- recouvrement$Site

# -------------------------------
# 3. LDA sur les données centrées-réduites
# -------------------------------
afd2 <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = newdata
)

# -------------------------------
# 4. MANOVA pour tester les différences entre groupes
# -------------------------------
manova_res <- manova(as.matrix(recouvrement[, 4:8]) ~ recouvrement$Site)

# -------------------------------
# 5. Prédiction avec LDA
# -------------------------------
pred <- predict(afd2)
table(Site = recouvrement$Site, Predicted = pred$class)

# -------------------------------
# 6. Validation croisée (jackknife)
# -------------------------------
afd_cv <- lda(
  Site ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = newdata,
  CV = TRUE
)
table(Site = newdata$Site, Predicted = afd_cv$class)

# -------------------------------
# 7. AFD basée sur l'ACP centrée-réduite
# -------------------------------
pca_res <- dudi.pca(recouvrement[, 4:8], scannf = FALSE, nf = 3)
afd3 <- discrimin(pca_res, factor(recouvrement$Site), scannf = FALSE, nf = 3) ## dans le nombre d'axe, indiquer la valeur adéquate dans pca_res$nf

# Exploration des valeurs propres et des coefficients standardisés
afd3$eig
sqrt(afd3$eig / (1 + afd3$eig))

# Projection des variables sur les fonctions discriminantes
# Créer une nouvelle fenêtre graphique (ou plot)
s.arrow(afd3$fa)  

# Projection des individus selon leur groupe
s.class(afd3$li, factor(recouvrement$Site))

#Regarder contribution relative des strates des variables aux axes
afd3$fa # strates
afd3$gc # sites
#A priori strate muscinale et arbustive basse sont les plus importantes
```

Les résultats de l’analyse factorielle discriminante (AFD) permettent de visualiser et d’expliquer les différences de composition végétale entre les sites étudiés.

Les deux graphiques issus de l’AFD illustrent ces différences. Le premier graphique montre la contribution des différentes strates de végétation aux axes discriminants : la longueur et la direction des flèches indiquent quelles strates participent le plus à la séparation des sites. Le second graphique représente la projection des individus regroupés par site : une bonne séparation entre les groupes traduit des différences nettes de recouvrement des strates entre les sites.

Le tableau des coefficients standardisés sur les trois premières fonctions discriminantes (DS1, DS2, DS3) permet de quantifier l’importance relative de chaque strate dans la discrimination des sites. L’interprétation montre que les strates muscinale et arbustive basse ont les coefficients les plus élevés sur les axes principaux (DS1 et DS2), ce qui indique qu’elles jouent un rôle clé dans la différenciation des sites. Les autres strates contribuent moins à la séparation, suggérant que leurs variations sont moins distinctives entre les sites.

Le tableau des coordonnées des sites sur les trois premières fonctions discriminantes montre la position de chaque site dans l’espace discriminant défini par les strates. Sur le premier axe (DS1), Combe Michaut est la plus positive et Vigne au Renard la plus négative, indiquant que ces deux sites sont les plus contrastés en termes de recouvrement des strates discriminantes, notamment muscinale et arbustive basse. Les autres sites se distinguent principalement sur le deuxième axe (DS2), avec Val Clavin très positive et Tête Cendrée haut négative, ce qui reflète des différences spécifiques sur les strates associées à cet axe.

Dans l’ensemble, ces résultats montrent que la structuration de la végétation permet de discriminer partiellement certains sites. Certains sites sont nettement distincts, tandis que d’autres se rapprochent, illustrant des similarités écologiques. L’AFD met ainsi en évidence que les strates muscinale et arbustive basse sont les variables les plus informatives pour expliquer les différences de composition végétale entre les sites.

### Régression Multinomiale

modèle statistique utilisé quand la variable réponse est catégorielle avec plus de deux catégories, sans ordre naturel entre elles. Phénologie est un état discret, non ordonné, avec plusieurs modalités. On fait pas RDA car suggère que la variable réponse est continue, elle cherche des relation linéaire

```{r}
library(nnet)

mod_pheno <- multinom(
  phenologie_verif ~ S_muscinale + S_herbacee + S_arbustive_basse + S_arbustive_haute + S_arborescente,
  data = tab_complet
)
summary(mod_pheno)


# Extraction
coef_mat <- summary(mod_pheno)$coefficients
se_mat   <- summary(mod_pheno)$standard.errors
z_mat    <- coef_mat / se_mat
p_mat    <- 2 * (1 - pnorm(abs(z_mat)))

# Fonction pour étoiles
etoiles <- function(p){
  ifelse(p < 0.001, "***",
         ifelse(p < 0.01, "**",
                ifelse(p < 0.05, "*",
                       ifelse(p < 0.1, ".", ""))))
}

# Construction du tableau
tableau <- data.frame(
  Etat = rep(rownames(coef_mat), each = ncol(coef_mat)),
  Parametre = rep(colnames(coef_mat), times = nrow(coef_mat)),
  Coefficient = as.vector(coef_mat),
  SE = as.vector(se_mat),
  z = as.vector(z_mat),
  p_value = as.vector(p_mat)
) %>%
  mutate(
    Coefficient = round(Coefficient, 4),
    SE = round(SE, 4),
    z = round(z, 3),
    p_value = signif(p_value, 3),
    Signif = etoiles(p_value)
  )

library(knitr)
library(kableExtra)

kable(tableau, format = "html", booktabs = TRUE,
      caption = "Régression multinomiale : effets des strates de recouvrement sur la phénologie") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))
```

Les résultats montrent un gradient phénologique structuré par l’ouverture du milieu : Milieux ouverts (herbacées) → stades avancés (fleurs fanées, fruits), peu de juvéniles. Milieux semi‑fermés (arbustif bas) → forte probabilité de fleurs fanées et de fruits. Milieux très fermés (arbustif haut, arborescent) → stades précoces (non fleuri, juvénile), peu de stades avancés. Mousse → effet faible ou non significatif, sauf absence quasi totale de fleurs fanées dans ces micro‑habitats.

La structure verticale du recouvrement influence donc fortement la progression phénologique, avec un cycle plus avancé dans les milieux ouverts ou semi‑ouverts, et plus précoce dans les milieux fermés.

## --------------

# II\_ Analyse de la variation dans le temps

Dans un premier temps, nous avons étudié la variation des données au cours du temps afin d’obtenir une vision dynamique de leur évolution.

## --------------

## II_i Effet de la session

### Effet de la session sur la taille

```{r}

# Transformer les données en format long
taille_long <- data_original %>%
  dplyr::select(tailleS1, tailleS2, tailleS3) %>%
  pivot_longer(
    cols = everything(),
    names_to = "session",
    values_to = "taille"
  ) %>%
  mutate(
    # remplacer les "," par "." et convertir en numérique
    taille = as.numeric(gsub(",", ".", taille)),
    # renommer les sessions
    session = dplyr::recode(session, "tailleS1"="S1", "tailleS2"="S2", "tailleS3"="S3")
  )

# Calcul de la moyenne, écart-type et IC 95%
taille_stats <- taille_long %>%
  group_by(session) %>%
  summarise(
    mean_taille = mean(taille, na.rm = TRUE),
    sd_taille = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille)),
    .groups = "drop"
  ) %>%
  mutate(
    se = sd_taille / sqrt(n),
    ci_lower = mean_taille - 1.96 * se,
    ci_upper = mean_taille + 1.96 * se
  )

# Histogramme avec IC 95%
ggplot(taille_stats, aes(x = session, y = mean_taille, fill = session)) +
  geom_bar(stat = "identity", width = 0.6) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, color = "black") +
  scale_fill_manual(values = c("S1"="#FF9999", "S2"="#FF4D4D", "S3"="#CC0000")) +
  labs(
    title = "Taille moyenne par session",
    x = "Session",
    y = "Taille moyenne",
    fill = "Session"
  ) +
  theme_minimal()


# Test global de significativité
kruskal.test(taille ~ session, data = taille_long)
# Hypothèse : il y a au moins une différence significative de taille entre les sessions. Hypothèse acceptée si p-value < 0.05 

# Comparaisons deux à deux (si le test global est significatif)
taille_long %>%
  pairwise_wilcox_test(taille ~ session, p.adjust.method = "BH") %>%
  select(group1, group2, p, p.adj)


```

Le graphique montre la taille moyenne des individus par session avec les barres d’erreur représentant l’intervalle de confiance à 95 %. On observe une augmentation progressive de la taille : la moyenne passe de S1 (\~13,7) à S2 (\~16,9) puis à S3 (\~17,3). L'augmentation est statistiquement significative.

### Effet de la session sur la phénologie

```{r}

# Transformer les données en format long : session = S1, S2, S3
pheno_long <- data_original %>%
  dplyr::select(phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = everything(),
    names_to = "session",
    values_to = "pheno"
  ) %>%
  # Remplacer NA par un label pour garder comme modalité
  dplyr::mutate(pheno = ifelse(is.na(pheno), "NA", as.character(pheno))) %>%
  # Renommer les sessions plus simplement
  mutate(session = dplyr::recode(session,
                          "phenoS1" = "S1",
                          "phenoS2" = "S2",
                          "phenoS3" = "S3"))

# Calcul des effectifs par session et type phénologique
pheno_stats <- pheno_long %>%
  group_by(session, pheno) %>%
  summarise(
    n = n(),
    .groups = "drop"
  ) %>%
  mutate(
    # IC 95% approximatif (Poisson)
    se = sqrt(n),
    ci_lower = pmax(n - 1.96 * se, 0),
    ci_upper = n + 1.96 * se
  )

# Définir l'ordre des phénos
pheno_stats$pheno <- factor(pheno_stats$pheno, levels = c("j", "nf", "f", "ff", "F", "NA"))

# Graphique avec barres côte à côte et IC 95%
ggplot(pheno_stats, aes(x = session, y = n, fill = pheno)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
                position = position_dodge(width = 0.8), width = 0.2, color = "black") +
  scale_fill_manual(values = c(
    "j"  = "#FF9999",
    "nf" = "#FF4D4D",
    "f"  = "#CC0000",
    "ff" = "#990000",
    "F"  = "#660000",
    "NA" = "#000000"  # noir pur pour NA
  )) +
  labs(
    title = "Effet de la session (S1, S2, S3) sur la phénologie",
    x = "Session",
    y = "Nombre d'individus",
    fill = "Type phénologique"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Le graphique montre une progression claire du développement phénologique au fil des sessions : début majoritairement jeunes, floraison qui commence à S2 principalement, diminution des données manquantes et des jeunes. La diminution des NA pourrait être dûe à une meilleure détectabilité des individus matures (nous vérifirons cette hpyothèse dans les analyses suivantes). La session 3 montre l'apparition de fleurs fannées, et de fruits.

```{r}

# ordonner les modalités
pheno_stats$pheno <- factor(pheno_stats$pheno, levels = c("j", "nf", "f", "ff", "F", "NA"))
pheno_stats$session <- factor(pheno_stats$session, levels = c("S1", "S2", "S3"))

# graphique : phénologie en x, couleur = session
ggplot(pheno_stats, aes(x = pheno, y = n, fill = session)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
                position = position_dodge(width = 0.8), width = 0.2, color = "black") +
  scale_fill_manual(values = c("S1" = "#FF9999", "S2" = "#FF4D4D", "S3" = "#CC0000")) +
  labs(title = "Distribution de la phénologie par session", x = "Type phénologique", y = "Nombre d'individus", fill = "Session") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5), legend.position = "right")
```

## --------------

# III\_ Analyse de la variation dans l'espace

## --------------

## III_i Effet du site

### Effet du site sur la taille

Taille \~ site

```{r}

# Transformer les données en format long pour toutes les tailles
taille_long <- data_original %>%
  dplyr::select(site, tailleS1, tailleS2, tailleS3) %>%
  pivot_longer(
    cols = c(tailleS1, tailleS2, tailleS3),
    names_to = "session",
    values_to = "taille"
  ) %>%
  mutate(
    # remplacer les "," par "." et convertir en numérique
    taille = as.numeric(gsub(",", ".", taille))
  )

# Calcul de la taille moyenne par site
taille_stats <- taille_long %>%
  group_by(site) %>%
  summarise(
    mean_taille = mean(taille, na.rm = TRUE),
    sd_taille = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille)),
    .groups = "drop"
  ) %>%
  mutate(
    se = sd_taille / sqrt(n),
    ci_lower = mean_taille - 1.96 * se,
    ci_upper = mean_taille + 1.96 * se
  )

# Histogramme avec IC 95%
ggplot(taille_stats, aes(x = site, y = mean_taille)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, color = "black") +
  labs(
    title = "Taille moyenne par site",
    x = "Site",
    y = "Taille moyenne",
    fill = "Site"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

```

### Effet du site sur la taille selon la session

Taille \~ site + session

```{r}

# Assurer que les colonnes de taille sont numériques
data_original <- data_original %>%
  mutate(
    tailleS1 = as.numeric(gsub(",", ".", tailleS1)),
    tailleS2 = as.numeric(gsub(",", ".", tailleS2)),
    tailleS3 = as.numeric(gsub(",", ".", tailleS3))
  )

# Calcul des statistiques pour chaque taille
stats_long <- data_original %>%
  pivot_longer(cols = c(tailleS1, tailleS2, tailleS3),
               names_to = "taille_type",
               values_to = "taille") %>%
  group_by(site, taille_type) %>%
  summarise(
    mean = mean(taille, na.rm = TRUE),
    sd = sd(taille, na.rm = TRUE),
    n = sum(!is.na(taille))
  ) %>%
  mutate(
    se = sd / sqrt(n),
    ci95 = se * qt(0.975, df = n - 1)
  )

# Définir des couleurs rouges avec différentes opacités
red_colors <- c("tailleS1" = "#FF6666",  # clair
                "tailleS2" = "#FF3333",  # moyen
                "tailleS3" = "#CC0000")  # foncé

# Graphique avec les trois tailles côte à côte par site
ggplot(stats_long, aes(x = site, y = mean, fill = taille_type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = mean - ci95, ymax = mean + ci95),
                position = position_dodge(width = 0.8), width = 0.2) +
  scale_fill_manual(values = red_colors) +
  labs(
    title = "Taille moyenne par site avec IC 95%",
    y = "Taille moyenne",
    x = "Site",
    fill = "Type de taille"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Effet du site sur la phénologie

phénologie \~ site

```{r}

# Transformer les phénos en format long en gardant les NA
pheno_long <- data_original %>%
  dplyr::select(site, phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = c(phenoS1, phenoS2, phenoS3),
    names_to = "pheno_type",
    values_to = "pheno"
  ) %>%
  # Remplacer NA par un label pour garder comme modalité
  mutate(pheno = ifelse(is.na(pheno), "NA", as.character(pheno)))

# Calcul des effectifs par site et type phénologique
pheno_stats <- pheno_long %>%
  group_by(site, pheno) %>%
  summarise(n = n(), .groups = "drop") %>%
  complete(site, pheno, fill = list(n = 0)) %>%  # inclure les combinaisons manquantes
  mutate(
    # IC 95% approximatif pour comptages (Poisson)
    se = sqrt(n),
    ci_lower = pmax(n - 1.96 * se, 0),
    ci_upper = n + 1.96 * se
  )

# Définir l'ordre des phénos
pheno_stats$pheno <- factor(pheno_stats$pheno, levels = c("j", "nf", "f", "ff", "F", "NA"))

# Graphique avec barres côte à côte et IC 95%
ggplot(pheno_stats, aes(x = site, y = n, fill = pheno)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
                position = position_dodge(width = 0.8), width = 0.2, color = "black") +
  scale_fill_manual(values = c(
    "j"  = "#FF9999",
    "nf" = "#FF4D4D",
    "f"  = "#CC0000",
    "ff" = "#990000",
    "F"  = "#660000",
    "NA" = "#000000"  # noir pur pour NA
  )) +
  labs(
    title = "Effet du site sur la phénologie",
    x = "Site",
    y = "Nombre d'individus",
    fill = "Type phénologique"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## --------------

## III_ii Effet de la strate

### Effet de la strate sur la taille

Taille \~ strate

```{r}

# Joindre les données par ID_Quadrat
data_joined <- data_original %>%
  left_join(recouvrement, by = c("ID_quadrat" = "ID_Quadrat"))

# Calcul de la taille moyenne par individu
data_joined <- data_joined %>%
  mutate(
    tailleS1 = as.numeric(gsub(",", ".", tailleS1)),
    tailleS2 = as.numeric(gsub(",", ".", tailleS2)),
    tailleS3 = as.numeric(gsub(",", ".", tailleS3)),
    taille_moyenne = rowMeans(dplyr::select(., tailleS1, tailleS2, tailleS3), na.rm = TRUE)
  )

# Transformer les strates en format long pour facettes
recouvrement_long <- data_joined %>%
  pivot_longer(
    cols = c(S_muscinale, S_herbacee, S_arbustive_basse, S_arbustive_haute, S_arborescente),
    names_to = "strate",
    values_to = "recouvrement"
  )

# Formule pour afficher R² et p-value
eqn <- ggpmisc::stat_poly_eq(
  aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")),
  formula = y ~ x,
  parse = TRUE,
  label.x.npc = "right",
  label.y.npc = 0.1,
  size = 3
)

# Graphique par strate avec couleurs modifiées
ggplot(recouvrement_long, aes(x = recouvrement, y = taille_moyenne)) +
  geom_point(alpha = 0.7, color = "black") +  # points noirs
  geom_smooth(method = "lm", se = TRUE, color = "#CC0000", fill = "#FF9999") +  # ligne rouge foncé, IC rouge clair
  eqn +
  facet_wrap(~ strate, scales = "free_x") +
  labs(
    title = "Taille moyenne en fonction du recouvrement végétal par strate",
    x = "Recouvrement (%)",
    y = "Taille moyenne"
  ) +
  theme_minimal()
```

### Effet de la strate sur la phénologie

phénologie \~ strate

```{r}

# Phénologie en format long
pheno_long <- data_original %>%
  dplyr::select(ID_quadrat, phenoS1, phenoS2, phenoS3) %>%
  pivot_longer(
    cols = starts_with("pheno"),
    names_to = "session",
    values_to = "pheno"
  ) %>%
  mutate(pheno = ifelse(is.na(pheno), "NA", pheno))

# Tableau de contingence (fréquences)
pheno_tab <- pheno_long %>%
  group_by(ID_quadrat, pheno) %>%
  summarise(n = n(), .groups = "drop") %>%
  pivot_wider(
    names_from = pheno,
    values_from = n,
    values_fill = 0
  )

# Vérification
str(pheno_tab)

data_rda <- pheno_tab %>%
  left_join(recouvrement, by = c("ID_quadrat" = "ID_Quadrat")) %>% dplyr::select(-"NA")

# Variables explicatives (recouvrement)
X <- data_rda %>%
  dplyr::select(
    S_muscinale,
    S_herbacee,
    S_arbustive_basse,
    S_arbustive_haute,
    S_arborescente
  )

Y <- data_rda %>%
  dplyr::select(j, nf, f, ff, F)

# Hellinger (très recommandé)
Y_hel <- decostand(Y, method = "hellinger")

X <- data_rda %>%
  dplyr::select(
    S_muscinale,
    S_herbacee,
    S_arbustive_basse,
    S_arbustive_haute,
    S_arborescente
  )

rda_pheno <- rda(Y_hel ~ ., data = X)

plot(rda_pheno, scaling = 2)

a_1<- anova(rda_pheno)          # effet global du recouvrement
a_2<-anova(rda_pheno, by="term") # effet de chaque strate
a_3<- anova(rda_pheno, by="axis")  # axes significatifs


```

La RDA montre que le recouvrement végétal n’explique pas significativement la variation globale de la phénologie (p = 0.146). Toutefois, le recouvrement herbacé et arbustif bas présentent des effets proches du seuil de significativité (p \< 0.1). Les strates hautes (arbustive haute et arborescente) n’influencent pas la phénologie. Ces résultats suggèrent que la phénologie est principalement associée à la structure végétale proche du sol.

## --------------

# IV\_ Niveau des observateurs

## Adéquation et fiabilité des observateurs

```{r}

# ------------------------------------------------------------
# 1. Taux d’erreur d’adéquation par observateur
# ------------------------------------------------------------

verification3 <- verification %>% 
  group_by(observateur) %>% 
  count(adequation) %>% 
  pivot_wider(
    names_from = adequation,
    values_from = n,
    names_glue = "{ifelse(adequation == 1, 'id_valide', 'id_fausse')}"
  ) %>% 
  replace_na(list(
    id_valide = 0,
    id_fausse = 0
  )) %>% 
  mutate(
    id_total = id_valide + id_fausse,
    tx_erreur = id_fausse / id_total
  )

verification3 <- verification3 %>%
  left_join(
    experience %>% dplyr::select(Observateur, sexe),
    by = c("observateur" = "Observateur")
  )

# Vérification des adéquations manquantes
verification %>% 
  filter(is.na(adequation))

# ------------------------------------------------------------
# 2. Score moyen d’auto-évaluation (A à E)
# ------------------------------------------------------------

experience <- experience %>%
  mutate(
    score_moyen = rowMeans(across(A:E), na.rm = TRUE),
    fiabilite = score_moyen / 10,
    risque_erreur = 1 - fiabilite
  )

# Variabilité intra-observateur
experience <- experience %>%
  rowwise() %>%
  mutate(ecart_type = sd(c_across(A:E), na.rm = TRUE)) %>%
  ungroup()

# Classement par risque d’erreur
experience <- experience %>%
  arrange(desc(risque_erreur)) %>%
  mutate(ID.observateur = factor(ID.observateur, levels = ID.observateur))

# ------------------------------------------------------------
# 3. Fusion auto-évaluation / adéquation réelle
# ------------------------------------------------------------

experience2 <- experience %>% 
  inner_join(
    verification3,
    by = join_by("Observateur" == "observateur")
  )


# ------------------------------------------------------------
# 4. Taux de détection réel par observateur
# ------------------------------------------------------------

tx_erreur <- tab_complet %>% 
  group_by(observateur) %>% 
  summarise(
    nb_ind = n(),
    nb_detect = sum(detection, na.rm = TRUE),
    tx_detect = nb_detect / nb_ind
  )

tx_erreur_fin <- experience2 %>% 
  inner_join(
    tx_erreur,
    by = join_by("Observateur" == "observateur")
  )

# ------------------------------------------------------------
# 5. Graphiques
# ------------------------------------------------------------

```

### Erreur d’attribution phénologique vs non-détection

```{r}

ggplot(tx_erreur_fin, aes(x = tx_erreur, y = 1 - tx_detect)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre taux d'erreur d'attribution et non-détection",
    x = "Taux d'erreur d'attribution de la phénologie",
    y = "Taux de non-détection",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Autonotation vs erreur d'attribution phénologique

```{r}
ggplot(tx_erreur_fin, aes(x = risque_erreur, y = tx_erreur)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre risque d'erreur (auto-évaluation) et erreur d'attribution",
    x = "Risque d'erreur basé sur l'auto-évaluation",
    y = "Taux d'erreur d'attribution de la phénologie",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Autonotation vs non-détection

```{r}
ggplot(tx_erreur_fin, aes(x = risque_erreur, y = 1 - tx_detect)) +
  geom_point(
    aes(color = sexe.x, size = id_total),
    alpha = 0.8
  ) +
  geom_smooth(
    method = "lm",
    se = TRUE,
    color = "red",
    fill = "pink",
    alpha = 0.3
  ) +
  geom_text_repel(
    aes(label = Observateur, color = sexe.x),
    size = 3,
    max.overlaps = Inf,
    force = 5,
    box.padding = 0.6,
    point.padding = 0.5,
    segment.color = "grey60",
    segment.size = 0.4
  ) +
  scale_color_manual(values = c("f" = "#E41A1C", "m" = "#377EB8")) +
  scale_size_continuous(range = c(2, 8)) +
  labs(
    title = "Relation entre risque d'erreur (auto-évaluation) et non-détection",
    x = "Risque d'erreur basé sur l'auto-évaluation",
    y = "Taux de non-détection",
    color = "Sexe",
    size = "Nombre d'observations"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Analyses complémentaires

```{r}
# ------------------------------------------------------------
# Visualisation des 3 axes en 3D 
# ------------------------------------------------------------

# Graphique 3D interactif avec taille fixe
plot_ly(
  tx_erreur_fin,
  x = ~tx_erreur,
  y = ~risque_erreur,
  z = ~ (1 - tx_detect),
  type = "scatter3d",
  mode = "markers+text",
  text = ~Observateur,
  textposition = "top center",
  marker = list(
    size = 5,  # taille fixe pour tous les points
    color = ~ifelse(sexe.x == "f", "#E41A1C", "#377EB8"),
    opacity = 0.8
  ),
  hovertemplate = paste(
    "<b>%{text}</b><br>",
    "Sexe: %{customdata[0]}<br>",
    "Taux erreur: %{x}<br>",
    "Risque auto: %{y}<br>",
    "Non-détection: %{z}<br>",
    "<extra></extra>"
  ),
  customdata = tx_erreur_fin[, c("sexe.x")]
) %>%
  layout(
    scene = list(
      xaxis = list(title = "Taux d'erreur d'attribution"),
      yaxis = list(title = "Risque d'erreur (auto-évaluation)"),
      zaxis = list(title = "Taux de non-détection")
    ),
    title = "Graphique 3D interactif des erreurs et non-détection"
  )

# ------------------------------------------------------------
# Corrélation
# ------------------------------------------------------------

cor.test(
  tx_erreur_fin$tx_detect,
  tx_erreur_fin$tx_erreur,
  method = "spearman"
)

# ------------------------------------------------------------
# Modèles linéaires
# ------------------------------------------------------------

model1_autonotation <- lm(
  risque_erreur ~ tx_erreur + tx_detect,
  data = tx_erreur_fin
)

model2_autonotation <- lm(
  risque_erreur ~ tx_detect,
  data = tx_erreur_fin
)

model3_autonotation <- lm(
  risque_erreur ~ tx_erreur,
  data = tx_erreur_fin
)

summary(model1_autonotation)
anova(model1_autonotation)

summary(model2_autonotation)
anova(model2_autonotation)

summary(model3_autonotation)
anova(model3_autonotation)

# ------------------------------------------------------------
# Comparaison des modèles
# ------------------------------------------------------------

AIC(model1_autonotation, model2_autonotation, model3_autonotation)

```

# --------------------------------------------------

# PROBABILITE DE DETECTION

## --------------

## V_i GLM

```{r}
# On a plusieurs strates et on veut seulement une covariable "recouvrement". On utilise donc une ACP pour avec l'inertie sur PC1.

# Extraire juste les colonnes numériques pour la PCA
recouvrement_num <- tab_complet %>%
  ungroup() %>%  # enlever le grouping
  dplyr::select(S_muscinale:S_arborescente) %>%
  mutate(across(everything(), as.numeric)) %>%
  as.data.frame()

# Vérifier
str(recouvrement_num)

acp1 <- dudi.pca(recouvrement_num, scale=T, center=T, scannf=F, nf=4)

#Calcul des % de chaque axe :
pc<-round(acp1$eig/sum(acp1$eig)*100,2)
pc

# % cumulés
cumsum(pc) 

#visualisation sur un graph
barplot(acp1$eig)

###Graphique de l'ACP####
s.corcircle(acp1$co, xax=1, yax=2, box = F, clabel = 0.5) 

# Ajouter la première et deuxième composante au tableau
tab_complet$recouvrement_PC1 <- acp1$li[,1]
tab_complet$recouvrement_PC2 <- acp1$li[,2]

# préparation variables pour GLMM
tab_complet <- tab_complet %>% 
  mutate(
    site = as.factor(site),
    session = as.factor(session),
    phenologie_verif = as.factor(phenologie_verif),
    taille = as.numeric(gsub(",", ".", taille)),
    ID_ind <- as.factor(ID_ind)
  )
str(tab_complet)

#Standardiser la taille sinon ça ne marche pas
tab_complet$taille_sc <- scale(tab_complet$taille)

tab_complet$ID_quadrat <- as.factor(tab_complet$ID_quadrat)

tx_erreur <- tab_complet %>% 
  group_by(observateur) %>% 
  summarise(
    nb_ind = n(),
    nb_detect = sum(detection, na.rm = TRUE),
    tx_detect = nb_detect / nb_ind
  )

tab_complet <- tab_complet %>% 
  left_join(
    tx_erreur,
    by = "observateur"
  )

experience_final <- experience %>% 
  mutate(observateur = Observateur) %>% 
  dplyr::select(observateur, risque_erreur)

tab_complet <- tab_complet %>% 
  left_join(experience_final, by = "observateur")

glmm_final <- glmer(
  detection ~ site * session + taille_sc + phenologie_verif + recouvrement_PC1 + recouvrement_PC2 + risque_erreur + (1|observateur) + (1|ID_ind) + (1|ID_quadrat),
  data = tab_complet,
  family = binomial,
  control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))
)

summary(glmm_final)
Anova(glmm_final, type = 3)

#prédictions marginales du modèle

#Pour l'axe 1 de l'ACP
emm_PC1 <- emmeans(
  glmm_final,
  ~ recouvrement_PC1,
  at = list(
    recouvrement_PC1 = seq(
      min(tab_complet$recouvrement_PC1, na.rm = TRUE),
      max(tab_complet$recouvrement_PC1, na.rm = TRUE),
      length.out = 100
    )
  ),
  type = "response"
)

emm_PC1_df <- as.data.frame(emm_PC1)

ggplot(emm_PC1_df, aes(x = recouvrement_PC1, y = prob)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL),
              alpha = 0.25) +
  labs(x = "Gradient de fermeture du milieu (axe 2 ACP)",
       y = "Probabilité de détection")+
  theme_minimal()

#pour l'axe 2 de l'ACP
emm_PC2 <- emmeans(
  glmm_final,
  ~ recouvrement_PC2,
  at = list(
    recouvrement_PC2 = seq(
      min(tab_complet$recouvrement_PC2, na.rm = TRUE),
      max(tab_complet$recouvrement_PC2, na.rm = TRUE),
      length.out = 100
    )
  ),
  type = "response"
)

emm_PC2_df <- as.data.frame(emm_PC2)

ggplot(emm_PC2_df, aes(x = recouvrement_PC2, y = prob)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL),
              alpha = 0.25) +
  labs(x = "Gradient de fermeture du milieu (axe 2 ACP)",
       y = "Probabilité de détection")+
  theme_minimal()

#pour le risque d'erreur lié à l'autonotation
emm_risque_erreur <- emmeans(
  glmm_final,
  ~ risque_erreur,
  at = list(
    risque_erreur = seq(
      min(tab_complet$risque_erreur, na.rm = TRUE),
      max(tab_complet$risque_erreur, na.rm = TRUE),
      length.out = 100
    )
  ),
  type = "response"
)

emm_risque_erreur_df <- as.data.frame(emm_risque_erreur)

ggplot(emm_risque_erreur_df, aes(x = risque_erreur, y = prob)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL),
              alpha = 0.25) +
  labs(x = "Risque d'erreur (basé sur autonotation des observateurs",
       y = "Probabilité de détection")+
  theme_minimal()

#pour la taille
#Préparer moyenne et écart type pour détransformer ma variable
mu_taille <- attr(tab_complet$taille_sc, "scaled:center")
sd_taille <- attr(tab_complet$taille_sc, "scaled:scale")
mu_taille
sd_taille

emm_taille <- emmeans(
  glmm_final,
  ~ taille_sc,
  at = list(
    taille_sc = seq(
      min(tab_complet$taille_sc, na.rm = TRUE),
      max(tab_complet$taille_sc, na.rm = TRUE),
      length.out = 100
    )
  ),
  type = "response"
)

emm_taille_df <- as.data.frame(emm_taille)

emm_taille_df$taille_reelle <-
  emm_taille_df$taille_sc * sd_taille + mu_taille

ggplot(emm_taille_df, aes(x = taille_reelle, y = prob)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL),
              alpha = 0.25) +
  labs(x = "Taille des individus (cm)",
       y = "Probabilité de détection")+
  theme_minimal()

#Pour l'interaction session x site
emm_site_session <- emmeans(
  glmm_final,
  ~ site * session,          # prédire toutes les combinaisons
  type = "response"          # retourne la probabilité (échelle 0-1)
)

# Convertir en data.frame pour ggplot
emm_site_session_df <- as.data.frame(emm_site_session)

ggplot(emm_site_session_df, aes(x = site, y = prob, fill = session)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL),
                position = position_dodge(width = 0.8),
                width = 0.2) +
  scale_y_continuous(limits = c(0,1)) +
  labs(
    x = "Site",
    y = "Probabilité de détection",
    fill = "Session",
    title = "Probabilité marginale de détection par site et session"
  ) +
  theme_classic(base_size = 14)

#Pour le stade phénologique
emm_phenologie <- emmeans(
  glmm_final,
  ~ phenologie_verif,          # prédire toutes les combinaisons
  type = "response"          # retourne la probabilité (échelle 0-1)
)

# Convertir en data.frame pour ggplot
emm_phenologie_df <- as.data.frame(emm_phenologie)

ggplot(emm_phenologie_df, aes(x = phenologie_verif, y = prob)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL),
                position = position_dodge(width = 0.8),
                width = 0.2) +
  scale_y_continuous(limits = c(0,1)) +
  labs(
    x = "Site",
    y = "Probabilité de détection",,
    title = "Probabilité marginale de détection par stade phénologique"
  ) +
  theme_classic(base_size = 14)


```

### Sélection de modèles

```{r}

# #Dredge ne fonctionne pas avec NA
# vars <- c("detection", "site", "session", "taille_sc",
#           "phenologie_verif", "recouvrement_PC1", "ID_ind")
# 
# tab_dredge <- tab_complet[complete.cases(tab_complet[, vars]), ]
# 
# #modèle complet
# glmm_global <- glmer(
#   detection ~ site + session + site:session + taille_sc + phenologie_verif + recouvrement_PC1 +
#     (1 | ID_ind),
#   data = tab_dredge,
#   family = binomial,
#   control = glmerControl(optimizer = "bobyqa",
#                          optCtrl = list(maxfun = 2e5))
# )
# 
# # Autoriser MuMIn à travailler avec glmer
# options(na.action = "na.fail")
# 
# # Sélection de modèle (toutes combinaisons de variables fixes)
# model_set <- dredge(glmm_global, trace = TRUE)
# 
# # Afficher les modèles triés par AICc
# model_set
# 
# model_set_df <- as.data.frame(model_set)
# 
# write.csv(
#   model_set_df,
#   file = "selection.csv",
#   row.names = FALSE
# )

```

## V_ii Détection de la phénologie

```{r}
unique(tab_complet$phenologie)
unique(tab_complet$phenologie_verif)

#création tableau
detect_comp <- tab_complet %>% 
  ungroup() %>% 
  filter(detection == 1) %>% #on ne garde que les individus détectés par les observateurs
  select(id_ind_fin,session,site,quadrat,marquage,phenologie_verif,phenologie)


unique(detect_comp$phenologie)
unique(detect_comp$phenologie_verif) #toujours des NA avec phénologie superviseuses

detect_comp %>% 
  filter(is.na(phenologie_verif))
#deux pheno non observées par superviseuses
tab_complet %>% 
  filter(id_ind_fin == "VC.Q4.45.3")
#Vu par un observateur/6

tab_complet %>% 
  filter(id_ind_fin == "VC.Q4.19.3")
#Vu par un observateur/6

#j'enlève ces deux individus des analyses
detect_comp <- detect_comp %>% 
  filter(!is.na(phenologie_verif))

#matrice de confusion
conf_mat <- table(
  phenologie_verif = tab_complet$phenologie_verif,
  phenologie = tab_complet$phenologie
)

conf_mat

#Version proportions
prop_conf_mat <- prop.table(conf_mat, margin = 1)

prop_conf_mat

#Transformer matrices en data frame
conf_df <- as.data.frame(conf_mat)
prop_df <- as.data.frame(prop_conf_mat)

# Renommage explicite (évite TOUS les bugs)
names(conf_df) <- c("phenologie_verif", "phenologie", "n")
names(prop_df) <- c("phenologie_verif", "phenologie", "prob")

#Tableau graphique
heat_df <- conf_df %>%
  left_join(prop_df,
            by = c("phenologie_verif", "phenologie")) %>%
  mutate(
    correct = phenologie_verif == phenologie,
    signed_prob = ifelse(correct, prob, -prob)
  )

#standardisation de mes probas pour que ça rende joli sur le graphique
heat_df <- heat_df %>%
  mutate(
    signed_prob_scaled = case_when(
      correct ~ prob / max(prob[correct]),               # 0 → 1 pour les bons
      !correct ~ -prob / max(prob[!correct])              # 0 → -1 pour les erreurs
    )
  )

#Heat map avec le nombre d'observations
ggplot(heat_df,
       aes(x = phenologie, y = phenologie_verif)) +
  
  geom_tile(aes(fill = signed_prob_scaled)) +
  
  geom_text(aes(label = n), size = 4, color = "black") +
  
  scale_fill_gradient2(
    low = "darkred",
    mid = "white",
    high = "darkgreen",
    midpoint = 0,
    limits = c(-1, 1),
    name = "Qualité d'observation\n(échelle relative)"
  ) +
  
  labs(
    x = "Phénologie observée",
    y = "Phénologie vérifiée",
    title = "Matrice de confusion – phénologie Sabot de Vénus",
    subtitle = "Vert = bonnes classifications | Rouge = erreurs"
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )

#Heat map avec les proportions
ggplot(heat_df,
       aes(x = phenologie, y = phenologie_verif)) +
  
  geom_tile(aes(fill = signed_prob_scaled)) +
  
  geom_text(aes(label = round(prob,2)), size = 4, color = "black") +
  
  scale_fill_gradient2(
    low = "darkred",
    mid = "white",
    high = "darkgreen",
    midpoint = 0,
    limits = c(-1, 1),
    name = "Qualité d'observation\n(échelle relative)"
  ) +
  
  labs(
    x = "Phénologie observée",
    y = "Phénologie vérifiée",
    title = "Matrice de confusion – phénologie Sabot de Vénus",
    subtitle = "Vert = bonnes classifications | Rouge = erreurs"
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )

#Si on veut faire la même chose par sites
conf_par_site <- tab_complet %>%
  group_by(site) %>%
  summarise(
    conf = list(table(phenologie_verif, phenologie)),
    .groups = "drop"
  )

prop.table(conf_par_site$conf[[1]], margin = 1)
prop.table(conf_par_site$conf[[2]], margin = 1)
prop.table(conf_par_site$conf[[3]], margin = 1)
prop.table(conf_par_site$conf[[4]], margin = 1)
prop.table(conf_par_site$conf[[5]], margin = 1)





```

# --------------------------------------------------

# CMR

## --------------

## VII_iAnalyse des transitions phénologiques avec et sans MARK ###VII_i.i Toutes transitions

```{r}
# -------------------------------
# 1. Charger les données
# -------------------------------
data<- data_original

# -------------------------------
# 2. Préparer les données phénologiques
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS1, phenoS2, phenoS3) %>%
  mutate(
    phenoS1 = phenology_codes[phenoS1],
    phenoS2 = phenology_codes[phenoS2],
    phenoS3 = phenology_codes[phenoS3]
  )

# Supprimer les individus avec NA dans phenoS1, phenoS2 ou phenoS3
phenology_data_numeric <- phenology_data_numeric %>%
  filter(!is.na(phenoS1) & !is.na(phenoS2) & !is.na(phenoS3))

# -------------------------------
# 3. Calcul empirique des transitions 1 → 2 → 3
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS1, phenoS2, phenoS3),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Calculer les transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Créer le champ "ch" pour MARK
# -------------------------------
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS1, phenoS2, phenoS3))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 3))

# -------------------------------
# 6. Préparer les données pour RMark
# -------------------------------
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1", "2", "3", "4", "5")
)

ms_ddl <- make.design.data(ms_data)

# -------------------------------
# 7. Modèle Multistrata avec RMark
# -------------------------------
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

### VII_i.ii Transitions session 1 → 2

```{r}
###MARK Session 1-2 ----

# -------------------------------
# 1. Charger les données
# -------------------------------
data <- data_original

# -------------------------------
# 2. Préparer les données phénologiques (sessions 1 et 2)
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS1, phenoS2) %>%
  mutate(
    phenoS1 = as.character(phenology_codes[phenoS1]),
    phenoS2 = as.character(phenology_codes[phenoS2])
  ) %>%
  # Supprimer les individus avec NA dans phenoS1 ou phenoS2
  filter(!is.na(phenoS1) & !is.na(phenoS2))

# -------------------------------
# 3. Calcul empirique des transitions 1 → 2
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS1, phenoS2),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation des transitions avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Partie RMark
# -------------------------------
# Créer le champ "ch" pour MARK
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS1, phenoS2))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 2))

# Préparer les données pour RMark
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1","2","3","4","5")
)

ms_ddl <- make.design.data(ms_data)

# Modèle Multistrata avec RMark
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

### VII_i.iii Transitions session 2 → 3

```{r}
###MARK Session 2-3 ----

# -------------------------------
# 1. Charger les données
# -------------------------------
data <- data_original

# -------------------------------
# 2. Préparer les données phénologiques (sessions 2 et 3)
# -------------------------------
phenology_codes <- c("j" = 1, "nf" = 2, "f" = 3, "ff" = 4, "F" = 5)

phenology_data_numeric <- data %>%
  dplyr::select(ID_ind, phenoS2, phenoS3) %>%
  mutate(
    phenoS2 = as.character(phenology_codes[phenoS2]),
    phenoS3 = as.character(phenology_codes[phenoS3])
  ) %>%
  # Supprimer les individus avec NA dans phenoS2 ou phenoS3
  filter(!is.na(phenoS2) & !is.na(phenoS3))

# -------------------------------
# 3. Calcul empirique des transitions 2 → 3
# -------------------------------
phenology_long <- phenology_data_numeric %>%
  pivot_longer(cols = c(phenoS2, phenoS3),
               names_to = "session",
               values_to = "state") %>%
  mutate(session = as.integer(gsub("phenoS", "", session)))

# Transitions successives
transitions <- phenology_long %>%
  group_by(ID_ind) %>%
  arrange(session) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n))

# Créer la matrice 5x5
num_states <- 5
states <- c("j","nf","f","ff","F")
Psi_matrix <- matrix(0, nrow=num_states, ncol=num_states, dimnames = list(states, states))

for(i in 1:num_states){
  for(j in 1:num_states){
    val <- transitions %>% filter(state == i, next_state == j) %>% pull(prob)
    if(length(val) > 0) Psi_matrix[i,j] <- mean(val)
  }
}

# Normalisation par ligne
Psi_matrix_norm <- Psi_matrix / rowSums(Psi_matrix)

# -------------------------------
# 4. Visualisation des transitions avec DiagrammeR
# -------------------------------
dot_code <- "digraph pheno_transitions { 
  rankdir=LR;
  node [shape=circle, style=filled, color=lightblue, fontname=Helvetica];
  j; nf; f; ff; F;
"

for(i in 1:num_states){
  for(j in 1:num_states){
    prob <- Psi_matrix_norm[i,j]
    if(!is.na(prob) && prob > 0){
      dot_code <- paste0(dot_code, states[i], " -> ", states[j], 
                         " [label=\"", round(prob, 2), "\"];\n")
    }
  }
}

dot_code <- paste0(dot_code, "}")
grViz(dot_code)

# -------------------------------
# 5. Partie RMark
# -------------------------------
# Créer le champ "ch" pour MARK
phenology_data_numeric <- phenology_data_numeric %>%
  mutate(ch = paste0(phenoS2, phenoS3))

# Vérification
stopifnot(all(nchar(phenology_data_numeric$ch) == 2))

# Préparer les données pour RMark
ms_data <- process.data(
  phenology_data_numeric,
  model = "Multistrata",
  strata.labels = c("1","2","3","4","5")
)

ms_ddl <- make.design.data(ms_data)

# Modèle Multistrata avec RMark
ms_model <- mark(
  ms_data,
  ms_ddl,
  model.parameters = list(
    Psi = list(formula = ~stratum),
    p = list(formula = ~1)
  )
)

# Résultats MARK
ms_model$results$real

```

## --------------

#TEST RMARK

```{r}
#Faire le tableau propre
verification %>%
  mutate(site=as.factor(site),
         date=date(date),
         ID_quadrat=as.factor(ID_quadrat),
         ID_ind=as.factor(ID_ind),
         observateur=as.factor(observateur)) %>%
  rowwise() %>%
  mutate(detecte=sum(juv, non_fleuri, fleur, fleurs_fanees, fruit)) -> data_imp


data_original %>%
  mutate(site=as.factor(site),
         ID_quadrat=as.factor(ID_quadrat),
         ID_ind=as.factor(ID_ind),
         phenoS1=as.factor(phenoS1),
         phenoS2=as.factor(phenoS2),
         phenoS3=as.factor(phenoS3)) -> taille_pheno

data_original %>%
  pivot_longer(cols=c(phenoS1, phenoS2, phenoS3), names_prefix = "phenoS", names_to = "session", values_to = "stade_pheno") %>%
  mutate(session=as.numeric(session)) %>%
  select(site, ID_quadrat, ID_ind, session, stade_pheno) -> pheno 

data_original %>%
  pivot_longer(cols=c(tailleS1, tailleS2, tailleS3), names_prefix = "tailleS", names_to = "session", values_to = "taille") %>%
  mutate(session=as.numeric(session)) %>%
  select(site, ID_quadrat, ID_ind, session, taille) -> taille


# visualisation des changements phéno
pheno %>%
  pivot_wider(names_from=session, id_cols = "ID_ind", values_from = "stade_pheno", names_prefix = "session") -> evo_pheno

evo_pheno %>%
  filter(!ID_ind%in%"CM.Q5.10") %>%
  group_by(session1, session2, session3) %>%
  summarise(n=n()) -> recap_pheno

# jointure avec données détectins individuelles et infos pheno/taille
data_imp %>%
  select(-site) %>%
  left_join(pheno) %>%
  left_join(taille) -> data

# on importe les infos observateurs / numéros de sessions 
obs_session <- readr::read_csv2("data/raw/obs_session.csv")
obs_session %>%
  dplyr::mutate(ID_quadrat = as.factor(ID_quadrat),
                observateur = as.factor(observateur),
                num_obs=as.factor(num_obs)) -> obs_session

obs_session %>%
  mutate(val=1) %>%
  pivot_wider(names_from = c(session,num_obs), values_from = val, id_cols=ID_quadrat) -> recap_sessions_obs


# on indique l'effort pour les observateurs manquants sur des quadrats, on reporte ensuite cette info aux individus
recap_sessions_obs %>%
  pivot_longer(cols=2:19,  names_to = "session_obs", values_to = "prospecte") %>%
  mutate(session=str_sub(session_obs, 1,1),
         session=as.numeric(session),
         num_obs=str_sub(session_obs, 3,6),
         num_obs=as.factor(num_obs)) %>%
  left_join(obs_session) -> effort


data %>%
  select(ID_quadrat, ID_ind) %>%
  group_by(ID_ind) %>%
  slice(1) -> ind_quadrat


ind_quadrat %>%
  left_join(effort) -> effort_inds


# histoires de détection individuelles avec les stades phénos pour multistate. 
effort_inds %>%
  left_join(data) %>%
  select(session, ID_ind, num_obs, stade_pheno, prospecte) %>%
  mutate(pheno_lettres = case_when(stade_pheno%in% "j" ~ "A",
                                   stade_pheno%in% "nf" ~ "B",
                                   stade_pheno%in% "f" ~ "C",
                                   stade_pheno%in% "ff" ~ "D",
                                   stade_pheno%in% "F"~ "E"),
         etat_prosp= case_when(prospecte==1~pheno_lettres, 
                               is.na(prospecte)~".")) %>% 
  arrange(session, num_obs) %>%
  pivot_wider(names_from = c(session,num_obs), values_from = etat_prosp, id_cols=ID_ind) %>%
  replace(is.na(.),"0") -> hist_det
  
hist_long <- hist_det %>%
  pivot_longer(
    cols = -ID_ind,
    names_to = "sess_obs",
    values_to = "etat"
  ) %>%
  mutate(
    session = as.integer(str_sub(sess_obs, 1, 1)),
    obs = str_extract(sess_obs, "obs[0-9]+")
  )

histories_for_mark <- hist_long %>%
  arrange(ID_ind, obs, session) %>%
  group_by(ID_ind, obs) %>%
  summarise(
    ch = paste0(etat, collapse = ""),
    .groups = "drop"
  )
  
histories_clean <- histories_for_mark %>%
  mutate(ID_obs = paste(ID_ind, obs, sep = "_")) %>%
  select(ID_obs, ch)

histories_valid <- histories_clean %>%
  # garder seulement les lignes qui ont au moins un A ou B
  filter(grepl("[A-Z]", ch))

histories_valid2 <- histories_valid %>%
  filter(!grepl("obs6", ID_obs))

# 2. Définir time.intervals : longueur = T - 1 = 2

# Si tu n'as pas de covariables individuelles prêtes, on utilise juste ID et ch
histories_for_mark <- histories_valid2 %>% select(ID_obs, ch)

# vérifier les chaînes
table(nchar(histories_for_mark$ch))
unique(head(histories_for_mark$ch, 20))

# définir time.intervals (T = longueur des ch ; ici T = 3 => length = 2)
T <- unique(nchar(histories_for_mark$ch))
time.intervals <- rep(1, as.integer(T) - 1)

# Process data en Multistrata : indiquer les labels d'états présents
# RMark attend : lettres pour états et "0" pour non-observé — c'est ton cas
states <- c("A","B","C","D","E")   # adapte si tu as d'autres états
```

# Multistrata

```{r}
processed_ms <- process.data(histories_for_mark, model = "Multistrata",
                             time.intervals = time.intervals,
                             strata.labels = states)

ddl_ms <- make.design.data(processed_ms)

# Exemple de modèles simples
S.const <- list(formula = ~1)                       # survie constante
p.bystratum <- list(formula = ~ stratum)            # p dépend de l'état observé
Psi.bystratum <- list(formula = ~ stratum)          # transitions dépendant de l'état de départ

# Lancer un modèle multistate simple
model_ms <- mark(processed_ms, ddl_ms,
                 model.parameters = list(S = S.const, p = p.bystratum, Psi = Psi.bystratum))

summary(model_ms)

```

Résultat correcte pour A et B et pour D et E résultats completement aberrants

#Autres modèles

```{r}

# 5. lancer modèles parcimonieux (Multistrata)
mA <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),       # survie constante
  p   = list(formula = ~stratum), # détection selon état
  Psi = list(formula = ~1)        # transitions constantes
))

mB <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~1),
  Psi = list(formula = ~stratum)
))

mC <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~stratum),
  Psi = list(formula = ~stratum)
))

# 6. comparer
models <- collect.models()
model.table(models)


```

#Prendre le recouvrement en compte

```{r}
# 1. Sécuriser noms et types
histories_for_mark <- histories_for_mark %>%
  rename_with(~ as.character(.), everything())

tab_complet <- tab_complet %>%
  rename_with(~ as.character(.), everything())

# 2. Extraire ID_ind depuis ID_obs (tout avant le premier "_")
histories_tmp <- histories_for_mark %>%
  mutate(ID_ind = sub("_.*$", "", as.character(ID_obs)),
         ID_ind = str_trim(ID_ind))

# 3. Préparer tab_complet : ID_ind + covariables à joindre
tab_tmp <- tab_complet %>%
  mutate(ID_ind = as.character(ID_ind),
         ID_ind = str_trim(ID_ind)) %>%
  select(ID_ind,
         recouvrement_PC1,
         site,
         session,
         taille,
         quadrat)

# 4. Jointure des covariables
histories_with_recov <- histories_tmp %>%
  left_join(tab_tmp, by = "ID_ind")

# 5. Conserver la structure d'origine + nouvelles colonnes
histories_for_mark_final <- histories_with_recov %>%
  select(all_of(names(histories_for_mark)),
         recouvrement_PC1,
         site,
         session,
         taille,
         quadrat)

# 6. Contrôles rapides
n_total <- nrow(histories_for_mark_final)
n_missing <- sum(is.na(histories_for_mark_final$recouvrement_PC1))
message("Total lignes : ", n_total,
        " — lignes sans recouvrement_PC1 après jointure : ", n_missing)

# 7. Préparation finale : ID_ind + centrage de la covariable continue
histories_for_mark_final <- histories_for_mark_final %>%
  mutate(ID_ind = sub("_.*$", "", as.character(ID_obs)),
         recouvrement_PC1 = as.numeric(recouvrement_PC1),
         taille = as.numeric(taille),
         recov_c = recouvrement_PC1 - mean(recouvrement_PC1, na.rm = TRUE))

# 8. Vérifier longueurs des chaînes ch
len_tab <- table(nchar(histories_for_mark_final$ch))
if (length(len_tab) != 1)
  stop("Les chaînes ch n'ont pas toutes la même longueur")

T <- as.integer(names(len_tab)[1])
time.intervals <- rep(1, T - 1)

# 9. Définir états présents (exclure '0' et '.')
states <- sort(
  setdiff(
    unique(unlist(strsplit(paste(histories_for_mark_final$ch,
                                 collapse = ""), ""))),
    c("0", ".")
  )
)
message("États détectés : ", paste(states, collapse = ", "))

# 10. Table pour process.data : ID, ch + covariables individuelles
histories_rmark <- histories_for_mark_final %>%
  transmute(ID = ID_obs,
            ch = ch,
            recov_c,
            site,
            session,
            taille,
            quadrat)

# 11. process.data Multistrata
processed_ms <- process.data(histories_rmark,
                             model = "Multistrata",
                             time.intervals = time.intervals,
                             strata.labels = states)

# 12. design data
ddl_ms <- make.design.data(processed_ms)

# Modèle 1 : base parcimonieuse (S constant, p selon état, Psi constant)
m1 <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~ stratum),
  Psi = list(formula = ~1)
))

# Modèle 2 : p constant, Psi selon état (test de structure)
m2 <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~1),
  Psi = list(formula = ~ stratum)
))

# Modèle 3 : modèle complet sans covariable (S constant, p ~ stratum, Psi ~ stratum)
m3 <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~1),
  p   = list(formula = ~ stratum),
  Psi = list(formula = ~ stratum)
))

# Modèle 4 : inclure recouvrement_PC1 (cov individuelle) sur S
m4 <- mark(processed_ms, ddl_ms, model.parameters = list(
  S   = list(formula = ~ recov_c),
  p   = list(formula = ~ stratum),
  Psi = list(formula = ~ stratum)
))

# Modèle 5 : 
m5 <- mark(processed_ms, ddl_ms, model.parameters = list( 
S = list(formula = ~1), 
p = list(formula = ~ stratum + recov_c), 
Psi = list(formula = ~ stratum) ))

# Modèle 5 : 
m5 <- mark(processed_ms, ddl_ms, model.parameters = list( 
S = list(formula = ~ 1), 
p = list(formula = ~ stratum + recov_c), 
Psi = list(formula = ~ stratum) ))


# Rassembler et comparer
models_list <- list(m1 = m1, m2 = m2, m3 = m3, m4 = m4, m5 =m5)
model.table(models_list)

processed_ms <- process.data(
  histories_rmark,
  model = "Multistrata",
  time.intervals = time.intervals,
  strata.labels = states,
  groups = "site"
)

ddl_ms <- make.design.data(processed_ms)

m6 <- mark(
  processed_ms,
  ddl_ms,
  model.parameters = list(
    S   = list(formula = ~ group),                 # survie différente selon site
    p   = list(formula = ~ stratum + recov_c),     # détection selon état + recouvrement
    Psi = list(formula = ~ stratum)                # transitions selon état
  )
)

models_list <- list(m6=m6)
model.table(models_list)
```

# CRDMS

processed_crdms \<- process.data(histories_rmark, model = "CRDMS", time.intervals = time.intervals_crdms, strata.labels = states)

# 12. design data

ddl_crdms \<- make.design.data(processed_crdms)

# Modèle 1 : base parcimonieuse (S constant, p selon état, Psi constant)

m1_crdms \<- mark(processed_crdms, ddl_crdms, model.parameters = list( S = list(formula = \~1), p = list(formula = \~ stratum), Psi = list(formula = \~1) ))
